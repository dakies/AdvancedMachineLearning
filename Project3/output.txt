Sender: LSF System <lsfadmin@eu-g1-034-2>
Subject: Job 154016616: <python estimate.py> in cluster <euler> Done

Job <python estimate.py> was submitted from host <eu-login-02> by user <daniekie> in cluster <euler> at Mon Nov 30 12:38:41 2020
Job was executed on host(s) <40*eu-g1-034-2>, in queue <normal.4h>, as user <daniekie> in cluster <euler> at Mon Nov 30 12:38:45 2020
</cluster/home/daniekie> was used as the home directory.
</cluster/home/daniekie/aml> was used as the working directory.
Started at Mon Nov 30 12:38:45 2020
Terminated at Mon Nov 30 13:35:47 2020
Results reported at Mon Nov 30 13:35:47 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python estimate.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   7404.00 sec.
    Max Memory :                                 5477 MB
    Average Memory :                             4915.80 MB
    Total Requested Memory :                     40960.00 MB
    Delta Memory :                               35483.00 MB
    Max Swap :                                   -
    Max Processes :                              86
    Max Threads :                                90
    Run time :                                   3447 sec.
    Turnaround time :                            3426 sec.

The output (if any) follows:

False
False

(5117, 131)
(5117, 1)
Performing grid search...
pipeline: ['outlier', 'selection', 'scale', 'model']
parameters:
{'model': [XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)],
 'model__colsample_bylevel': (0.01, 1.0, 'uniform'),
 'model__colsample_bytree': Real(low=0.3, high=1, prior='uniform', transform='identity'),
 'model__gamma': Integer(low=1, high=5, prior='uniform', transform='identity'),
 'model__learning_rate': (0.01, 1.0, 'log-uniform'),
 'model__max_delta_step': Integer(low=0, high=20, prior='uniform', transform='identity'),
 'model__max_depth': Integer(low=3, high=20, prior='uniform', transform='identity'),
 'model__min_child_weight': Integer(low=1, high=10, prior='uniform', transform='identity'),
 'model__n_estimators': Integer(low=50, high=150, prior='uniform', transform='identity'),
 'model__scale_pos_weight': Real(low=1, high=1000, prior='log-uniform', transform='identity'),
 'model__subsample': Real(low=0.3, high=1, prior='uniform', transform='identity'),
 'scale': ['passthrough']}
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6582926807483003, model__colsample_bytree=0.3, model__gamma=5, model__learning_rate=0.2482871564923991, model__max_delta_step=14, model__max_depth=20, model__min_child_weight=10, model__n_estimators=61, model__scale_pos_weight=882.6450983940014, model__subsample=1.0, scale=passthrough 
[12:40:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6582926807483003, model__colsample_bytree=0.3, model__gamma=5, model__learning_rate=0.2482871564923991, model__max_delta_step=14, model__max_depth=20, model__min_child_weight=10, model__n_estimators=61, model__scale_pos_weight=882.6450983940014, model__subsample=1.0, scale=passthrough, score=0.822, total=   4.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9120957067510712, model__colsample_bytree=0.5976528037728883, model__gamma=1, model__learning_rate=0.12761761072761757, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=2.0000521908976103, model__subsample=1.0, scale=passthrough 
[12:43:15] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9120957067510712, model__colsample_bytree=0.5976528037728883, model__gamma=1, model__learning_rate=0.12761761072761757, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=2.0000521908976103, model__subsample=1.0, scale=passthrough, score=0.815, total=  29.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4519864554659911, model__colsample_bytree=0.8366425105706587, model__gamma=5, model__learning_rate=0.18683460622727016, model__max_delta_step=9, model__max_depth=8, model__min_child_weight=1, model__n_estimators=107, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:46:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4519864554659911, model__colsample_bytree=0.8366425105706587, model__gamma=5, model__learning_rate=0.18683460622727016, model__max_delta_step=9, model__max_depth=8, model__min_child_weight=1, model__n_estimators=107, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.818, total=  10.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8567412002271322, model__colsample_bytree=0.8575671103085107, model__gamma=2, model__learning_rate=0.07465261039980901, model__max_delta_step=18, model__max_depth=3, model__min_child_weight=9, model__n_estimators=107, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[12:49:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8567412002271322, model__colsample_bytree=0.8575671103085107, model__gamma=2, model__learning_rate=0.07465261039980901, model__max_delta_step=18, model__max_depth=3, model__min_child_weight=9, model__n_estimators=107, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.816, total=   3.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.33427716540771224, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.02433661877263249, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=14.638697274418845, model__subsample=0.3, scale=passthrough 
[12:53:17] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.33427716540771224, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.02433661877263249, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=14.638697274418845, model__subsample=0.3, scale=passthrough, score=0.792, total=   2.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5018576187286898, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.028564295402751114, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=101, model__scale_pos_weight=1.0, model__subsample=0.6459261463922767, scale=passthrough 
[12:57:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5018576187286898, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.028564295402751114, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=101, model__scale_pos_weight=1.0, model__subsample=0.6459261463922767, scale=passthrough, score=0.812, total=  13.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9330712449712505, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.11159539600064079, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.729062663586322, scale=passthrough 
[13:00:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9330712449712505, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.11159539600064079, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.729062663586322, scale=passthrough, score=0.821, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.35786876313122484, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1400059167253532, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.804837633099327, scale=passthrough 
[13:02:53] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.35786876313122484, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1400059167253532, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.804837633099327, scale=passthrough, score=0.826, total=   4.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5509412498824555, model__colsample_bytree=0.9876610047109231, model__gamma=4, model__learning_rate=0.9817695135819916, model__max_delta_step=12, model__max_depth=4, model__min_child_weight=10, model__n_estimators=60, model__scale_pos_weight=228.264514753827, model__subsample=0.31836289784150784, scale=passthrough 
[13:07:06] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5509412498824555, model__colsample_bytree=0.9876610047109231, model__gamma=4, model__learning_rate=0.9817695135819916, model__max_delta_step=12, model__max_depth=4, model__min_child_weight=10, model__n_estimators=60, model__scale_pos_weight=228.264514753827, model__subsample=0.31836289784150784, scale=passthrough, score=0.768, total=   1.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8239118000910547, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.13590694805472336, model__max_delta_step=5, model__max_depth=10, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7636751799087067, scale=passthrough 
[13:10:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8239118000910547, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.13590694805472336, model__max_delta_step=5, model__max_depth=10, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7636751799087067, scale=passthrough, score=0.823, total=  19.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9365057126379146, model__colsample_bytree=0.9868871308476761, model__gamma=3, model__learning_rate=0.04020976089944642, model__max_delta_step=1, model__max_depth=13, model__min_child_weight=1, model__n_estimators=146, model__scale_pos_weight=11.775609005448057, model__subsample=0.3268292221957598, scale=passthrough 
[13:14:09] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9365057126379146, model__colsample_bytree=0.9868871308476761, model__gamma=3, model__learning_rate=0.04020976089944642, model__max_delta_step=1, model__max_depth=13, model__min_child_weight=1, model__n_estimators=146, model__scale_pos_weight=11.775609005448057, model__subsample=0.3268292221957598, scale=passthrough, score=0.828, total=  20.1s
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   16.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   20.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    8.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   18.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   14.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   32.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   16.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   29.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   17.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   23.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   12.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   24.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   37.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   12.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   17.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    8.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    8.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   12.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   27.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   25.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   11.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   14.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   30.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   14.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   20.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   47.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   16.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   35.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   21.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   12.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   29.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    8.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   17.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   52.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   18.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   12.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    8.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   28.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   22.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   19.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   19.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   15.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    8.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    8.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   15.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   20.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   24.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    8.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   30.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    8.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   11.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   17.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   34.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9951983831500005, model__colsample_bytree=0.3610949756900127, model__gamma=1, model__learning_rate=0.01098541902881326, model__max_delta_step=18, model__max_depth=17, model__min_child_weight=10, model__n_estimators=59, model__scale_pos_weight=420.9935578783081, model__subsample=0.9577403793948231, scale=passthrough 
[13:23:56] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9951983831500005, model__colsample_bytree=0.3610949756900127, model__gamma=1, model__learning_rate=0.01098541902881326, model__max_delta_step=18, model__max_depth=17, model__min_child_weight=10, model__n_estimators=59, model__scale_pos_weight=420.9935578783081, model__subsample=0.9577403793948231, scale=passthrough, score=0.800, total=   6.5s
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   12.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   28.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.3s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   18.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    8.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   16.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   19.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.6s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   17.5s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6565466212924355, model__colsample_bytree=0.735357685288236, model__gamma=2, model__learning_rate=0.04957929129543922, model__max_delta_step=15, model__max_depth=8, model__min_child_weight=4, model__n_estimators=78, model__scale_pos_weight=23.24113601995236, model__subsample=0.3610574395015852, scale=passthrough 
[12:39:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6565466212924355, model__colsample_bytree=0.735357685288236, model__gamma=2, model__learning_rate=0.04957929129543922, model__max_delta_step=15, model__max_depth=8, model__min_child_weight=4, model__n_estimators=78, model__scale_pos_weight=23.24113601995236, model__subsample=0.3610574395015852, scale=passthrough, score=0.823, total=   5.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5288586629520308, model__colsample_bytree=0.3, model__gamma=3, model__learning_rate=0.16432636056877883, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=5, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:41:23] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5288586629520308, model__colsample_bytree=0.3, model__gamma=3, model__learning_rate=0.16432636056877883, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=5, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.808, total=   3.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.17501511587798843, model__colsample_bytree=0.688339167996399, model__gamma=4, model__learning_rate=0.14555030812967049, model__max_delta_step=19, model__max_depth=15, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1.5505401377102335, model__subsample=1.0, scale=passthrough 
[12:44:29] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.17501511587798843, model__colsample_bytree=0.688339167996399, model__gamma=4, model__learning_rate=0.14555030812967049, model__max_delta_step=19, model__max_depth=15, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1.5505401377102335, model__subsample=1.0, scale=passthrough, score=0.818, total=   7.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3446779503502123, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.18228125280787674, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=6.979894561096652, model__subsample=1.0, scale=passthrough 
[12:48:03] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3446779503502123, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.18228125280787674, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=6.979894561096652, model__subsample=1.0, scale=passthrough, score=0.812, total=   2.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.23083627991824782, model__colsample_bytree=0.41548787960338146, model__gamma=5, model__learning_rate=0.0981440649803512, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0295122186395866, model__subsample=0.7460870487526741, scale=passthrough 
[12:51:00] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.23083627991824782, model__colsample_bytree=0.41548787960338146, model__gamma=5, model__learning_rate=0.0981440649803512, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0295122186395866, model__subsample=0.7460870487526741, scale=passthrough, score=0.817, total=   6.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9098253164362686, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.2593988949894903, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=4.418766958765141, model__subsample=1.0, scale=passthrough 
[12:54:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9098253164362686, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.2593988949894903, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=4.418766958765141, model__subsample=1.0, scale=passthrough, score=0.820, total=   4.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.5403128228512762, model__gamma=1, model__learning_rate=0.06332776457703826, model__max_delta_step=17, model__max_depth=16, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=627.2845718396584, model__subsample=1.0, scale=passthrough 
[12:58:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.5403128228512762, model__gamma=1, model__learning_rate=0.06332776457703826, model__max_delta_step=17, model__max_depth=16, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=627.2845718396584, model__subsample=1.0, scale=passthrough, score=0.816, total=   6.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8700241242535257, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1077293607590322, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=100, model__scale_pos_weight=1.0, model__subsample=0.8512232839810878, scale=passthrough 
[13:01:12] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8700241242535257, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1077293607590322, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=100, model__scale_pos_weight=1.0, model__subsample=0.8512232839810878, scale=passthrough, score=0.811, total=  17.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7723746868256385, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=9.000308447877524, model__subsample=0.3, scale=passthrough 
[13:04:18] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7723746868256385, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=9.000308447877524, model__subsample=0.3, scale=passthrough, score=0.818, total=  17.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.99256112795603, model__colsample_bytree=0.3402333276520046, model__gamma=4, model__learning_rate=0.11307837202164223, model__max_delta_step=19, model__max_depth=4, model__min_child_weight=1, model__n_estimators=145, model__scale_pos_weight=13.987266647869875, model__subsample=0.39763524876794626, scale=passthrough 
[13:07:34] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.99256112795603, model__colsample_bytree=0.3402333276520046, model__gamma=4, model__learning_rate=0.11307837202164223, model__max_delta_step=19, model__max_depth=4, model__min_child_weight=1, model__n_estimators=145, model__scale_pos_weight=13.987266647869875, model__subsample=0.39763524876794626, scale=passthrough, score=0.822, total=   4.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4511140442147604, model__colsample_bytree=0.9903547674262179, model__gamma=5, model__learning_rate=0.4551364817707272, model__max_delta_step=3, model__max_depth=9, model__min_child_weight=10, model__n_estimators=51, model__scale_pos_weight=686.3543271963737, model__subsample=0.9292339219363912, scale=passthrough 
[13:11:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4511140442147604, model__colsample_bytree=0.9903547674262179, model__gamma=5, model__learning_rate=0.4551364817707272, model__max_delta_step=3, model__max_depth=9, model__min_child_weight=10, model__n_estimators=51, model__scale_pos_weight=686.3543271963737, model__subsample=0.9292339219363912, scale=passthrough, score=0.808, total=   4.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8734254422828995, model__colsample_bytree=0.9509562517823495, model__gamma=2, model__learning_rate=0.010287031832540747, model__max_delta_step=3, model__max_depth=18, model__min_child_weight=2, model__n_estimators=137, model__scale_pos_weight=3.717320547813186, model__subsample=0.5853514305903059, scale=passthrough 
[13:15:40] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8734254422828995, model__colsample_bytree=0.9509562517823495, model__gamma=2, model__learning_rate=0.010287031832540747, model__max_delta_step=3, model__max_depth=18, model__min_child_weight=2, model__n_estimators=137, model__scale_pos_weight=3.717320547813186, model__subsample=0.5853514305903059, scale=passthrough, score=0.820, total=  30.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6788578084180311, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10510529783124824, model__max_delta_step=0, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.712108015281221, scale=passthrough 
[13:20:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6788578084180311, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10510529783124824, model__max_delta_step=0, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.712108015281221, scale=passthrough, score=0.819, total=  12.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2806112006438811, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.2451042114060229, model__max_delta_step=2, model__max_depth=3, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6786443757545222, scale=passthrough 
[13:25:26] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2806112006438811, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.2451042114060229, model__max_delta_step=2, model__max_depth=3, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6786443757545222, scale=passthrough, score=0.820, total=   3.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.036013135558974105, model__colsample_bytree=0.6770798813716852, model__gamma=1, model__learning_rate=0.35384207897748293, model__max_delta_step=7, model__max_depth=14, model__min_child_weight=4, model__n_estimators=141, model__scale_pos_weight=13.587798533272867, model__subsample=0.7134838459802921, scale=passthrough 
[12:39:45] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.036013135558974105, model__colsample_bytree=0.6770798813716852, model__gamma=1, model__learning_rate=0.35384207897748293, model__max_delta_step=7, model__max_depth=14, model__min_child_weight=4, model__n_estimators=141, model__scale_pos_weight=13.587798533272867, model__subsample=0.7134838459802921, scale=passthrough, score=0.805, total=   3.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.04051980750184009, model__max_delta_step=15, model__max_depth=20, model__min_child_weight=5, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:41:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.04051980750184009, model__max_delta_step=15, model__max_depth=20, model__min_child_weight=5, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.784, total=   1.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.30473733141436166, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.26300031954289427, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:44:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.30473733141436166, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.26300031954289427, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.807, total=   3.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.30710558780986585, model__colsample_bytree=0.7451117847409254, model__gamma=4, model__learning_rate=0.03979965805844932, model__max_delta_step=1, model__max_depth=20, model__min_child_weight=3, model__n_estimators=150, model__scale_pos_weight=73.2857211995429, model__subsample=1.0, scale=passthrough 
[12:48:09] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.30710558780986585, model__colsample_bytree=0.7451117847409254, model__gamma=4, model__learning_rate=0.03979965805844932, model__max_delta_step=1, model__max_depth=20, model__min_child_weight=3, model__n_estimators=150, model__scale_pos_weight=73.2857211995429, model__subsample=1.0, scale=passthrough, score=0.819, total=  12.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.415790734612201, model__colsample_bytree=0.6845964052587015, model__gamma=1, model__learning_rate=0.020308990155481214, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=14.718278134971332, model__subsample=0.3, scale=passthrough 
[12:51:10] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.415790734612201, model__colsample_bytree=0.6845964052587015, model__gamma=1, model__learning_rate=0.020308990155481214, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=14.718278134971332, model__subsample=0.3, scale=passthrough, score=0.821, total=   6.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3559794222308732, model__colsample_bytree=0.38368467345407525, model__gamma=3, model__learning_rate=0.03568816551718303, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=795.2428424486291, model__subsample=0.5003519395379956, scale=passthrough 
[12:55:04] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3559794222308732, model__colsample_bytree=0.38368467345407525, model__gamma=3, model__learning_rate=0.03568816551718303, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=795.2428424486291, model__subsample=0.5003519395379956, scale=passthrough, score=0.826, total=   6.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.5403128228512762, model__gamma=1, model__learning_rate=0.06332776457703826, model__max_delta_step=17, model__max_depth=16, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=627.2845718396584, model__subsample=1.0, scale=passthrough 
[12:58:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.5403128228512762, model__gamma=1, model__learning_rate=0.06332776457703826, model__max_delta_step=17, model__max_depth=16, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=627.2845718396584, model__subsample=1.0, scale=passthrough, score=0.815, total=   7.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8700241242535257, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1077293607590322, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=100, model__scale_pos_weight=1.0, model__subsample=0.8512232839810878, scale=passthrough 
[13:01:12] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8700241242535257, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1077293607590322, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=100, model__scale_pos_weight=1.0, model__subsample=0.8512232839810878, scale=passthrough, score=0.823, total=  17.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.37873309844010733, model__colsample_bytree=0.9278492397684184, model__gamma=2, model__learning_rate=0.03231204867296303, model__max_delta_step=19, model__max_depth=20, model__min_child_weight=10, model__n_estimators=145, model__scale_pos_weight=68.94834156267456, model__subsample=0.9248473167614011, scale=passthrough 
[13:04:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.37873309844010733, model__colsample_bytree=0.9278492397684184, model__gamma=2, model__learning_rate=0.03231204867296303, model__max_delta_step=19, model__max_depth=20, model__min_child_weight=10, model__n_estimators=145, model__scale_pos_weight=68.94834156267456, model__subsample=0.9248473167614011, scale=passthrough, score=0.821, total=  12.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9973377829752199, model__colsample_bytree=0.9869839643094087, model__gamma=4, model__learning_rate=0.025409003650511294, model__max_delta_step=17, model__max_depth=17, model__min_child_weight=10, model__n_estimators=134, model__scale_pos_weight=38.40198305133798, model__subsample=0.7748467805582491, scale=passthrough 
[13:07:46] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9973377829752199, model__colsample_bytree=0.9869839643094087, model__gamma=4, model__learning_rate=0.025409003650511294, model__max_delta_step=17, model__max_depth=17, model__min_child_weight=10, model__n_estimators=134, model__scale_pos_weight=38.40198305133798, model__subsample=0.7748467805582491, scale=passthrough, score=0.812, total=  28.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4511140442147604, model__colsample_bytree=0.9903547674262179, model__gamma=5, model__learning_rate=0.4551364817707272, model__max_delta_step=3, model__max_depth=9, model__min_child_weight=10, model__n_estimators=51, model__scale_pos_weight=686.3543271963737, model__subsample=0.9292339219363912, scale=passthrough 
[13:11:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4511140442147604, model__colsample_bytree=0.9903547674262179, model__gamma=5, model__learning_rate=0.4551364817707272, model__max_delta_step=3, model__max_depth=9, model__min_child_weight=10, model__n_estimators=51, model__scale_pos_weight=686.3543271963737, model__subsample=0.9292339219363912, scale=passthrough, score=0.821, total=   4.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2059973912347993, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07842903659436415, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=733.8385022788663, model__subsample=1.0, scale=passthrough 
[13:16:18] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2059973912347993, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07842903659436415, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=733.8385022788663, model__subsample=1.0, scale=passthrough, score=0.825, total=   8.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.31309620572574814, model__colsample_bytree=0.9460314608457268, model__gamma=2, model__learning_rate=0.05746414696295757, model__max_delta_step=16, model__max_depth=6, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=614.8716643477134, model__subsample=0.8367754740911908, scale=passthrough 
[13:20:52] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.31309620572574814, model__colsample_bytree=0.9460314608457268, model__gamma=2, model__learning_rate=0.05746414696295757, model__max_delta_step=16, model__max_depth=6, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=614.8716643477134, model__subsample=0.8367754740911908, scale=passthrough, score=0.812, total=   2.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2806112006438811, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.2451042114060229, model__max_delta_step=2, model__max_depth=3, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6786443757545222, scale=passthrough 
[13:25:26] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2806112006438811, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.2451042114060229, model__max_delta_step=2, model__max_depth=3, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6786443757545222, scale=passthrough, score=0.813, total=   3.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8496240201470282, model__colsample_bytree=0.9830777326171856, model__gamma=4, model__learning_rate=0.06874849914790944, model__max_delta_step=4, model__max_depth=12, model__min_child_weight=8, model__n_estimators=133, model__scale_pos_weight=8.080969479597385, model__subsample=0.537030103927309, scale=passthrough 
[12:39:25] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8496240201470282, model__colsample_bytree=0.9830777326171856, model__gamma=4, model__learning_rate=0.06874849914790944, model__max_delta_step=4, model__max_depth=12, model__min_child_weight=8, model__n_estimators=133, model__scale_pos_weight=8.080969479597385, model__subsample=0.537030103927309, scale=passthrough, score=0.816, total=  18.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5288586629520308, model__colsample_bytree=0.3, model__gamma=3, model__learning_rate=0.16432636056877883, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=5, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:41:23] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5288586629520308, model__colsample_bytree=0.3, model__gamma=3, model__learning_rate=0.16432636056877883, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=5, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.813, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5196344243152036, model__colsample_bytree=0.9624293710653027, model__gamma=1, model__learning_rate=0.046588484069784795, model__max_delta_step=15, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=31.748607485649025, model__subsample=1.0, scale=passthrough 
[12:44:39] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5196344243152036, model__colsample_bytree=0.9624293710653027, model__gamma=1, model__learning_rate=0.046588484069784795, model__max_delta_step=15, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=31.748607485649025, model__subsample=1.0, scale=passthrough, score=0.821, total=  13.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3446779503502123, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.18228125280787674, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=6.979894561096652, model__subsample=1.0, scale=passthrough 
[12:48:03] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3446779503502123, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.18228125280787674, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=6.979894561096652, model__subsample=1.0, scale=passthrough, score=0.811, total=   2.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.23083627991824782, model__colsample_bytree=0.41548787960338146, model__gamma=5, model__learning_rate=0.0981440649803512, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0295122186395866, model__subsample=0.7460870487526741, scale=passthrough 
[12:51:00] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.23083627991824782, model__colsample_bytree=0.41548787960338146, model__gamma=5, model__learning_rate=0.0981440649803512, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0295122186395866, model__subsample=0.7460870487526741, scale=passthrough, score=0.824, total=   6.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3559794222308732, model__colsample_bytree=0.38368467345407525, model__gamma=3, model__learning_rate=0.03568816551718303, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=795.2428424486291, model__subsample=0.5003519395379956, scale=passthrough 
[12:55:04] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3559794222308732, model__colsample_bytree=0.38368467345407525, model__gamma=3, model__learning_rate=0.03568816551718303, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=795.2428424486291, model__subsample=0.5003519395379956, scale=passthrough, score=0.804, total=   6.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.5403128228512762, model__gamma=1, model__learning_rate=0.06332776457703826, model__max_delta_step=17, model__max_depth=16, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=627.2845718396584, model__subsample=1.0, scale=passthrough 
[12:58:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.5403128228512762, model__gamma=1, model__learning_rate=0.06332776457703826, model__max_delta_step=17, model__max_depth=16, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=627.2845718396584, model__subsample=1.0, scale=passthrough, score=0.816, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=0.9498280409117508, model__gamma=2, model__learning_rate=1.0, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.7897702919913976, model__subsample=1.0, scale=passthrough 
[13:01:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=0.9498280409117508, model__gamma=2, model__learning_rate=1.0, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.7897702919913976, model__subsample=1.0, scale=passthrough, score=0.791, total=   0.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.37873309844010733, model__colsample_bytree=0.9278492397684184, model__gamma=2, model__learning_rate=0.03231204867296303, model__max_delta_step=19, model__max_depth=20, model__min_child_weight=10, model__n_estimators=145, model__scale_pos_weight=68.94834156267456, model__subsample=0.9248473167614011, scale=passthrough 
[13:04:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.37873309844010733, model__colsample_bytree=0.9278492397684184, model__gamma=2, model__learning_rate=0.03231204867296303, model__max_delta_step=19, model__max_depth=20, model__min_child_weight=10, model__n_estimators=145, model__scale_pos_weight=68.94834156267456, model__subsample=0.9248473167614011, scale=passthrough, score=0.816, total=  12.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6954617459256157, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08474569606546652, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=2.280597182116985, model__subsample=0.5936363540144308, scale=passthrough 
[13:08:21] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6954617459256157, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08474569606546652, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=2.280597182116985, model__subsample=0.5936363540144308, scale=passthrough, score=0.820, total=  22.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.859413033359576, model__colsample_bytree=0.6176696372925154, model__gamma=4, model__learning_rate=0.7945582762256038, model__max_delta_step=6, model__max_depth=3, model__min_child_weight=1, model__n_estimators=109, model__scale_pos_weight=4.57456444643311, model__subsample=0.9818856087025138, scale=passthrough 
[13:12:11] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.859413033359576, model__colsample_bytree=0.6176696372925154, model__gamma=4, model__learning_rate=0.7945582762256038, model__max_delta_step=6, model__max_depth=3, model__min_child_weight=1, model__n_estimators=109, model__scale_pos_weight=4.57456444643311, model__subsample=0.9818856087025138, scale=passthrough, score=0.805, total=   5.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2059973912347993, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07842903659436415, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=733.8385022788663, model__subsample=1.0, scale=passthrough 
[13:16:18] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2059973912347993, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07842903659436415, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=733.8385022788663, model__subsample=1.0, scale=passthrough, score=0.819, total=   7.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.31309620572574814, model__colsample_bytree=0.9460314608457268, model__gamma=2, model__learning_rate=0.05746414696295757, model__max_delta_step=16, model__max_depth=6, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=614.8716643477134, model__subsample=0.8367754740911908, scale=passthrough 
[13:20:52] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.31309620572574814, model__colsample_bytree=0.9460314608457268, model__gamma=2, model__learning_rate=0.05746414696295757, model__max_delta_step=16, model__max_depth=6, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=614.8716643477134, model__subsample=0.8367754740911908, scale=passthrough, score=0.811, total=   2.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2806112006438811, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.2451042114060229, model__max_delta_step=2, model__max_depth=3, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6786443757545222, scale=passthrough 
[13:25:26] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2806112006438811, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.2451042114060229, model__max_delta_step=2, model__max_depth=3, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6786443757545222, scale=passthrough, score=0.817, total=   3.6s
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   19.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   16.8s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2378981683448771, model__colsample_bytree=0.4246854599411771, model__gamma=3, model__learning_rate=0.5679480397376981, model__max_delta_step=13, model__max_depth=14, model__min_child_weight=9, model__n_estimators=89, model__scale_pos_weight=1.9808702709217594, model__subsample=0.637798907679531, scale=passthrough 
[12:40:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2378981683448771, model__colsample_bytree=0.4246854599411771, model__gamma=3, model__learning_rate=0.5679480397376981, model__max_delta_step=13, model__max_depth=14, model__min_child_weight=9, model__n_estimators=89, model__scale_pos_weight=1.9808702709217594, model__subsample=0.637798907679531, scale=passthrough, score=0.803, total=   3.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44570692226878567, model__colsample_bytree=0.9301667584195348, model__gamma=4, model__learning_rate=1.0, model__max_delta_step=14, model__max_depth=13, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=3.0252585215462067, model__subsample=0.948328801556569, scale=passthrough 
[12:42:29] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44570692226878567, model__colsample_bytree=0.9301667584195348, model__gamma=4, model__learning_rate=1.0, model__max_delta_step=14, model__max_depth=13, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=3.0252585215462067, model__subsample=0.948328801556569, scale=passthrough, score=0.791, total=  16.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6806280748235639, model__colsample_bytree=0.48764509248314014, model__gamma=5, model__learning_rate=0.09523406289357018, model__max_delta_step=0, model__max_depth=6, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:45:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6806280748235639, model__colsample_bytree=0.48764509248314014, model__gamma=5, model__learning_rate=0.09523406289357018, model__max_delta_step=0, model__max_depth=6, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.819, total=   6.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6675765153644005, model__colsample_bytree=0.5505381326437495, model__gamma=2, model__learning_rate=0.4094607061353391, model__max_delta_step=0, model__max_depth=10, model__min_child_weight=5, model__n_estimators=113, model__scale_pos_weight=37.34055062512279, model__subsample=1.0, scale=passthrough 
[12:49:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6675765153644005, model__colsample_bytree=0.5505381326437495, model__gamma=2, model__learning_rate=0.4094607061353391, model__max_delta_step=0, model__max_depth=10, model__min_child_weight=5, model__n_estimators=113, model__scale_pos_weight=37.34055062512279, model__subsample=1.0, scale=passthrough, score=0.817, total=   8.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4796817805920893, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.01470772226123463, model__max_delta_step=15, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:52:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4796817805920893, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.01470772226123463, model__max_delta_step=15, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.812, total=  30.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5323120346429068, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.955995972082883, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:56:06] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5323120346429068, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.955995972082883, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.799, total=   4.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8441827290623279, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08088260623930922, model__max_delta_step=20, model__max_depth=4, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7800718254694903, scale=passthrough 
[12:59:57] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8441827290623279, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08088260623930922, model__max_delta_step=20, model__max_depth=4, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7800718254694903, scale=passthrough, score=0.821, total=  13.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6509883200932527, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.18036595906132868, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7198184445399873, scale=passthrough 
[13:02:30] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6509883200932527, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.18036595906132868, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7198184445399873, scale=passthrough, score=0.825, total=   7.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8420342990824446, model__colsample_bytree=0.793823268897349, model__gamma=3, model__learning_rate=0.1494590893130938, model__max_delta_step=14, model__max_depth=4, model__min_child_weight=1, model__n_estimators=149, model__scale_pos_weight=182.2988537761414, model__subsample=0.7000085627096705, scale=passthrough 
[13:06:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8420342990824446, model__colsample_bytree=0.793823268897349, model__gamma=3, model__learning_rate=0.1494590893130938, model__max_delta_step=14, model__max_depth=4, model__min_child_weight=1, model__n_estimators=149, model__scale_pos_weight=182.2988537761414, model__subsample=0.7000085627096705, scale=passthrough, score=0.826, total=  10.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3610289879511644, model__colsample_bytree=0.8794040949446551, model__gamma=1, model__learning_rate=0.07114080874500128, model__max_delta_step=7, model__max_depth=3, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[13:10:01] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3610289879511644, model__colsample_bytree=0.8794040949446551, model__gamma=1, model__learning_rate=0.07114080874500128, model__max_delta_step=7, model__max_depth=3, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.822, total=   5.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6163527786738386, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10094658635968386, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1.142841169809037, model__subsample=0.66461683533738, scale=passthrough 
[13:13:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6163527786738386, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10094658635968386, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1.142841169809037, model__subsample=0.66461683533738, scale=passthrough, score=0.827, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.46476812763552044, model__colsample_bytree=0.4279578966612934, model__gamma=4, model__learning_rate=0.01095924342794842, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=2, model__n_estimators=140, model__scale_pos_weight=2.0466633977771815, model__subsample=0.47493466094751796, scale=passthrough 
[13:18:20] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.46476812763552044, model__colsample_bytree=0.4279578966612934, model__gamma=4, model__learning_rate=0.01095924342794842, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=2, model__n_estimators=140, model__scale_pos_weight=2.0466633977771815, model__subsample=0.47493466094751796, scale=passthrough, score=0.797, total=   7.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.15422998735889965, model__colsample_bytree=0.559080415297065, model__gamma=1, model__learning_rate=0.16521794081310845, model__max_delta_step=7, model__max_depth=16, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=658.1634602836999, model__subsample=1.0, scale=passthrough 
[13:22:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.15422998735889965, model__colsample_bytree=0.559080415297065, model__gamma=1, model__learning_rate=0.16521794081310845, model__max_delta_step=7, model__max_depth=16, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=658.1634602836999, model__subsample=1.0, scale=passthrough, score=0.816, total=   3.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3154486275030611, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.031577212450166446, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=384.50590738415696, model__subsample=1.0, scale=passthrough 
[13:28:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3154486275030611, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.031577212450166446, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=384.50590738415696, model__subsample=1.0, scale=passthrough, score=0.809, total=   4.4s
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   22.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.4s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   22.1s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.39232926160480097, model__gamma=1, model__learning_rate=1.0, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[12:40:44] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.39232926160480097, model__gamma=1, model__learning_rate=1.0, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.752, total=   1.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7765467128965023, model__colsample_bytree=0.47449772718627137, model__gamma=2, model__learning_rate=0.2169162634145997, model__max_delta_step=19, model__max_depth=20, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=9.675167622062212, model__subsample=0.90717348388679, scale=passthrough 
[12:42:48] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7765467128965023, model__colsample_bytree=0.47449772718627137, model__gamma=2, model__learning_rate=0.2169162634145997, model__max_delta_step=19, model__max_depth=20, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=9.675167622062212, model__subsample=0.90717348388679, scale=passthrough, score=0.815, total=  13.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6690442908198551, model__colsample_bytree=0.9611093825304611, model__gamma=2, model__learning_rate=0.010735390356849636, model__max_delta_step=9, model__max_depth=11, model__min_child_weight=3, model__n_estimators=68, model__scale_pos_weight=14.770406100341361, model__subsample=0.36808154547666466, scale=passthrough 
[12:45:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6690442908198551, model__colsample_bytree=0.9611093825304611, model__gamma=2, model__learning_rate=0.010735390356849636, model__max_delta_step=9, model__max_depth=11, model__min_child_weight=3, model__n_estimators=68, model__scale_pos_weight=14.770406100341361, model__subsample=0.36808154547666466, scale=passthrough, score=0.805, total=   6.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6586096224709334, model__colsample_bytree=0.3, model__gamma=4, model__learning_rate=0.06355706096516056, model__max_delta_step=1, model__max_depth=14, model__min_child_weight=10, model__n_estimators=55, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[12:49:25] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6586096224709334, model__colsample_bytree=0.3, model__gamma=4, model__learning_rate=0.06355706096516056, model__max_delta_step=1, model__max_depth=14, model__min_child_weight=10, model__n_estimators=55, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.807, total=   3.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.689713924422194, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.039397143036738566, model__max_delta_step=0, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:52:51] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.689713924422194, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.039397143036738566, model__max_delta_step=0, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.809, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.29504087950548863, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.2177922599853049, model__max_delta_step=20, model__max_depth=17, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=173.66523151392474, model__subsample=0.3, scale=passthrough 
[12:56:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.29504087950548863, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.2177922599853049, model__max_delta_step=20, model__max_depth=17, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=173.66523151392474, model__subsample=0.3, scale=passthrough, score=0.794, total=   2.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2212595747279, model__colsample_bytree=0.8456003131367817, model__gamma=4, model__learning_rate=0.18767576643234232, model__max_delta_step=12, model__max_depth=7, model__min_child_weight=9, model__n_estimators=143, model__scale_pos_weight=732.8868593669005, model__subsample=0.48737223244557426, scale=passthrough 
[13:00:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2212595747279, model__colsample_bytree=0.8456003131367817, model__gamma=4, model__learning_rate=0.18767576643234232, model__max_delta_step=12, model__max_depth=7, model__min_child_weight=9, model__n_estimators=143, model__scale_pos_weight=732.8868593669005, model__subsample=0.48737223244557426, scale=passthrough, score=0.814, total=   3.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6509883200932527, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.18036595906132868, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7198184445399873, scale=passthrough 
[13:02:30] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6509883200932527, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.18036595906132868, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7198184445399873, scale=passthrough, score=0.830, total=   7.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7975556755091645, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.23661077950939263, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=203.09690651748897, model__subsample=1.0, scale=passthrough 
[13:06:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7975556755091645, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.23661077950939263, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=203.09690651748897, model__subsample=1.0, scale=passthrough, score=0.820, total=  10.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2848417324417165, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.1595137567347673, model__max_delta_step=7, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[13:10:13] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2848417324417165, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.1595137567347673, model__max_delta_step=7, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.823, total=   4.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5283288332660206, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.14894535378591978, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8188083661080623, scale=passthrough 
[13:13:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5283288332660206, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.14894535378591978, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8188083661080623, scale=passthrough, score=0.823, total=   5.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2153599397239865, model__colsample_bytree=0.922078348309785, model__gamma=5, model__learning_rate=0.021479986135452957, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=5, model__n_estimators=56, model__scale_pos_weight=38.59487821201587, model__subsample=0.9605964562185123, scale=passthrough 
[13:18:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2153599397239865, model__colsample_bytree=0.922078348309785, model__gamma=5, model__learning_rate=0.021479986135452957, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=5, model__n_estimators=56, model__scale_pos_weight=38.59487821201587, model__subsample=0.9605964562185123, scale=passthrough, score=0.808, total=   3.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8491308316053338, model__colsample_bytree=0.9259115147228867, model__gamma=4, model__learning_rate=0.219537601255428, model__max_delta_step=15, model__max_depth=12, model__min_child_weight=8, model__n_estimators=53, model__scale_pos_weight=98.16359301666786, model__subsample=0.9909209199087825, scale=passthrough 
[13:23:15] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8491308316053338, model__colsample_bytree=0.9259115147228867, model__gamma=4, model__learning_rate=0.219537601255428, model__max_delta_step=15, model__max_depth=12, model__min_child_weight=8, model__n_estimators=53, model__scale_pos_weight=98.16359301666786, model__subsample=0.9909209199087825, scale=passthrough, score=0.819, total=  10.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3154486275030611, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.031577212450166446, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=384.50590738415696, model__subsample=1.0, scale=passthrough 
[13:28:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3154486275030611, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.031577212450166446, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=384.50590738415696, model__subsample=1.0, scale=passthrough, score=0.816, total=   4.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.011902017182026462, model__colsample_bytree=0.7873661660413364, model__gamma=3, model__learning_rate=0.015215020717305742, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=4, model__n_estimators=129, model__scale_pos_weight=28.52738776154143, model__subsample=0.7086817848712379, scale=passthrough 
[12:40:37] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.011902017182026462, model__colsample_bytree=0.7873661660413364, model__gamma=3, model__learning_rate=0.015215020717305742, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=4, model__n_estimators=129, model__scale_pos_weight=28.52738776154143, model__subsample=0.7086817848712379, scale=passthrough, score=0.741, total=   2.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44570692226878567, model__colsample_bytree=0.9301667584195348, model__gamma=4, model__learning_rate=1.0, model__max_delta_step=14, model__max_depth=13, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=3.0252585215462067, model__subsample=0.948328801556569, scale=passthrough 
[12:42:29] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44570692226878567, model__colsample_bytree=0.9301667584195348, model__gamma=4, model__learning_rate=1.0, model__max_delta_step=14, model__max_depth=13, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=3.0252585215462067, model__subsample=0.948328801556569, scale=passthrough, score=0.803, total=  16.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6690442908198551, model__colsample_bytree=0.9611093825304611, model__gamma=2, model__learning_rate=0.010735390356849636, model__max_delta_step=9, model__max_depth=11, model__min_child_weight=3, model__n_estimators=68, model__scale_pos_weight=14.770406100341361, model__subsample=0.36808154547666466, scale=passthrough 
[12:45:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6690442908198551, model__colsample_bytree=0.9611093825304611, model__gamma=2, model__learning_rate=0.010735390356849636, model__max_delta_step=9, model__max_depth=11, model__min_child_weight=3, model__n_estimators=68, model__scale_pos_weight=14.770406100341361, model__subsample=0.36808154547666466, scale=passthrough, score=0.801, total=   6.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6675765153644005, model__colsample_bytree=0.5505381326437495, model__gamma=2, model__learning_rate=0.4094607061353391, model__max_delta_step=0, model__max_depth=10, model__min_child_weight=5, model__n_estimators=113, model__scale_pos_weight=37.34055062512279, model__subsample=1.0, scale=passthrough 
[12:49:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6675765153644005, model__colsample_bytree=0.5505381326437495, model__gamma=2, model__learning_rate=0.4094607061353391, model__max_delta_step=0, model__max_depth=10, model__min_child_weight=5, model__n_estimators=113, model__scale_pos_weight=37.34055062512279, model__subsample=1.0, scale=passthrough, score=0.810, total=   8.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.689713924422194, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.039397143036738566, model__max_delta_step=0, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:52:51] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.689713924422194, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.039397143036738566, model__max_delta_step=0, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.785, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8328798665656025, model__colsample_bytree=0.8641530432628106, model__gamma=5, model__learning_rate=0.18180439867552042, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.7641293579113424, model__subsample=0.7529559001830912, scale=passthrough 
[12:56:15] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8328798665656025, model__colsample_bytree=0.8641530432628106, model__gamma=5, model__learning_rate=0.18180439867552042, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.7641293579113424, model__subsample=0.7529559001830912, scale=passthrough, score=0.811, total=  34.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8441827290623279, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08088260623930922, model__max_delta_step=20, model__max_depth=4, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7800718254694903, scale=passthrough 
[12:59:57] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8441827290623279, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08088260623930922, model__max_delta_step=20, model__max_depth=4, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7800718254694903, scale=passthrough, score=0.818, total=  13.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.484080037051211, model__colsample_bytree=0.9181123691412922, model__gamma=4, model__learning_rate=0.01, model__max_delta_step=10, model__max_depth=16, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=1.546040733397408, model__subsample=0.3, scale=passthrough 
[13:02:21] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.484080037051211, model__colsample_bytree=0.9181123691412922, model__gamma=4, model__learning_rate=0.01, model__max_delta_step=10, model__max_depth=16, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=1.546040733397408, model__subsample=0.3, scale=passthrough, score=0.808, total=   3.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8420342990824446, model__colsample_bytree=0.793823268897349, model__gamma=3, model__learning_rate=0.1494590893130938, model__max_delta_step=14, model__max_depth=4, model__min_child_weight=1, model__n_estimators=149, model__scale_pos_weight=182.2988537761414, model__subsample=0.7000085627096705, scale=passthrough 
[13:06:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8420342990824446, model__colsample_bytree=0.793823268897349, model__gamma=3, model__learning_rate=0.1494590893130938, model__max_delta_step=14, model__max_depth=4, model__min_child_weight=1, model__n_estimators=149, model__scale_pos_weight=182.2988537761414, model__subsample=0.7000085627096705, scale=passthrough, score=0.819, total=  10.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2848417324417165, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.1595137567347673, model__max_delta_step=7, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[13:10:13] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2848417324417165, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.1595137567347673, model__max_delta_step=7, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.818, total=   4.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7793269398106947, model__colsample_bytree=0.8460423420685759, model__gamma=4, model__learning_rate=0.4520210689634202, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=1, model__n_estimators=63, model__scale_pos_weight=11.716568798360003, model__subsample=0.8782649268360583, scale=passthrough 
[13:13:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7793269398106947, model__colsample_bytree=0.8460423420685759, model__gamma=4, model__learning_rate=0.4520210689634202, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=1, model__n_estimators=63, model__scale_pos_weight=11.716568798360003, model__subsample=0.8782649268360583, scale=passthrough, score=0.802, total=  15.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2153599397239865, model__colsample_bytree=0.922078348309785, model__gamma=5, model__learning_rate=0.021479986135452957, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=5, model__n_estimators=56, model__scale_pos_weight=38.59487821201587, model__subsample=0.9605964562185123, scale=passthrough 
[13:18:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2153599397239865, model__colsample_bytree=0.922078348309785, model__gamma=5, model__learning_rate=0.021479986135452957, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=5, model__n_estimators=56, model__scale_pos_weight=38.59487821201587, model__subsample=0.9605964562185123, scale=passthrough, score=0.808, total=   3.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8491308316053338, model__colsample_bytree=0.9259115147228867, model__gamma=4, model__learning_rate=0.219537601255428, model__max_delta_step=15, model__max_depth=12, model__min_child_weight=8, model__n_estimators=53, model__scale_pos_weight=98.16359301666786, model__subsample=0.9909209199087825, scale=passthrough 
[13:23:15] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8491308316053338, model__colsample_bytree=0.9259115147228867, model__gamma=4, model__learning_rate=0.219537601255428, model__max_delta_step=15, model__max_depth=12, model__min_child_weight=8, model__n_estimators=53, model__scale_pos_weight=98.16359301666786, model__subsample=0.9909209199087825, scale=passthrough, score=0.818, total=  10.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3154486275030611, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.031577212450166446, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=384.50590738415696, model__subsample=1.0, scale=passthrough 
[13:28:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3154486275030611, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.031577212450166446, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=384.50590738415696, model__subsample=1.0, scale=passthrough, score=0.811, total=   4.6s
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.2s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6565466212924355, model__colsample_bytree=0.735357685288236, model__gamma=2, model__learning_rate=0.04957929129543922, model__max_delta_step=15, model__max_depth=8, model__min_child_weight=4, model__n_estimators=78, model__scale_pos_weight=23.24113601995236, model__subsample=0.3610574395015852, scale=passthrough 
[12:39:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6565466212924355, model__colsample_bytree=0.735357685288236, model__gamma=2, model__learning_rate=0.04957929129543922, model__max_delta_step=15, model__max_depth=8, model__min_child_weight=4, model__n_estimators=78, model__scale_pos_weight=23.24113601995236, model__subsample=0.3610574395015852, scale=passthrough, score=0.812, total=   5.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3877751846015693, model__colsample_bytree=0.3756560342002999, model__gamma=1, model__learning_rate=0.09924153138966316, model__max_delta_step=16, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=4.88715669317987, model__subsample=0.4833253110046396, scale=passthrough 
[12:41:19] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3877751846015693, model__colsample_bytree=0.3756560342002999, model__gamma=1, model__learning_rate=0.09924153138966316, model__max_delta_step=16, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=4.88715669317987, model__subsample=0.4833253110046396, scale=passthrough, score=0.811, total=   1.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.17501511587798843, model__colsample_bytree=0.688339167996399, model__gamma=4, model__learning_rate=0.14555030812967049, model__max_delta_step=19, model__max_depth=15, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1.5505401377102335, model__subsample=1.0, scale=passthrough 
[12:44:29] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.17501511587798843, model__colsample_bytree=0.688339167996399, model__gamma=4, model__learning_rate=0.14555030812967049, model__max_delta_step=19, model__max_depth=15, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1.5505401377102335, model__subsample=1.0, scale=passthrough, score=0.814, total=   7.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5986048699610145, model__colsample_bytree=0.7206152207911285, model__gamma=1, model__learning_rate=0.030273563622536564, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=9, model__n_estimators=50, model__scale_pos_weight=953.4397812625493, model__subsample=1.0, scale=passthrough 
[12:47:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5986048699610145, model__colsample_bytree=0.7206152207911285, model__gamma=1, model__learning_rate=0.030273563622536564, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=9, model__n_estimators=50, model__scale_pos_weight=953.4397812625493, model__subsample=1.0, scale=passthrough, score=0.809, total=   5.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.23083627991824782, model__colsample_bytree=0.41548787960338146, model__gamma=5, model__learning_rate=0.0981440649803512, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0295122186395866, model__subsample=0.7460870487526741, scale=passthrough 
[12:51:00] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.23083627991824782, model__colsample_bytree=0.41548787960338146, model__gamma=5, model__learning_rate=0.0981440649803512, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0295122186395866, model__subsample=0.7460870487526741, scale=passthrough, score=0.808, total=   6.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9098253164362686, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.2593988949894903, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=4.418766958765141, model__subsample=1.0, scale=passthrough 
[12:54:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9098253164362686, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.2593988949894903, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=4.418766958765141, model__subsample=1.0, scale=passthrough, score=0.809, total=   4.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.028930220462137776, model__max_delta_step=13, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:58:12] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.028930220462137776, model__max_delta_step=13, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.816, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8700241242535257, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1077293607590322, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=100, model__scale_pos_weight=1.0, model__subsample=0.8512232839810878, scale=passthrough 
[13:01:12] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8700241242535257, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1077293607590322, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=100, model__scale_pos_weight=1.0, model__subsample=0.8512232839810878, scale=passthrough, score=0.819, total=  17.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7723746868256385, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=9.000308447877524, model__subsample=0.3, scale=passthrough 
[13:04:18] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7723746868256385, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=9.000308447877524, model__subsample=0.3, scale=passthrough, score=0.811, total=  18.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9973377829752199, model__colsample_bytree=0.9869839643094087, model__gamma=4, model__learning_rate=0.025409003650511294, model__max_delta_step=17, model__max_depth=17, model__min_child_weight=10, model__n_estimators=134, model__scale_pos_weight=38.40198305133798, model__subsample=0.7748467805582491, scale=passthrough 
[13:07:46] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9973377829752199, model__colsample_bytree=0.9869839643094087, model__gamma=4, model__learning_rate=0.025409003650511294, model__max_delta_step=17, model__max_depth=17, model__min_child_weight=10, model__n_estimators=134, model__scale_pos_weight=38.40198305133798, model__subsample=0.7748467805582491, scale=passthrough, score=0.817, total=  27.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4511140442147604, model__colsample_bytree=0.9903547674262179, model__gamma=5, model__learning_rate=0.4551364817707272, model__max_delta_step=3, model__max_depth=9, model__min_child_weight=10, model__n_estimators=51, model__scale_pos_weight=686.3543271963737, model__subsample=0.9292339219363912, scale=passthrough 
[13:11:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4511140442147604, model__colsample_bytree=0.9903547674262179, model__gamma=5, model__learning_rate=0.4551364817707272, model__max_delta_step=3, model__max_depth=9, model__min_child_weight=10, model__n_estimators=51, model__scale_pos_weight=686.3543271963737, model__subsample=0.9292339219363912, scale=passthrough, score=0.811, total=   4.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8734254422828995, model__colsample_bytree=0.9509562517823495, model__gamma=2, model__learning_rate=0.010287031832540747, model__max_delta_step=3, model__max_depth=18, model__min_child_weight=2, model__n_estimators=137, model__scale_pos_weight=3.717320547813186, model__subsample=0.5853514305903059, scale=passthrough 
[13:15:40] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8734254422828995, model__colsample_bytree=0.9509562517823495, model__gamma=2, model__learning_rate=0.010287031832540747, model__max_delta_step=3, model__max_depth=18, model__min_child_weight=2, model__n_estimators=137, model__scale_pos_weight=3.717320547813186, model__subsample=0.5853514305903059, scale=passthrough, score=0.807, total=  30.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6788578084180311, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10510529783124824, model__max_delta_step=0, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.712108015281221, scale=passthrough 
[13:20:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6788578084180311, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10510529783124824, model__max_delta_step=0, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.712108015281221, scale=passthrough, score=0.825, total=  12.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9001342684252364, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.054251822511365205, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7348745960658764, scale=passthrough 
[13:25:05] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9001342684252364, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.054251822511365205, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7348745960658764, scale=passthrough, score=0.824, total=   8.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6683160421947889, model__colsample_bytree=0.8777316471202263, model__gamma=2, model__learning_rate=0.03873852470666852, model__max_delta_step=6, model__max_depth=4, model__min_child_weight=1, model__n_estimators=137, model__scale_pos_weight=3.7995034600209316, model__subsample=0.31696593658678845, scale=passthrough 
[13:30:11] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6683160421947889, model__colsample_bytree=0.8777316471202263, model__gamma=2, model__learning_rate=0.03873852470666852, model__max_delta_step=6, model__max_depth=4, model__min_child_weight=1, model__n_estimators=137, model__scale_pos_weight=3.7995034600209316, model__subsample=0.31696593658678845, scale=passthrough, score=0.824, total=   5.6s
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[13:35:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


Done in 3411.545s

Best f1_micro score:  0.826656243892906
Best parameters set: OrderedDict([('model', XGBClassifier(base_score=0.5, booster='gbtree',
              colsample_bylevel=0.8668701895013304, colsample_bynode=1,
              colsample_bytree=1.0,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'ext...
              interaction_constraints='', learning_rate=0.12492801938016393,
              max_delta_step=0, max_depth=8, min_child_weight=10, missing=nan,
              monotone_constraints='()', n_estimators=150, n_jobs=0,
              num_parallel_tree=1, objective='multi:softprob', random_state=0,
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1.0,
              subsample=0.871625599700572, tree_method='exact',
              validate_parameters=1, verbosity=None)), ('model__colsample_bylevel', 0.8668701895013304), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.12492801938016393), ('model__max_delta_step', 0), ('model__max_depth', 8), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.871625599700572), ('scale', 'passthrough')])

Grid scores on development set:

0.805 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8956598812561088), ('model__colsample_bytree', 0.6432413582312556), ('model__gamma', 2), ('model__learning_rate', 0.47950224134277997), ('model__max_delta_step', 9), ('model__max_depth', 11), ('model__min_child_weight', 8), ('model__n_estimators', 129), ('model__scale_pos_weight', 16.340094294903054), ('model__subsample', 0.7395710203466399), ('scale', 'passthrough')])
0.816 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.21116703221890631), ('model__colsample_bytree', 0.819317800389112), ('model__gamma', 3), ('model__learning_rate', 0.20579929372020303), ('model__max_delta_step', 12), ('model__max_depth', 14), ('model__min_child_weight', 5), ('model__n_estimators', 65), ('model__scale_pos_weight', 597.6163936494521), ('model__subsample', 0.7932909428145046), ('scale', 'passthrough')])
0.817 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6565466212924355), ('model__colsample_bytree', 0.735357685288236), ('model__gamma', 2), ('model__learning_rate', 0.04957929129543922), ('model__max_delta_step', 15), ('model__max_depth', 8), ('model__min_child_weight', 4), ('model__n_estimators', 78), ('model__scale_pos_weight', 23.24113601995236), ('model__subsample', 0.3610574395015852), ('scale', 'passthrough')])
0.818 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8496240201470282), ('model__colsample_bytree', 0.9830777326171856), ('model__gamma', 4), ('model__learning_rate', 0.06874849914790944), ('model__max_delta_step', 4), ('model__max_depth', 12), ('model__min_child_weight', 8), ('model__n_estimators', 133), ('model__scale_pos_weight', 8.080969479597385), ('model__subsample', 0.537030103927309), ('scale', 'passthrough')])
0.799 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.036013135558974105), ('model__colsample_bytree', 0.6770798813716852), ('model__gamma', 1), ('model__learning_rate', 0.35384207897748293), ('model__max_delta_step', 7), ('model__max_depth', 14), ('model__min_child_weight', 4), ('model__n_estimators', 141), ('model__scale_pos_weight', 13.587798533272867), ('model__subsample', 0.7134838459802921), ('scale', 'passthrough')])
0.814 (+/-0.021) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5078988934265182), ('model__colsample_bytree', 0.8346246633266341), ('model__gamma', 4), ('model__learning_rate', 0.43750217377340134), ('model__max_delta_step', 2), ('model__max_depth', 13), ('model__min_child_weight', 4), ('model__n_estimators', 53), ('model__scale_pos_weight', 7.209798890237415), ('model__subsample', 0.6639515335369921), ('scale', 'passthrough')])
0.808 (+/-0.003) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.787035117607132), ('model__colsample_bytree', 0.7112453824126441), ('model__gamma', 4), ('model__learning_rate', 0.02079837150135237), ('model__max_delta_step', 18), ('model__max_depth', 20), ('model__min_child_weight', 4), ('model__n_estimators', 78), ('model__scale_pos_weight', 249.52308451288775), ('model__subsample', 0.9976698378005269), ('scale', 'passthrough')])
0.817 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.804000760089205), ('model__colsample_bytree', 0.87439356412997), ('model__gamma', 2), ('model__learning_rate', 0.09724451331363028), ('model__max_delta_step', 8), ('model__max_depth', 12), ('model__min_child_weight', 5), ('model__n_estimators', 91), ('model__scale_pos_weight', 8.712236078372266), ('model__subsample', 0.5590460523937827), ('scale', 'passthrough')])
0.798 (+/-0.022) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2378981683448771), ('model__colsample_bytree', 0.4246854599411771), ('model__gamma', 3), ('model__learning_rate', 0.5679480397376981), ('model__max_delta_step', 13), ('model__max_depth', 14), ('model__min_child_weight', 9), ('model__n_estimators', 89), ('model__scale_pos_weight', 1.9808702709217594), ('model__subsample', 0.637798907679531), ('scale', 'passthrough')])
0.739 (+/-0.042) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.011902017182026462), ('model__colsample_bytree', 0.7873661660413364), ('model__gamma', 3), ('model__learning_rate', 0.015215020717305742), ('model__max_delta_step', 20), ('model__max_depth', 11), ('model__min_child_weight', 4), ('model__n_estimators', 129), ('model__scale_pos_weight', 28.52738776154143), ('model__subsample', 0.7086817848712379), ('scale', 'passthrough')])
0.750 (+/-0.004) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 0.39232926160480097), ('model__gamma', 1), ('model__learning_rate', 1.0), ('model__max_delta_step', 15), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 50), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.814 (+/-0.012) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5912298436097947), ('model__colsample_bytree', 1.0), ('model__gamma', 5), ('model__learning_rate', 0.2372450606441309), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 50), ('model__scale_pos_weight', 184.62872204248956), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.815 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6582926807483003), ('model__colsample_bytree', 0.3), ('model__gamma', 5), ('model__learning_rate', 0.2482871564923991), ('model__max_delta_step', 14), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 61), ('model__scale_pos_weight', 882.6450983940014), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.798 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 0.8835222719721867), ('model__gamma', 3), ('model__learning_rate', 0.01), ('model__max_delta_step', 17), ('model__max_depth', 20), ('model__min_child_weight', 7), ('model__n_estimators', 80), ('model__scale_pos_weight', 24.931036467252635), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.771 (+/-0.030) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.01), ('model__colsample_bytree', 0.3), ('model__gamma', 5), ('model__learning_rate', 0.09212493376669943), ('model__max_delta_step', 20), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 278.87157613599607), ('model__subsample', 0.46981062344447505), ('scale', 'passthrough')])
0.808 (+/-0.014) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3877751846015693), ('model__colsample_bytree', 0.3756560342002999), ('model__gamma', 1), ('model__learning_rate', 0.09924153138966316), ('model__max_delta_step', 16), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 50), ('model__scale_pos_weight', 4.88715669317987), ('model__subsample', 0.4833253110046396), ('scale', 'passthrough')])
0.810 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5288586629520308), ('model__colsample_bytree', 0.3), ('model__gamma', 3), ('model__learning_rate', 0.16432636056877883), ('model__max_delta_step', 7), ('model__max_depth', 20), ('model__min_child_weight', 5), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.806 (+/-0.014) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.1420774216790083), ('model__colsample_bytree', 1.0), ('model__gamma', 4), ('model__learning_rate', 0.4509992641426783), ('model__max_delta_step', 0), ('model__max_depth', 20), ('model__min_child_weight', 8), ('model__n_estimators', 50), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.8623998033233848), ('scale', 'passthrough')])
0.797 (+/-0.018) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 0.3), ('model__gamma', 1), ('model__learning_rate', 0.04051980750184009), ('model__max_delta_step', 15), ('model__max_depth', 20), ('model__min_child_weight', 5), ('model__n_estimators', 50), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.816 (+/-0.003) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9985235150787968), ('model__colsample_bytree', 1.0), ('model__gamma', 5), ('model__learning_rate', 0.18558997178831976), ('model__max_delta_step', 0), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 71.9368373769291), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.775 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6372693350745634), ('model__colsample_bytree', 0.856279090521453), ('model__gamma', 4), ('model__learning_rate', 0.01), ('model__max_delta_step', 14), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.815 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5463605528721855), ('model__colsample_bytree', 0.7118040938283031), ('model__gamma', 5), ('model__learning_rate', 0.16951716523028687), ('model__max_delta_step', 6), ('model__max_depth', 14), ('model__min_child_weight', 3), ('model__n_estimators', 93), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.7509140215242676), ('scale', 'passthrough')])
0.799 (+/-0.012) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.44570692226878567), ('model__colsample_bytree', 0.9301667584195348), ('model__gamma', 4), ('model__learning_rate', 1.0), ('model__max_delta_step', 14), ('model__max_depth', 13), ('model__min_child_weight', 4), ('model__n_estimators', 150), ('model__scale_pos_weight', 3.0252585215462067), ('model__subsample', 0.948328801556569), ('scale', 'passthrough')])
0.819 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7765467128965023), ('model__colsample_bytree', 0.47449772718627137), ('model__gamma', 2), ('model__learning_rate', 0.2169162634145997), ('model__max_delta_step', 19), ('model__max_depth', 20), ('model__min_child_weight', 7), ('model__n_estimators', 150), ('model__scale_pos_weight', 9.675167622062212), ('model__subsample', 0.90717348388679), ('scale', 'passthrough')])
0.800 (+/-0.015) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.625380306995069), ('model__colsample_bytree', 0.8514283442895596), ('model__gamma', 5), ('model__learning_rate', 0.41910787084766915), ('model__max_delta_step', 18), ('model__max_depth', 20), ('model__min_child_weight', 8), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.40915009963638754), ('scale', 'passthrough')])
0.816 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9120957067510712), ('model__colsample_bytree', 0.5976528037728883), ('model__gamma', 1), ('model__learning_rate', 0.12761761072761757), ('model__max_delta_step', 20), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 2.0000521908976103), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.790 (+/-0.003) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 1.0), ('model__gamma', 5), ('model__learning_rate', 0.01), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.820 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6731793514102031), ('model__colsample_bytree', 0.6363610788977796), ('model__gamma', 3), ('model__learning_rate', 0.06654762391643661), ('model__max_delta_step', 6), ('model__max_depth', 19), ('model__min_child_weight', 7), ('model__n_estimators', 150), ('model__scale_pos_weight', 4.459684760380094), ('model__subsample', 0.699457292016114), ('scale', 'passthrough')])
0.815 (+/-0.012) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8067700059239111), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.0386039068194868), ('model__max_delta_step', 0), ('model__max_depth', 15), ('model__min_child_weight', 3), ('model__n_estimators', 50), ('model__scale_pos_weight', 1.0841388341722655), ('model__subsample', 0.693493293070414), ('scale', 'passthrough')])
0.818 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.17501511587798843), ('model__colsample_bytree', 0.688339167996399), ('model__gamma', 4), ('model__learning_rate', 0.14555030812967049), ('model__max_delta_step', 19), ('model__max_depth', 15), ('model__min_child_weight', 2), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.5505401377102335), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.818 (+/-0.004) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5196344243152036), ('model__colsample_bytree', 0.9624293710653027), ('model__gamma', 1), ('model__learning_rate', 0.046588484069784795), ('model__max_delta_step', 15), ('model__max_depth', 7), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 31.748607485649025), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.810 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.30473733141436166), ('model__colsample_bytree', 0.3), ('model__gamma', 1), ('model__learning_rate', 0.26300031954289427), ('model__max_delta_step', 18), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.791 (+/-0.004) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 1.0), ('model__gamma', 5), ('model__learning_rate', 1.0), ('model__max_delta_step', 0), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 51), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.816 (+/-0.012) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7209883604008371), ('model__colsample_bytree', 1.0), ('model__gamma', 5), ('model__learning_rate', 0.05711622673001165), ('model__max_delta_step', 0), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.749 (+/-0.022) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.01), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.1581960850027507), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 2), ('model__n_estimators', 50), ('model__scale_pos_weight', 9.047961657876439), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.816 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6806280748235639), ('model__colsample_bytree', 0.48764509248314014), ('model__gamma', 5), ('model__learning_rate', 0.09523406289357018), ('model__max_delta_step', 0), ('model__max_depth', 6), ('model__min_child_weight', 10), ('model__n_estimators', 148), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.805 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6690442908198551), ('model__colsample_bytree', 0.9611093825304611), ('model__gamma', 2), ('model__learning_rate', 0.010735390356849636), ('model__max_delta_step', 9), ('model__max_depth', 11), ('model__min_child_weight', 3), ('model__n_estimators', 68), ('model__scale_pos_weight', 14.770406100341361), ('model__subsample', 0.36808154547666466), ('scale', 'passthrough')])
0.819 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5319250256040385), ('model__colsample_bytree', 0.5421940677812587), ('model__gamma', 4), ('model__learning_rate', 0.041051773959994736), ('model__max_delta_step', 20), ('model__max_depth', 14), ('model__min_child_weight', 6), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.813 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.4519864554659911), ('model__colsample_bytree', 0.8366425105706587), ('model__gamma', 5), ('model__learning_rate', 0.18683460622727016), ('model__max_delta_step', 9), ('model__max_depth', 8), ('model__min_child_weight', 1), ('model__n_estimators', 107), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.814 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.06348571978562509), ('model__max_delta_step', 20), ('model__max_depth', 6), ('model__min_child_weight', 1), ('model__n_estimators', 134), ('model__scale_pos_weight', 56.24623518863065), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.805 (+/-0.016) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.4201453433278661), ('model__colsample_bytree', 0.6602346245231958), ('model__gamma', 5), ('model__learning_rate', 0.01), ('model__max_delta_step', 18), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 50), ('model__scale_pos_weight', 4.536038333596355), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.812 (+/-0.004) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.1534871991399859), ('model__max_delta_step', 20), ('model__max_depth', 14), ('model__min_child_weight', 1), ('model__n_estimators', 117), ('model__scale_pos_weight', 6.455106843288009), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.812 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5986048699610145), ('model__colsample_bytree', 0.7206152207911285), ('model__gamma', 1), ('model__learning_rate', 0.030273563622536564), ('model__max_delta_step', 0), ('model__max_depth', 20), ('model__min_child_weight', 9), ('model__n_estimators', 50), ('model__scale_pos_weight', 953.4397812625493), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.813 (+/-0.004) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3446779503502123), ('model__colsample_bytree', 0.3), ('model__gamma', 1), ('model__learning_rate', 0.18228125280787674), ('model__max_delta_step', 0), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 50), ('model__scale_pos_weight', 6.979894561096652), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.819 (+/-0.002) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.30710558780986585), ('model__colsample_bytree', 0.7451117847409254), ('model__gamma', 4), ('model__learning_rate', 0.03979965805844932), ('model__max_delta_step', 1), ('model__max_depth', 20), ('model__min_child_weight', 3), ('model__n_estimators', 150), ('model__scale_pos_weight', 73.2857211995429), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.814 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.23848993246804506), ('model__colsample_bytree', 0.9097869239684406), ('model__gamma', 3), ('model__learning_rate', 0.07521545489840264), ('model__max_delta_step', 6), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 14.096088207945458), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.816 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.33817897669411146), ('model__colsample_bytree', 1.0), ('model__gamma', 2), ('model__learning_rate', 0.1062929550762915), ('model__max_delta_step', 0), ('model__max_depth', 17), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.805 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5506653020270686), ('model__colsample_bytree', 0.9878808042703486), ('model__gamma', 1), ('model__learning_rate', 0.9418344688387262), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 149), ('model__scale_pos_weight', 3.118852246044101), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.814 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3487729741375725), ('model__colsample_bytree', 0.9093771692550638), ('model__gamma', 4), ('model__learning_rate', 0.03255609651115708), ('model__max_delta_step', 0), ('model__max_depth', 12), ('model__min_child_weight', 1), ('model__n_estimators', 87), ('model__scale_pos_weight', 57.66714231001726), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.814 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6675765153644005), ('model__colsample_bytree', 0.5505381326437495), ('model__gamma', 2), ('model__learning_rate', 0.4094607061353391), ('model__max_delta_step', 0), ('model__max_depth', 10), ('model__min_child_weight', 5), ('model__n_estimators', 113), ('model__scale_pos_weight', 37.34055062512279), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.812 (+/-0.013) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6586096224709334), ('model__colsample_bytree', 0.3), ('model__gamma', 4), ('model__learning_rate', 0.06355706096516056), ('model__max_delta_step', 1), ('model__max_depth', 14), ('model__min_child_weight', 10), ('model__n_estimators', 55), ('model__scale_pos_weight', 1000.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.808 (+/-0.017) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8567412002271322), ('model__colsample_bytree', 0.8575671103085107), ('model__gamma', 2), ('model__learning_rate', 0.07465261039980901), ('model__max_delta_step', 18), ('model__max_depth', 3), ('model__min_child_weight', 9), ('model__n_estimators', 107), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.816 (+/-0.016) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.19204835502229126), ('model__colsample_bytree', 0.9762399643818847), ('model__gamma', 3), ('model__learning_rate', 0.248985809110902), ('model__max_delta_step', 1), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.818 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8106827059215695), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.027779855529191815), ('model__max_delta_step', 1), ('model__max_depth', 10), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.636469752338156), ('scale', 'passthrough')])
0.734 (+/-0.013) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.03288580264204534), ('model__colsample_bytree', 0.5478144161532192), ('model__gamma', 4), ('model__learning_rate', 1.0), ('model__max_delta_step', 14), ('model__max_depth', 20), ('model__min_child_weight', 4), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.820 (+/-0.013) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6883518065722666), ('model__colsample_bytree', 1.0), ('model__gamma', 3), ('model__learning_rate', 0.04130579513609374), ('model__max_delta_step', 20), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.5103962518485224), ('scale', 'passthrough')])
0.816 (+/-0.013) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.23083627991824782), ('model__colsample_bytree', 0.41548787960338146), ('model__gamma', 5), ('model__learning_rate', 0.0981440649803512), ('model__max_delta_step', 20), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0295122186395866), ('model__subsample', 0.7460870487526741), ('scale', 'passthrough')])
0.814 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.415790734612201), ('model__colsample_bytree', 0.6845964052587015), ('model__gamma', 1), ('model__learning_rate', 0.020308990155481214), ('model__max_delta_step', 0), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 14.718278134971332), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.816 (+/-0.004) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.4561709681306783), ('model__colsample_bytree', 1.0), ('model__gamma', 3), ('model__learning_rate', 0.05744678535505964), ('model__max_delta_step', 8), ('model__max_depth', 14), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.30013062014501), ('scale', 'passthrough')])
0.816 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.54122389035169), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.42272303291809443), ('model__max_delta_step', 20), ('model__max_depth', 7), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.807 (+/-0.019) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5800812255247891), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.22521631668826875), ('model__max_delta_step', 0), ('model__max_depth', 4), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 599.6975396467072), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.809 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.773545840828518), ('model__colsample_bytree', 1.0), ('model__gamma', 5), ('model__learning_rate', 0.11718196680162268), ('model__max_delta_step', 0), ('model__max_depth', 20), ('model__min_child_weight', 2), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.809 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.4796817805920893), ('model__colsample_bytree', 1.0), ('model__gamma', 5), ('model__learning_rate', 0.01470772226123463), ('model__max_delta_step', 15), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.804 (+/-0.027) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.689713924422194), ('model__colsample_bytree', 0.3), ('model__gamma', 1), ('model__learning_rate', 0.039397143036738566), ('model__max_delta_step', 0), ('model__max_depth', 14), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.820 (+/-0.015) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7327427198317836), ('model__colsample_bytree', 1.0), ('model__gamma', 5), ('model__learning_rate', 0.05318619770853978), ('model__max_delta_step', 20), ('model__max_depth', 5), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.6714582277622831), ('scale', 'passthrough')])
0.801 (+/-0.015) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.33427716540771224), ('model__colsample_bytree', 1.0), ('model__gamma', 3), ('model__learning_rate', 0.02433661877263249), ('model__max_delta_step', 6), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 50), ('model__scale_pos_weight', 14.638697274418845), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.816 (+/-0.014) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6476297636717281), ('model__colsample_bytree', 1.0), ('model__gamma', 2), ('model__learning_rate', 0.032733906308545044), ('model__max_delta_step', 20), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 50), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.5768325263639889), ('scale', 'passthrough')])
0.817 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6116986539206163), ('model__colsample_bytree', 0.8566999167764007), ('model__gamma', 1), ('model__learning_rate', 0.04296027090185901), ('model__max_delta_step', 0), ('model__max_depth', 12), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.817 (+/-0.014) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 1.0), ('model__gamma', 4), ('model__learning_rate', 0.07004251820541824), ('model__max_delta_step', 20), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.7625147925681803), ('scale', 'passthrough')])
0.815 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9098253164362686), ('model__colsample_bytree', 1.0), ('model__gamma', 4), ('model__learning_rate', 0.2593988949894903), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 50), ('model__scale_pos_weight', 4.418766958765141), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.814 (+/-0.018) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3559794222308732), ('model__colsample_bytree', 0.38368467345407525), ('model__gamma', 3), ('model__learning_rate', 0.03568816551718303), ('model__max_delta_step', 7), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 795.2428424486291), ('model__subsample', 0.5003519395379956), ('scale', 'passthrough')])
0.806 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7936756256804407), ('model__colsample_bytree', 0.7257873766908297), ('model__gamma', 5), ('model__learning_rate', 0.030237589119733947), ('model__max_delta_step', 20), ('model__max_depth', 20), ('model__min_child_weight', 7), ('model__n_estimators', 50), ('model__scale_pos_weight', 47.39578121166871), ('model__subsample', 0.42602881074865684), ('scale', 'passthrough')])
0.820 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.596005016271846), ('model__colsample_bytree', 1.0), ('model__gamma', 3), ('model__learning_rate', 0.15313504883569234), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.6736223814213212), ('scale', 'passthrough')])
0.815 (+/-0.013) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3729531833425515), ('model__colsample_bytree', 1.0), ('model__gamma', 2), ('model__learning_rate', 0.1927833680266232), ('model__max_delta_step', 20), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.6966147668977061), ('scale', 'passthrough')])
0.814 (+/-0.015) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.17881855116962453), ('model__colsample_bytree', 0.9439760336166867), ('model__gamma', 1), ('model__learning_rate', 0.10711338444861279), ('model__max_delta_step', 0), ('model__max_depth', 16), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 16.736349345470014), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.803 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5323120346429068), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.955995972082883), ('model__max_delta_step', 20), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 50), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.816 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8328798665656025), ('model__colsample_bytree', 0.8641530432628106), ('model__gamma', 5), ('model__learning_rate', 0.18180439867552042), ('model__max_delta_step', 20), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.7641293579113424), ('model__subsample', 0.7529559001830912), ('scale', 'passthrough')])
0.806 (+/-0.020) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.29504087950548863), ('model__colsample_bytree', 1.0), ('model__gamma', 5), ('model__learning_rate', 0.2177922599853049), ('model__max_delta_step', 20), ('model__max_depth', 17), ('model__min_child_weight', 1), ('model__n_estimators', 50), ('model__scale_pos_weight', 173.66523151392474), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.816 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5018576187286898), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.028564295402751114), ('model__max_delta_step', 0), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 101), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.6459261463922767), ('scale', 'passthrough')])
0.820 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3850395588759831), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.26109741414365173), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 7), ('model__n_estimators', 50), ('model__scale_pos_weight', 1.0926202043666218), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.818 (+/-0.003) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.01), ('model__max_delta_step', 20), ('model__max_depth', 16), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 419.3974496621373), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.794 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.01), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.7643252963704794), ('scale', 'passthrough')])
0.810 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.028930220462137776), ('model__max_delta_step', 13), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.816 (+/-0.001) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 0.5403128228512762), ('model__gamma', 1), ('model__learning_rate', 0.06332776457703826), ('model__max_delta_step', 17), ('model__max_depth', 16), ('model__min_child_weight', 10), ('model__n_estimators', 50), ('model__scale_pos_weight', 627.2845718396584), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.822 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9252061892810777), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.07134063846005033), ('model__max_delta_step', 15), ('model__max_depth', 17), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.9024170930502224), ('scale', 'passthrough')])
0.820 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2626717566045728), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.061741286298299246), ('model__max_delta_step', 11), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.801 (+/-0.013) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.32620009304869785), ('model__colsample_bytree', 0.575801209690553), ('model__gamma', 5), ('model__learning_rate', 0.010375661400059702), ('model__max_delta_step', 7), ('model__max_depth', 10), ('model__min_child_weight', 10), ('model__n_estimators', 107), ('model__scale_pos_weight', 29.14660215561998), ('model__subsample', 0.8964223262021889), ('scale', 'passthrough')])
0.825 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8624028593474139), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.119961338472243), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.7712371023169001), ('scale', 'passthrough')])
0.823 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7480226532288533), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.14204556358464834), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.6743244476697982), ('scale', 'passthrough')])
0.822 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8441827290623279), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.08088260623930922), ('model__max_delta_step', 20), ('model__max_depth', 4), ('model__min_child_weight', 6), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.7800718254694903), ('scale', 'passthrough')])
0.814 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2212595747279), ('model__colsample_bytree', 0.8456003131367817), ('model__gamma', 4), ('model__learning_rate', 0.18767576643234232), ('model__max_delta_step', 12), ('model__max_depth', 7), ('model__min_child_weight', 9), ('model__n_estimators', 143), ('model__scale_pos_weight', 732.8868593669005), ('model__subsample', 0.48737223244557426), ('scale', 'passthrough')])
0.798 (+/-0.003) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9186093142414973), ('model__colsample_bytree', 0.3426101106885372), ('model__gamma', 2), ('model__learning_rate', 0.9814305978851464), ('model__max_delta_step', 11), ('model__max_depth', 15), ('model__min_child_weight', 10), ('model__n_estimators', 148), ('model__scale_pos_weight', 3.3351492261289715), ('model__subsample', 0.986860683696918), ('scale', 'passthrough')])
0.821 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9330712449712505), ('model__colsample_bytree', 0.3), ('model__gamma', 1), ('model__learning_rate', 0.11159539600064079), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.729062663586322), ('scale', 'passthrough')])
0.808 (+/-0.013) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3728573344531136), ('model__colsample_bytree', 0.996298705345964), ('model__gamma', 2), ('model__learning_rate', 0.8927049177339886), ('model__max_delta_step', 1), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 53), ('model__scale_pos_weight', 3.893877211807879), ('model__subsample', 0.9822400866927687), ('scale', 'passthrough')])
0.808 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8647304389121462), ('model__colsample_bytree', 0.5531570314461818), ('model__gamma', 3), ('model__learning_rate', 0.01029200788866549), ('model__max_delta_step', 18), ('model__max_depth', 11), ('model__min_child_weight', 1), ('model__n_estimators', 71), ('model__scale_pos_weight', 137.07094436479818), ('model__subsample', 0.34245761309552675), ('scale', 'passthrough')])
0.786 (+/-0.015) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.26523868268741607), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.01), ('model__max_delta_step', 15), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.817 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8700241242535257), ('model__colsample_bytree', 1.0), ('model__gamma', 2), ('model__learning_rate', 0.1077293607590322), ('model__max_delta_step', 20), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 100), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.8512232839810878), ('scale', 'passthrough')])
0.795 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.01), ('model__colsample_bytree', 0.9498280409117508), ('model__gamma', 2), ('model__learning_rate', 1.0), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.7897702919913976), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.814 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5843600897185549), ('model__colsample_bytree', 0.9430163495262514), ('model__gamma', 1), ('model__learning_rate', 0.1691671183377136), ('model__max_delta_step', 5), ('model__max_depth', 4), ('model__min_child_weight', 10), ('model__n_estimators', 51), ('model__scale_pos_weight', 960.7489282692309), ('model__subsample', 0.42952695098688654), ('scale', 'passthrough')])
0.813 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.13518078933230862), ('model__colsample_bytree', 0.7554546456232811), ('model__gamma', 4), ('model__learning_rate', 0.2447022723549562), ('model__max_delta_step', 15), ('model__max_depth', 3), ('model__min_child_weight', 9), ('model__n_estimators', 145), ('model__scale_pos_weight', 15.633109434047906), ('model__subsample', 0.8502072361448936), ('scale', 'passthrough')])
0.812 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7306643321598706), ('model__colsample_bytree', 0.9047106324665182), ('model__gamma', 3), ('model__learning_rate', 0.289680856607798), ('model__max_delta_step', 2), ('model__max_depth', 5), ('model__min_child_weight', 7), ('model__n_estimators', 50), ('model__scale_pos_weight', 4.830750396431991), ('model__subsample', 0.682152373341296), ('scale', 'passthrough')])
0.822 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6278104355427412), ('model__colsample_bytree', 0.9340618268551624), ('model__gamma', 1), ('model__learning_rate', 0.07795317314610904), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.5342704969018652), ('scale', 'passthrough')])
0.808 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.484080037051211), ('model__colsample_bytree', 0.9181123691412922), ('model__gamma', 4), ('model__learning_rate', 0.01), ('model__max_delta_step', 10), ('model__max_depth', 16), ('model__min_child_weight', 1), ('model__n_estimators', 50), ('model__scale_pos_weight', 1.546040733397408), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.824 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6509883200932527), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.18036595906132868), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.7198184445399873), ('scale', 'passthrough')])
0.826 (+/-0.002) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3144666704979742), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.15503232672208117), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 3), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.6954064460144382), ('scale', 'passthrough')])
0.822 (+/-0.012) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.35786876313122484), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.1400059167253532), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.804837633099327), ('scale', 'passthrough')])
0.774 (+/-0.014) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.605848784786007), ('model__colsample_bytree', 0.3030158208675209), ('model__gamma', 1), ('model__learning_rate', 0.016666545458275794), ('model__max_delta_step', 14), ('model__max_depth', 3), ('model__min_child_weight', 3), ('model__n_estimators', 59), ('model__scale_pos_weight', 57.48214623733764), ('model__subsample', 0.8271495199964074), ('scale', 'passthrough')])
0.796 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.01), ('model__max_delta_step', 0), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.809 (+/-0.017) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2926672548978454), ('model__colsample_bytree', 0.5867886522755954), ('model__gamma', 3), ('model__learning_rate', 0.086894693605999), ('model__max_delta_step', 1), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 119), ('model__scale_pos_weight', 4.783825724876682), ('model__subsample', 0.3041125013442748), ('scale', 'passthrough')])
0.817 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7723746868256385), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.01), ('model__max_delta_step', 6), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 9.000308447877524), ('model__subsample', 0.3), ('scale', 'passthrough')])
0.821 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.37873309844010733), ('model__colsample_bytree', 0.9278492397684184), ('model__gamma', 2), ('model__learning_rate', 0.03231204867296303), ('model__max_delta_step', 19), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 145), ('model__scale_pos_weight', 68.94834156267456), ('model__subsample', 0.9248473167614011), ('scale', 'passthrough')])
0.813 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2477702860939067), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.3461558214213515), ('model__max_delta_step', 5), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 177.45000122817396), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.819 (+/-0.012) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2589955559392077), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.1386254927023557), ('model__max_delta_step', 20), ('model__max_depth', 9), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.5581625488060291), ('model__subsample', 0.6289416747925071), ('scale', 'passthrough')])
0.821 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3117389972617159), ('model__colsample_bytree', 0.5195135091613654), ('model__gamma', 2), ('model__learning_rate', 0.04768913109523132), ('model__max_delta_step', 19), ('model__max_depth', 13), ('model__min_child_weight', 9), ('model__n_estimators', 145), ('model__scale_pos_weight', 358.5890063939114), ('model__subsample', 0.9982940573627086), ('scale', 'passthrough')])
0.817 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 1.0), ('model__gamma', 2), ('model__learning_rate', 0.1124768899984001), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 2.7910206703123195), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.813 (+/-0.002) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.4421753592698282), ('model__colsample_bytree', 1.0), ('model__gamma', 4), ('model__learning_rate', 0.3291395022208627), ('model__max_delta_step', 19), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 218.85312393876526), ('model__subsample', 0.6182771993189242), ('scale', 'passthrough')])
0.819 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8420342990824446), ('model__colsample_bytree', 0.793823268897349), ('model__gamma', 3), ('model__learning_rate', 0.1494590893130938), ('model__max_delta_step', 14), ('model__max_depth', 4), ('model__min_child_weight', 1), ('model__n_estimators', 149), ('model__scale_pos_weight', 182.2988537761414), ('model__subsample', 0.7000085627096705), ('scale', 'passthrough')])
0.820 (+/-0.018) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7975556755091645), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.23661077950939263), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 203.09690651748897), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.811 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.25162162218389456), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.01), ('model__max_delta_step', 4), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 18.30486052676598), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.764 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5509412498824555), ('model__colsample_bytree', 0.9876610047109231), ('model__gamma', 4), ('model__learning_rate', 0.9817695135819916), ('model__max_delta_step', 12), ('model__max_depth', 4), ('model__min_child_weight', 10), ('model__n_estimators', 60), ('model__scale_pos_weight', 228.264514753827), ('model__subsample', 0.31836289784150784), ('scale', 'passthrough')])
0.812 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.47049265824961084), ('model__colsample_bytree', 0.336411957584814), ('model__gamma', 2), ('model__learning_rate', 0.0628578451181805), ('model__max_delta_step', 16), ('model__max_depth', 18), ('model__min_child_weight', 9), ('model__n_estimators', 53), ('model__scale_pos_weight', 768.7838984341289), ('model__subsample', 0.9992098127509952), ('scale', 'passthrough')])
0.790 (+/-0.023) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2311826252494585), ('model__colsample_bytree', 0.5676651755593167), ('model__gamma', 3), ('model__learning_rate', 0.010748621084095817), ('model__max_delta_step', 2), ('model__max_depth', 19), ('model__min_child_weight', 9), ('model__n_estimators', 146), ('model__scale_pos_weight', 1.2649493021420082), ('model__subsample', 0.3659818044313171), ('scale', 'passthrough')])
0.812 (+/-0.016) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.99256112795603), ('model__colsample_bytree', 0.3402333276520046), ('model__gamma', 4), ('model__learning_rate', 0.11307837202164223), ('model__max_delta_step', 19), ('model__max_depth', 4), ('model__min_child_weight', 1), ('model__n_estimators', 145), ('model__scale_pos_weight', 13.987266647869875), ('model__subsample', 0.39763524876794626), ('scale', 'passthrough')])
0.817 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9973377829752199), ('model__colsample_bytree', 0.9869839643094087), ('model__gamma', 4), ('model__learning_rate', 0.025409003650511294), ('model__max_delta_step', 17), ('model__max_depth', 17), ('model__min_child_weight', 10), ('model__n_estimators', 134), ('model__scale_pos_weight', 38.40198305133798), ('model__subsample', 0.7748467805582491), ('scale', 'passthrough')])
0.822 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6954617459256157), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.08474569606546652), ('model__max_delta_step', 20), ('model__max_depth', 11), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 2.280597182116985), ('model__subsample', 0.5936363540144308), ('scale', 'passthrough')])
0.821 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8798568306611239), ('model__colsample_bytree', 0.47270753775719826), ('model__gamma', 1), ('model__learning_rate', 0.037150031895065), ('model__max_delta_step', 10), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 157.84093873250987), ('model__subsample', 0.7285773004147215), ('scale', 'passthrough')])
0.808 (+/-0.018) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9936699207860689), ('model__colsample_bytree', 0.6645441411502944), ('model__gamma', 3), ('model__learning_rate', 0.26303546610593215), ('model__max_delta_step', 7), ('model__max_depth', 19), ('model__min_child_weight', 8), ('model__n_estimators', 149), ('model__scale_pos_weight', 3.5400627108435816), ('model__subsample', 0.36048433514513245), ('scale', 'passthrough')])
0.815 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.37124359452914657), ('model__colsample_bytree', 1.0), ('model__gamma', 3), ('model__learning_rate', 0.2387793343534091), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 50), ('model__scale_pos_weight', 431.54562714290086), ('model__subsample', 0.7257653442730212), ('scale', 'passthrough')])
0.810 (+/-0.021) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9887257144971328), ('model__colsample_bytree', 0.9110195960318892), ('model__gamma', 2), ('model__learning_rate', 0.8217627525189802), ('model__max_delta_step', 3), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 145), ('model__scale_pos_weight', 729.0973283235462), ('model__subsample', 0.9877580955181187), ('scale', 'passthrough')])
0.818 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3610289879511644), ('model__colsample_bytree', 0.8794040949446551), ('model__gamma', 1), ('model__learning_rate', 0.07114080874500128), ('model__max_delta_step', 7), ('model__max_depth', 3), ('model__min_child_weight', 2), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.819 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2848417324417165), ('model__colsample_bytree', 1.0), ('model__gamma', 4), ('model__learning_rate', 0.1595137567347673), ('model__max_delta_step', 7), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.806 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9932967556686029), ('model__colsample_bytree', 0.7591777852931287), ('model__gamma', 2), ('model__learning_rate', 0.04119481156715826), ('model__max_delta_step', 11), ('model__max_depth', 4), ('model__min_child_weight', 8), ('model__n_estimators', 62), ('model__scale_pos_weight', 925.6932253258915), ('model__subsample', 0.7396145920669119), ('scale', 'passthrough')])
0.822 (+/-0.002) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8239118000910547), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.13590694805472336), ('model__max_delta_step', 5), ('model__max_depth', 10), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.7636751799087067), ('scale', 'passthrough')])
0.823 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.44888233845569864), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.09627500238061928), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 8), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.6523953423489568), ('scale', 'passthrough')])
0.811 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.68577891423815), ('model__colsample_bytree', 0.5886129420682689), ('model__gamma', 3), ('model__learning_rate', 0.010700985541269331), ('model__max_delta_step', 9), ('model__max_depth', 19), ('model__min_child_weight', 10), ('model__n_estimators', 148), ('model__scale_pos_weight', 1.6415738019047055), ('model__subsample', 0.8637639144432199), ('scale', 'passthrough')])
0.820 (+/-0.002) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3385057496683822), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.07293494024397029), ('model__max_delta_step', 20), ('model__max_depth', 7), ('model__min_child_weight', 6), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.1054915522600333), ('model__subsample', 0.765240062441286), ('scale', 'passthrough')])
0.813 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.4511140442147604), ('model__colsample_bytree', 0.9903547674262179), ('model__gamma', 5), ('model__learning_rate', 0.4551364817707272), ('model__max_delta_step', 3), ('model__max_depth', 9), ('model__min_child_weight', 10), ('model__n_estimators', 51), ('model__scale_pos_weight', 686.3543271963737), ('model__subsample', 0.9292339219363912), ('scale', 'passthrough')])
0.806 (+/-0.002) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.859413033359576), ('model__colsample_bytree', 0.6176696372925154), ('model__gamma', 4), ('model__learning_rate', 0.7945582762256038), ('model__max_delta_step', 6), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 109), ('model__scale_pos_weight', 4.57456444643311), ('model__subsample', 0.9818856087025138), ('scale', 'passthrough')])
0.814 (+/-0.017) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6748069479751319), ('model__colsample_bytree', 0.9980520411215905), ('model__gamma', 2), ('model__learning_rate', 0.5736481967628337), ('model__max_delta_step', 14), ('model__max_depth', 4), ('model__min_child_weight', 10), ('model__n_estimators', 50), ('model__scale_pos_weight', 16.08828817508725), ('model__subsample', 0.9654648425589478), ('scale', 'passthrough')])
0.787 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.06852714836629802), ('model__colsample_bytree', 0.6721648535255251), ('model__gamma', 4), ('model__learning_rate', 0.9786052823132902), ('model__max_delta_step', 19), ('model__max_depth', 19), ('model__min_child_weight', 6), ('model__n_estimators', 93), ('model__scale_pos_weight', 15.114368867960748), ('model__subsample', 0.99098756513387), ('scale', 'passthrough')])
0.795 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.11754292344143252), ('model__colsample_bytree', 0.3717176663785936), ('model__gamma', 5), ('model__learning_rate', 0.4194700852049675), ('model__max_delta_step', 16), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 133), ('model__scale_pos_weight', 591.7767669297752), ('model__subsample', 0.3659602277225823), ('scale', 'passthrough')])
0.818 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 1.0), ('model__colsample_bytree', 0.3), ('model__gamma', 1), ('model__learning_rate', 0.06715616801878019), ('model__max_delta_step', 20), ('model__max_depth', 11), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.7340131984203679), ('scale', 'passthrough')])
0.823 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6163527786738386), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.10094658635968386), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 8), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.142841169809037), ('model__subsample', 0.66461683533738), ('scale', 'passthrough')])
0.810 (+/-0.014) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7793269398106947), ('model__colsample_bytree', 0.8460423420685759), ('model__gamma', 4), ('model__learning_rate', 0.4520210689634202), ('model__max_delta_step', 17), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 63), ('model__scale_pos_weight', 11.716568798360003), ('model__subsample', 0.8782649268360583), ('scale', 'passthrough')])
0.821 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5283288332660206), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.14894535378591978), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.8188083661080623), ('scale', 'passthrough')])
0.818 (+/-0.017) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9365057126379146), ('model__colsample_bytree', 0.9868871308476761), ('model__gamma', 3), ('model__learning_rate', 0.04020976089944642), ('model__max_delta_step', 1), ('model__max_depth', 13), ('model__min_child_weight', 1), ('model__n_estimators', 146), ('model__scale_pos_weight', 11.775609005448057), ('model__subsample', 0.3268292221957598), ('scale', 'passthrough')])
0.822 (+/-0.016) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8011959448551085), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.05610219809054872), ('model__max_delta_step', 20), ('model__max_depth', 14), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.8173084402012074), ('scale', 'passthrough')])
0.822 (+/-0.004) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.20188376728451304), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.08019434098964026), ('model__max_delta_step', 3), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 50), ('model__scale_pos_weight', 1.3112689020839243), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.813 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6171724782762312), ('model__colsample_bytree', 0.9575457944704855), ('model__gamma', 1), ('model__learning_rate', 0.31139832384577526), ('model__max_delta_step', 7), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 59), ('model__scale_pos_weight', 802.3181375618043), ('model__subsample', 0.6211383727747098), ('scale', 'passthrough')])
0.814 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8734254422828995), ('model__colsample_bytree', 0.9509562517823495), ('model__gamma', 2), ('model__learning_rate', 0.010287031832540747), ('model__max_delta_step', 3), ('model__max_depth', 18), ('model__min_child_weight', 2), ('model__n_estimators', 137), ('model__scale_pos_weight', 3.717320547813186), ('model__subsample', 0.5853514305903059), ('scale', 'passthrough')])
0.824 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2059973912347993), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.07842903659436415), ('model__max_delta_step', 8), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 733.8385022788663), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.816 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.35612969648125914), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.027575612985359214), ('model__max_delta_step', 0), ('model__max_depth', 14), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 90.96557432140554), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.821 (+/-0.001) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2505428520452186), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.0803489186489822), ('model__max_delta_step', 20), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 100), ('model__scale_pos_weight', 53.4291088650935), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.823 (+/-0.003) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.28381391345916734), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.16756239530200986), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.7043083452715965), ('scale', 'passthrough')])
0.821 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5665127357805507), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.07557817482194025), ('model__max_delta_step', 20), ('model__max_depth', 9), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 101.1085187309343), ('model__subsample', 0.5929559335829364), ('scale', 'passthrough')])
0.823 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7883810115957455), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.10038810423698225), ('model__max_delta_step', 20), ('model__max_depth', 5), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.705046821629796), ('scale', 'passthrough')])
0.810 (+/-0.021) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.46476812763552044), ('model__colsample_bytree', 0.4279578966612934), ('model__gamma', 4), ('model__learning_rate', 0.01095924342794842), ('model__max_delta_step', 8), ('model__max_depth', 20), ('model__min_child_weight', 2), ('model__n_estimators', 140), ('model__scale_pos_weight', 2.0466633977771815), ('model__subsample', 0.47493466094751796), ('scale', 'passthrough')])
0.809 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2153599397239865), ('model__colsample_bytree', 0.922078348309785), ('model__gamma', 5), ('model__learning_rate', 0.021479986135452957), ('model__max_delta_step', 13), ('model__max_depth', 20), ('model__min_child_weight', 5), ('model__n_estimators', 56), ('model__scale_pos_weight', 38.59487821201587), ('model__subsample', 0.9605964562185123), ('scale', 'passthrough')])
0.817 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.907369960529755), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.03960228586907178), ('model__max_delta_step', 20), ('model__max_depth', 14), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.6179628538616335), ('scale', 'passthrough')])
0.816 (+/-0.014) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9315262437086874), ('model__colsample_bytree', 0.5209034930826074), ('model__gamma', 3), ('model__learning_rate', 0.06678354184062682), ('model__max_delta_step', 16), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 148), ('model__scale_pos_weight', 4.944792697764897), ('model__subsample', 0.35858782860200866), ('scale', 'passthrough')])
0.814 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.046730668908318174), ('model__colsample_bytree', 0.6602693794904608), ('model__gamma', 2), ('model__learning_rate', 0.11136392187445981), ('model__max_delta_step', 3), ('model__max_depth', 19), ('model__min_child_weight', 9), ('model__n_estimators', 138), ('model__scale_pos_weight', 742.0520711455373), ('model__subsample', 0.975120004288275), ('scale', 'passthrough')])
0.813 (+/-0.004) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.44093624934152575), ('model__colsample_bytree', 0.6989660277906319), ('model__gamma', 1), ('model__learning_rate', 0.13577638361933037), ('model__max_delta_step', 13), ('model__max_depth', 11), ('model__min_child_weight', 1), ('model__n_estimators', 54), ('model__scale_pos_weight', 67.11062815232934), ('model__subsample', 0.338745900913235), ('scale', 'passthrough')])
0.823 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6788578084180311), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.10510529783124824), ('model__max_delta_step', 0), ('model__max_depth', 7), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.712108015281221), ('scale', 'passthrough')])
0.816 (+/-0.013) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.31309620572574814), ('model__colsample_bytree', 0.9460314608457268), ('model__gamma', 2), ('model__learning_rate', 0.05746414696295757), ('model__max_delta_step', 16), ('model__max_depth', 6), ('model__min_child_weight', 10), ('model__n_estimators', 50), ('model__scale_pos_weight', 614.8716643477134), ('model__subsample', 0.8367754740911908), ('scale', 'passthrough')])
0.818 (+/-0.014) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6560569571142313), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.099536311198538), ('model__max_delta_step', 20), ('model__max_depth', 6), ('model__min_child_weight', 1), ('model__n_estimators', 94), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.572266839191951), ('scale', 'passthrough')])
0.818 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6019253335494583), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.04140404996605915), ('model__max_delta_step', 17), ('model__max_depth', 20), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.7690437666379234), ('scale', 'passthrough')])
0.805 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.4294194035519802), ('model__colsample_bytree', 0.9985425452472365), ('model__gamma', 3), ('model__learning_rate', 0.04074439657930806), ('model__max_delta_step', 11), ('model__max_depth', 4), ('model__min_child_weight', 2), ('model__n_estimators', 50), ('model__scale_pos_weight', 5.056400141838011), ('model__subsample', 0.3276436882498791), ('scale', 'passthrough')])
0.822 (+/-0.010) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.16854968896737774), ('model__colsample_bytree', 1.0), ('model__gamma', 2), ('model__learning_rate', 0.08028164532086843), ('model__max_delta_step', 8), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.821 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3287345894566851), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.11907973975594477), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.6051624223829977), ('scale', 'passthrough')])
0.818 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.15422998735889965), ('model__colsample_bytree', 0.559080415297065), ('model__gamma', 1), ('model__learning_rate', 0.16521794081310845), ('model__max_delta_step', 7), ('model__max_depth', 16), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 658.1634602836999), ('model__subsample', 1.0), ('scale', 'passthrough')])[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.9s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.7s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.0s finished
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   25.3s finished
/cluster/home/daniekie/.local/lib/python3.7/site-packages/xgboost/sklearn.py:390: UserWarning: kwargs is not saved in Scikit-Learn meta.
  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.')

0.818 (+/-0.002) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8491308316053338), ('model__colsample_bytree', 0.9259115147228867), ('model__gamma', 4), ('model__learning_rate', 0.219537601255428), ('model__max_delta_step', 15), ('model__max_depth', 12), ('model__min_child_weight', 8), ('model__n_estimators', 53), ('model__scale_pos_weight', 98.16359301666786), ('model__subsample', 0.9909209199087825), ('scale', 'passthrough')])
0.757 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9568008986065447), ('model__colsample_bytree', 0.5203044858428413), ('model__gamma', 5), ('model__learning_rate', 0.8820045266265615), ('model__max_delta_step', 17), ('model__max_depth', 20), ('model__min_child_weight', 3), ('model__n_estimators', 55), ('model__scale_pos_weight', 3.2719254666846522), ('model__subsample', 0.3038874352935374), ('scale', 'passthrough')])
0.808 (+/-0.013) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9951983831500005), ('model__colsample_bytree', 0.3610949756900127), ('model__gamma', 1), ('model__learning_rate', 0.01098541902881326), ('model__max_delta_step', 18), ('model__max_depth', 17), ('model__min_child_weight', 10), ('model__n_estimators', 59), ('model__scale_pos_weight', 420.9935578783081), ('model__subsample', 0.9577403793948231), ('scale', 'passthrough')])
0.821 (+/-0.001) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6541951007767545), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.10696240430203029), ('model__max_delta_step', 20), ('model__max_depth', 12), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.8501377179735958), ('scale', 'passthrough')])
0.824 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7664751801070965), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.11878922251722432), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.7229682045214889), ('scale', 'passthrough')])
0.820 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9001342684252364), ('model__colsample_bytree', 0.3), ('model__gamma', 1), ('model__learning_rate', 0.054251822511365205), ('model__max_delta_step', 17), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.7348745960658764), ('scale', 'passthrough')])
0.817 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2806112006438811), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.2451042114060229), ('model__max_delta_step', 2), ('model__max_depth', 3), ('model__min_child_weight', 6), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.6786443757545222), ('scale', 'passthrough')])
0.819 (+/-0.002) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8752047644925973), ('model__colsample_bytree', 0.31594258501186395), ('model__gamma', 2), ('model__learning_rate', 0.0699536272323327), ('model__max_delta_step', 10), ('model__max_depth', 10), ('model__min_child_weight', 9), ('model__n_estimators', 95), ('model__scale_pos_weight', 641.6139761523774), ('model__subsample', 0.9901037630825249), ('scale', 'passthrough')])
0.816 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5810672524816962), ('model__colsample_bytree', 0.7387973192421962), ('model__gamma', 1), ('model__learning_rate', 0.3466551095725686), ('model__max_delta_step', 13), ('model__max_depth', 20), ('model__min_child_weight', 3), ('model__n_estimators', 143), ('model__scale_pos_weight', 671.269873737053), ('model__subsample', 0.9210538089708267), ('scale', 'passthrough')])
0.816 (+/-0.002) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.2966494369105463), ('model__colsample_bytree', 0.5631636618221096), ('model__gamma', 1), ('model__learning_rate', 0.0920789831417371), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 16.164741746637798), ('model__subsample', 0.7366027336456855), ('scale', 'passthrough')])
0.795 (+/-0.024) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.981045325174474), ('model__colsample_bytree', 0.5264717163452097), ('model__gamma', 3), ('model__learning_rate', 0.01193916349064292), ('model__max_delta_step', 10), ('model__max_depth', 10), ('model__min_child_weight', 9), ('model__n_estimators', 147), ('model__scale_pos_weight', 162.41796391491437), ('model__subsample', 0.3016928308053273), ('scale', 'passthrough')])
0.824 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7295693406448678), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.11495791474302917), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 6), ('model__n_estimators', 150), ('model__scale_pos_weight', 18.656186168499335), ('model__subsample', 0.6540461186238449), ('scale', 'passthrough')])
0.823 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7567370446384274), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.11171291371452337), ('model__max_delta_step', 20), ('model__max_depth', 8), ('model__min_child_weight', 6), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.7776434975141822), ('scale', 'passthrough')])
0.812 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.3154486275030611), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.031577212450166446), ('model__max_delta_step', 13), ('model__max_depth', 20), ('model__min_child_weight', 10), ('model__n_estimators', 50), ('model__scale_pos_weight', 384.50590738415696), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.801 (+/-0.017) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.20308158569106502), ('model__colsample_bytree', 0.6401627286084413), ('model__gamma', 4), ('model__learning_rate', 0.9958188276694409), ('model__max_delta_step', 3), ('model__max_depth', 4), ('model__min_child_weight', 10), ('model__n_estimators', 57), ('model__scale_pos_weight', 461.29058521458205), ('model__subsample', 0.9876357058598466), ('scale', 'passthrough')])
0.827 (+/-0.004) for OrderedDict([('model', XGBClassifier(base_score=0.5, booster='gbtree',
              colsample_bylevel=0.8668701895013304, colsample_bynode=1,
              colsample_bytree=1.0,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'ext...
              interaction_constraints='', learning_rate=0.12492801938016393,
              max_delta_step=0, max_depth=8, min_child_weight=10, missing=nan,
              monotone_constraints='()', n_estimators=150, n_jobs=0,
              num_parallel_tree=1, objective='multi:softprob', random_state=0,
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1.0,
              subsample=0.871625599700572, tree_method='exact',
              validate_parameters=1, verbosity=None)), ('model__colsample_bylevel', 0.8668701895013304), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.12492801938016393), ('model__max_delta_step', 0), ('model__max_depth', 8), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.871625599700572), ('scale', 'passthrough')])
0.821 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9916904238916124), ('model__colsample_bytree', 0.9688464311980622), ('model__gamma', 3), ('model__learning_rate', 0.20688302542803436), ('model__max_delta_step', 19), ('model__max_depth', 8), ('model__min_child_weight', 10), ('model__n_estimators', 149), ('model__scale_pos_weight', 47.440087594703016), ('model__subsample', 0.6276583216721197), ('scale', 'passthrough')])
0.820 (+/-0.002) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.9162715601351066), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.12409866378814392), ('model__max_delta_step', 0), ('model__max_depth', 7), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.8073766448422177), ('scale', 'passthrough')])
0.818 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6683160421947889), ('model__colsample_bytree', 0.8777316471202263), ('model__gamma', 2), ('model__learning_rate', 0.03873852470666852), ('model__max_delta_step', 6), ('model__max_depth', 4), ('model__min_child_weight', 1), ('model__n_estimators', 137), ('model__scale_pos_weight', 3.7995034600209316), ('model__subsample', 0.31696593658678845), ('scale', 'passthrough')])
0.823 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8219851494075568), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.09734760444294889), ('model__max_delta_step', 0), ('model__max_depth', 12), ('model__min_child_weight', 6), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.8555514576843115), ('scale', 'passthrough')])
0.818 (+/-0.006) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7383482959082196), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.09394733982427142), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 4), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.5309510763054156), ('scale', 'passthrough')])
0.819 (+/-0.011) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.837983323976336), ('model__colsample_bytree', 1.0), ('model__gamma', 5), ('model__learning_rate', 0.1501763422891961), ('model__max_delta_step', 20), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.7933790621572603), ('scale', 'passthrough')])
0.818 (+/-0.008) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.503220179218465), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.16994682863716545), ('model__max_delta_step', 4), ('model__max_depth', 3), ('model__min_child_weight', 10), ('model__n_estimators', 50), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.7902666752934907), ('scale', 'passthrough')])
0.818 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.27864801763257824), ('model__colsample_bytree', 1.0), ('model__gamma', 5), ('model__learning_rate', 0.0815770429427172), ('model__max_delta_step', 20), ('model__max_depth', 11), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.821 (+/-0.003) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8619070312505364), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.10597559475989468), ('model__max_delta_step', 20), ('model__max_depth', 11), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.8016679277664882), ('scale', 'passthrough')])
0.819 (+/-0.013) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8216926856123244), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.16864254346485413), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 1), ('model__n_estimators', 150), ('model__scale_pos_weight', 34.07608767092671), ('model__subsample', 1.0), ('scale', 'passthrough')])
0.819 (+/-0.009) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.6844854538966096), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.13716347464584985), ('model__max_delta_step', 0), ('model__max_depth', 3), ('model__min_child_weight', 7), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 0.7816123683388981), ('scale', 'passthrough')])
0.821 (+/-0.005) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.5813068156435819), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.1178995687832883), ('model__max_delta_step', 20), ('model__max_depth', 6), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1000.0), ('model__subsample', 0.6204906001531987), ('scale', 'passthrough')])
0.815 (+/-0.002) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.7529066100167874), ('model__colsample_bytree', 0.8659802214495997), ('model__gamma', 4), ('model__learning_rate', 0.12838713094015772), ('model__max_delta_step', 0), ('model__max_depth', 15), ('model__min_child_weight', 1), ('model__n_estimators', 65), ('model__scale_pos_weight', 8.262419368059616), ('model__subsample', 0.9672368693922622), ('scale', 'passthrough')])
0.819 (+/-0.007) for OrderedDict([('model', XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None)), ('model__colsample_bylevel', 0.8465371232284055), ('model__colsample_bytree', 1.0), ('model__gamma', 1), ('model__learning_rate', 0.11171784991334584), ('model__max_delta_step', 20), ('model__max_depth', 11), ('model__min_child_weight', 10), ('model__n_estimators', 150), ('model__scale_pos_weight', 1.0), ('model__subsample', 1.0), ('scale', 'passthrough')])


Results saved as prediction.csv
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.787035117607132, model__colsample_bytree=0.7112453824126441, model__gamma=4, model__learning_rate=0.02079837150135237, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=4, model__n_estimators=78, model__scale_pos_weight=249.52308451288775, model__subsample=0.9976698378005269, scale=passthrough 
[12:39:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.787035117607132, model__colsample_bytree=0.7112453824126441, model__gamma=4, model__learning_rate=0.02079837150135237, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=4, model__n_estimators=78, model__scale_pos_weight=249.52308451288775, model__subsample=0.9976698378005269, scale=passthrough, score=0.807, total=  16.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9985235150787968, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.18558997178831976, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=71.9368373769291, model__subsample=1.0, scale=passthrough 
[12:41:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9985235150787968, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.18558997178831976, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=71.9368373769291, model__subsample=1.0, scale=passthrough, score=0.818, total=  30.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=1.0, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=51, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:45:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=1.0, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=51, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.792, total=  17.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.23848993246804506, model__colsample_bytree=0.9097869239684406, model__gamma=3, model__learning_rate=0.07521545489840264, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=14.096088207945458, model__subsample=0.3, scale=passthrough 
[12:48:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.23848993246804506, model__colsample_bytree=0.9097869239684406, model__gamma=3, model__learning_rate=0.07521545489840264, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=14.096088207945458, model__subsample=0.3, scale=passthrough, score=0.821, total=   5.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4561709681306783, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.05744678535505964, model__max_delta_step=8, model__max_depth=14, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.30013062014501, scale=passthrough 
[12:51:20] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4561709681306783, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.05744678535505964, model__max_delta_step=8, model__max_depth=14, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.30013062014501, scale=passthrough, score=0.818, total=  10.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7936756256804407, model__colsample_bytree=0.7257873766908297, model__gamma=5, model__learning_rate=0.030237589119733947, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=47.39578121166871, model__subsample=0.42602881074865684, scale=passthrough 
[12:55:15] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7936756256804407, model__colsample_bytree=0.7257873766908297, model__gamma=5, model__learning_rate=0.030237589119733947, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=47.39578121166871, model__subsample=0.42602881074865684, scale=passthrough, score=0.813, total=   4.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9252061892810777, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07134063846005033, model__max_delta_step=15, model__max_depth=17, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.9024170930502224, scale=passthrough 
[12:58:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9252061892810777, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07134063846005033, model__max_delta_step=15, model__max_depth=17, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.9024170930502224, scale=passthrough, score=0.823, total=  28.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5843600897185549, model__colsample_bytree=0.9430163495262514, model__gamma=1, model__learning_rate=0.1691671183377136, model__max_delta_step=5, model__max_depth=4, model__min_child_weight=10, model__n_estimators=51, model__scale_pos_weight=960.7489282692309, model__subsample=0.42952695098688654, scale=passthrough 
[13:01:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5843600897185549, model__colsample_bytree=0.9430163495262514, model__gamma=1, model__learning_rate=0.1691671183377136, model__max_delta_step=5, model__max_depth=4, model__min_child_weight=10, model__n_estimators=51, model__scale_pos_weight=960.7489282692309, model__subsample=0.42952695098688654, scale=passthrough, score=0.809, total=   2.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2477702860939067, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.3461558214213515, model__max_delta_step=5, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=177.45000122817396, model__subsample=1.0, scale=passthrough 
[13:05:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2477702860939067, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.3461558214213515, model__max_delta_step=5, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=177.45000122817396, model__subsample=1.0, scale=passthrough, score=0.815, total=   3.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6954617459256157, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08474569606546652, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=2.280597182116985, model__subsample=0.5936363540144308, scale=passthrough 
[13:08:21] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6954617459256157, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08474569606546652, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=2.280597182116985, model__subsample=0.5936363540144308, scale=passthrough, score=0.818, total=  22.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.859413033359576, model__colsample_bytree=0.6176696372925154, model__gamma=4, model__learning_rate=0.7945582762256038, model__max_delta_step=6, model__max_depth=3, model__min_child_weight=1, model__n_estimators=109, model__scale_pos_weight=4.57456444643311, model__subsample=0.9818856087025138, scale=passthrough 
[13:12:11] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.859413033359576, model__colsample_bytree=0.6176696372925154, model__gamma=4, model__learning_rate=0.7945582762256038, model__max_delta_step=6, model__max_depth=3, model__min_child_weight=1, model__n_estimators=109, model__scale_pos_weight=4.57456444643311, model__subsample=0.9818856087025138, scale=passthrough, score=0.808, total=   5.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2059973912347993, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07842903659436415, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=733.8385022788663, model__subsample=1.0, scale=passthrough 
[13:16:18] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2059973912347993, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07842903659436415, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=733.8385022788663, model__subsample=1.0, scale=passthrough, score=0.828, total=   8.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.31309620572574814, model__colsample_bytree=0.9460314608457268, model__gamma=2, model__learning_rate=0.05746414696295757, model__max_delta_step=16, model__max_depth=6, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=614.8716643477134, model__subsample=0.8367754740911908, scale=passthrough 
[13:20:52] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.31309620572574814, model__colsample_bytree=0.9460314608457268, model__gamma=2, model__learning_rate=0.05746414696295757, model__max_delta_step=16, model__max_depth=6, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=614.8716643477134, model__subsample=0.8367754740911908, scale=passthrough, score=0.825, total=   2.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8752047644925973, model__colsample_bytree=0.31594258501186395, model__gamma=2, model__learning_rate=0.0699536272323327, model__max_delta_step=10, model__max_depth=10, model__min_child_weight=9, model__n_estimators=95, model__scale_pos_weight=641.6139761523774, model__subsample=0.9901037630825249, scale=passthrough 
[13:25:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8752047644925973, model__colsample_bytree=0.31594258501186395, model__gamma=2, model__learning_rate=0.0699536272323327, model__max_delta_step=10, model__max_depth=10, model__min_child_weight=9, model__n_estimators=95, model__scale_pos_weight=641.6139761523774, model__subsample=0.9901037630825249, scale=passthrough, score=0.821, total=   6.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8219851494075568, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09734760444294889, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8555514576843115, scale=passthrough 
[13:30:30] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8219851494075568, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09734760444294889, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8555514576843115, scale=passthrough, score=0.825, total=  22.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.804000760089205, model__colsample_bytree=0.87439356412997, model__gamma=2, model__learning_rate=0.09724451331363028, model__max_delta_step=8, model__max_depth=12, model__min_child_weight=5, model__n_estimators=91, model__scale_pos_weight=8.712236078372266, model__subsample=0.5590460523937827, scale=passthrough 
[12:40:17] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.804000760089205, model__colsample_bytree=0.87439356412997, model__gamma=2, model__learning_rate=0.09724451331363028, model__max_delta_step=8, model__max_depth=12, model__min_child_weight=5, model__n_estimators=91, model__scale_pos_weight=8.712236078372266, model__subsample=0.5590460523937827, scale=passthrough, score=0.812, total=  12.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6372693350745634, model__colsample_bytree=0.856279090521453, model__gamma=4, model__learning_rate=0.01, model__max_delta_step=14, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[12:42:10] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6372693350745634, model__colsample_bytree=0.856279090521453, model__gamma=4, model__learning_rate=0.01, model__max_delta_step=14, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.782, total=   4.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7209883604008371, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.05711622673001165, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[12:45:21] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7209883604008371, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.05711622673001165, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.821, total=  23.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.33817897669411146, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1062929550762915, model__max_delta_step=0, model__max_depth=17, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:48:34] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.33817897669411146, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1062929550762915, model__max_delta_step=0, model__max_depth=17, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.823, total=  17.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.54122389035169, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.42272303291809443, model__max_delta_step=20, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:51:34] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.54122389035169, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.42272303291809443, model__max_delta_step=20, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.821, total=  11.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.596005016271846, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.15313504883569234, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6736223814213212, scale=passthrough 
[12:55:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.596005016271846, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.15313504883569234, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6736223814213212, scale=passthrough, score=0.817, total=   7.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2626717566045728, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.061741286298299246, model__max_delta_step=11, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:59:10] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2626717566045728, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.061741286298299246, model__max_delta_step=11, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.815, total=   4.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5843600897185549, model__colsample_bytree=0.9430163495262514, model__gamma=1, model__learning_rate=0.1691671183377136, model__max_delta_step=5, model__max_depth=4, model__min_child_weight=10, model__n_estimators=51, model__scale_pos_weight=960.7489282692309, model__subsample=0.42952695098688654, scale=passthrough 
[13:01:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5843600897185549, model__colsample_bytree=0.9430163495262514, model__gamma=1, model__learning_rate=0.1691671183377136, model__max_delta_step=5, model__max_depth=4, model__min_child_weight=10, model__n_estimators=51, model__scale_pos_weight=960.7489282692309, model__subsample=0.42952695098688654, scale=passthrough, score=0.815, total=   2.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2477702860939067, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.3461558214213515, model__max_delta_step=5, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=177.45000122817396, model__subsample=1.0, scale=passthrough 
[13:05:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2477702860939067, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.3461558214213515, model__max_delta_step=5, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=177.45000122817396, model__subsample=1.0, scale=passthrough, score=0.819, total=   4.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8798568306611239, model__colsample_bytree=0.47270753775719826, model__gamma=1, model__learning_rate=0.037150031895065, model__max_delta_step=10, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=157.84093873250987, model__subsample=0.7285773004147215, scale=passthrough 
[13:08:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8798568306611239, model__colsample_bytree=0.47270753775719826, model__gamma=1, model__learning_rate=0.037150031895065, model__max_delta_step=10, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=157.84093873250987, model__subsample=0.7285773004147215, scale=passthrough, score=0.823, total=  19.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6748069479751319, model__colsample_bytree=0.9980520411215905, model__gamma=2, model__learning_rate=0.5736481967628337, model__max_delta_step=14, model__max_depth=4, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=16.08828817508725, model__subsample=0.9654648425589478, scale=passthrough 
[13:12:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6748069479751319, model__colsample_bytree=0.9980520411215905, model__gamma=2, model__learning_rate=0.5736481967628337, model__max_delta_step=14, model__max_depth=4, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=16.08828817508725, model__subsample=0.9654648425589478, scale=passthrough, score=0.816, total=   3.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.35612969648125914, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.027575612985359214, model__max_delta_step=0, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=90.96557432140554, model__subsample=1.0, scale=passthrough 
[13:16:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.35612969648125914, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.027575612985359214, model__max_delta_step=0, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=90.96557432140554, model__subsample=1.0, scale=passthrough, score=0.817, total=  11.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6560569571142313, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.099536311198538, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=1, model__n_estimators=94, model__scale_pos_weight=1000.0, model__subsample=0.572266839191951, scale=passthrough 
[13:21:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6560569571142313, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.099536311198538, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=1, model__n_estimators=94, model__scale_pos_weight=1000.0, model__subsample=0.572266839191951, scale=passthrough, score=0.811, total=   9.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8752047644925973, model__colsample_bytree=0.31594258501186395, model__gamma=2, model__learning_rate=0.0699536272323327, model__max_delta_step=10, model__max_depth=10, model__min_child_weight=9, model__n_estimators=95, model__scale_pos_weight=641.6139761523774, model__subsample=0.9901037630825249, scale=passthrough 
[13:25:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8752047644925973, model__colsample_bytree=0.31594258501186395, model__gamma=2, model__learning_rate=0.0699536272323327, model__max_delta_step=10, model__max_depth=10, model__min_child_weight=9, model__n_estimators=95, model__scale_pos_weight=641.6139761523774, model__subsample=0.9901037630825249, scale=passthrough, score=0.818, total=   6.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8219851494075568, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09734760444294889, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8555514576843115, scale=passthrough 
[13:30:30] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8219851494075568, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09734760444294889, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8555514576843115, scale=passthrough, score=0.819, total=  22.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8496240201470282, model__colsample_bytree=0.9830777326171856, model__gamma=4, model__learning_rate=0.06874849914790944, model__max_delta_step=4, model__max_depth=12, model__min_child_weight=8, model__n_estimators=133, model__scale_pos_weight=8.080969479597385, model__subsample=0.537030103927309, scale=passthrough 
[12:39:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8496240201470282, model__colsample_bytree=0.9830777326171856, model__gamma=4, model__learning_rate=0.06874849914790944, model__max_delta_step=4, model__max_depth=12, model__min_child_weight=8, model__n_estimators=133, model__scale_pos_weight=8.080969479597385, model__subsample=0.537030103927309, scale=passthrough, score=0.815, total=  18.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.1420774216790083, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.4509992641426783, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=8, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.8623998033233848, scale=passthrough 
[12:41:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.1420774216790083, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.4509992641426783, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=8, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.8623998033233848, scale=passthrough, score=0.796, total=   1.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5196344243152036, model__colsample_bytree=0.9624293710653027, model__gamma=1, model__learning_rate=0.046588484069784795, model__max_delta_step=15, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=31.748607485649025, model__subsample=1.0, scale=passthrough 
[12:44:39] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5196344243152036, model__colsample_bytree=0.9624293710653027, model__gamma=1, model__learning_rate=0.046588484069784795, model__max_delta_step=15, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=31.748607485649025, model__subsample=1.0, scale=passthrough, score=0.816, total=  13.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3446779503502123, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.18228125280787674, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=6.979894561096652, model__subsample=1.0, scale=passthrough 
[12:48:03] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3446779503502123, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.18228125280787674, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=6.979894561096652, model__subsample=1.0, scale=passthrough, score=0.816, total=   2.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.415790734612201, model__colsample_bytree=0.6845964052587015, model__gamma=1, model__learning_rate=0.020308990155481214, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=14.718278134971332, model__subsample=0.3, scale=passthrough 
[12:51:10] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.415790734612201, model__colsample_bytree=0.6845964052587015, model__gamma=1, model__learning_rate=0.020308990155481214, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=14.718278134971332, model__subsample=0.3, scale=passthrough, score=0.809, total=   6.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3559794222308732, model__colsample_bytree=0.38368467345407525, model__gamma=3, model__learning_rate=0.03568816551718303, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=795.2428424486291, model__subsample=0.5003519395379956, scale=passthrough 
[12:55:04] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3559794222308732, model__colsample_bytree=0.38368467345407525, model__gamma=3, model__learning_rate=0.03568816551718303, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=795.2428424486291, model__subsample=0.5003519395379956, scale=passthrough, score=0.812, total=   6.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9252061892810777, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07134063846005033, model__max_delta_step=15, model__max_depth=17, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.9024170930502224, scale=passthrough 
[12:58:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9252061892810777, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07134063846005033, model__max_delta_step=15, model__max_depth=17, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.9024170930502224, scale=passthrough, score=0.829, total=  28.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=0.9498280409117508, model__gamma=2, model__learning_rate=1.0, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.7897702919913976, model__subsample=1.0, scale=passthrough 
[13:01:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=0.9498280409117508, model__gamma=2, model__learning_rate=1.0, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.7897702919913976, model__subsample=1.0, scale=passthrough, score=0.796, total=   0.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.37873309844010733, model__colsample_bytree=0.9278492397684184, model__gamma=2, model__learning_rate=0.03231204867296303, model__max_delta_step=19, model__max_depth=20, model__min_child_weight=10, model__n_estimators=145, model__scale_pos_weight=68.94834156267456, model__subsample=0.9248473167614011, scale=passthrough 
[13:04:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.37873309844010733, model__colsample_bytree=0.9278492397684184, model__gamma=2, model__learning_rate=0.03231204867296303, model__max_delta_step=19, model__max_depth=20, model__min_child_weight=10, model__n_estimators=145, model__scale_pos_weight=68.94834156267456, model__subsample=0.9248473167614011, scale=passthrough, score=0.826, total=  12.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9973377829752199, model__colsample_bytree=0.9869839643094087, model__gamma=4, model__learning_rate=0.025409003650511294, model__max_delta_step=17, model__max_depth=17, model__min_child_weight=10, model__n_estimators=134, model__scale_pos_weight=38.40198305133798, model__subsample=0.7748467805582491, scale=passthrough 
[13:07:46] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9973377829752199, model__colsample_bytree=0.9869839643094087, model__gamma=4, model__learning_rate=0.025409003650511294, model__max_delta_step=17, model__max_depth=17, model__min_child_weight=10, model__n_estimators=134, model__scale_pos_weight=38.40198305133798, model__subsample=0.7748467805582491, scale=passthrough, score=0.823, total=  28.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.859413033359576, model__colsample_bytree=0.6176696372925154, model__gamma=4, model__learning_rate=0.7945582762256038, model__max_delta_step=6, model__max_depth=3, model__min_child_weight=1, model__n_estimators=109, model__scale_pos_weight=4.57456444643311, model__subsample=0.9818856087025138, scale=passthrough 
[13:12:11] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.859413033359576, model__colsample_bytree=0.6176696372925154, model__gamma=4, model__learning_rate=0.7945582762256038, model__max_delta_step=6, model__max_depth=3, model__min_child_weight=1, model__n_estimators=109, model__scale_pos_weight=4.57456444643311, model__subsample=0.9818856087025138, scale=passthrough, score=0.805, total=   5.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.35612969648125914, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.027575612985359214, model__max_delta_step=0, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=90.96557432140554, model__subsample=1.0, scale=passthrough 
[13:16:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.35612969648125914, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.027575612985359214, model__max_delta_step=0, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=90.96557432140554, model__subsample=1.0, scale=passthrough, score=0.813, total=  11.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6560569571142313, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.099536311198538, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=1, model__n_estimators=94, model__scale_pos_weight=1000.0, model__subsample=0.572266839191951, scale=passthrough 
[13:21:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6560569571142313, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.099536311198538, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=1, model__n_estimators=94, model__scale_pos_weight=1000.0, model__subsample=0.572266839191951, scale=passthrough, score=0.817, total=   9.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8752047644925973, model__colsample_bytree=0.31594258501186395, model__gamma=2, model__learning_rate=0.0699536272323327, model__max_delta_step=10, model__max_depth=10, model__min_child_weight=9, model__n_estimators=95, model__scale_pos_weight=641.6139761523774, model__subsample=0.9901037630825249, scale=passthrough 
[13:25:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8752047644925973, model__colsample_bytree=0.31594258501186395, model__gamma=2, model__learning_rate=0.0699536272323327, model__max_delta_step=10, model__max_depth=10, model__min_child_weight=9, model__n_estimators=95, model__scale_pos_weight=641.6139761523774, model__subsample=0.9901037630825249, scale=passthrough, score=0.819, total=   6.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8219851494075568, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09734760444294889, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8555514576843115, scale=passthrough 
[13:30:30] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8219851494075568, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09734760444294889, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8555514576843115, scale=passthrough, score=0.825, total=  22.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5078988934265182, model__colsample_bytree=0.8346246633266341, model__gamma=4, model__learning_rate=0.43750217377340134, model__max_delta_step=2, model__max_depth=13, model__min_child_weight=4, model__n_estimators=53, model__scale_pos_weight=7.209798890237415, model__subsample=0.6639515335369921, scale=passthrough 
[12:39:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5078988934265182, model__colsample_bytree=0.8346246633266341, model__gamma=4, model__learning_rate=0.43750217377340134, model__max_delta_step=2, model__max_depth=13, model__min_child_weight=4, model__n_estimators=53, model__scale_pos_weight=7.209798890237415, model__subsample=0.6639515335369921, scale=passthrough, score=0.829, total=   6.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.04051980750184009, model__max_delta_step=15, model__max_depth=20, model__min_child_weight=5, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:41:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.04051980750184009, model__max_delta_step=15, model__max_depth=20, model__min_child_weight=5, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.802, total=   1.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=1.0, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=51, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:45:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=1.0, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=51, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.792, total=  16.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.23848993246804506, model__colsample_bytree=0.9097869239684406, model__gamma=3, model__learning_rate=0.07521545489840264, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=14.096088207945458, model__subsample=0.3, scale=passthrough 
[12:48:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.23848993246804506, model__colsample_bytree=0.9097869239684406, model__gamma=3, model__learning_rate=0.07521545489840264, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=14.096088207945458, model__subsample=0.3, scale=passthrough, score=0.814, total=   5.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.54122389035169, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.42272303291809443, model__max_delta_step=20, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:51:34] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.54122389035169, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.42272303291809443, model__max_delta_step=20, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.810, total=  11.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.596005016271846, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.15313504883569234, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6736223814213212, scale=passthrough 
[12:55:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.596005016271846, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.15313504883569234, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6736223814213212, scale=passthrough, score=0.827, total=   7.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.32620009304869785, model__colsample_bytree=0.575801209690553, model__gamma=5, model__learning_rate=0.010375661400059702, model__max_delta_step=7, model__max_depth=10, model__min_child_weight=10, model__n_estimators=107, model__scale_pos_weight=29.14660215561998, model__subsample=0.8964223262021889, scale=passthrough 
[12:59:19] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.32620009304869785, model__colsample_bytree=0.575801209690553, model__gamma=5, model__learning_rate=0.010375661400059702, model__max_delta_step=7, model__max_depth=10, model__min_child_weight=10, model__n_estimators=107, model__scale_pos_weight=29.14660215561998, model__subsample=0.8964223262021889, scale=passthrough, score=0.794, total=   4.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.13518078933230862, model__colsample_bytree=0.7554546456232811, model__gamma=4, model__learning_rate=0.2447022723549562, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=9, model__n_estimators=145, model__scale_pos_weight=15.633109434047906, model__subsample=0.8502072361448936, scale=passthrough 
[13:01:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.13518078933230862, model__colsample_bytree=0.7554546456232811, model__gamma=4, model__learning_rate=0.2447022723549562, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=9, model__n_estimators=145, model__scale_pos_weight=15.633109434047906, model__subsample=0.8502072361448936, scale=passthrough, score=0.808, total=   1.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2589955559392077, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1386254927023557, model__max_delta_step=20, model__max_depth=9, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.5581625488060291, model__subsample=0.6289416747925071, scale=passthrough 
[13:05:12] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2589955559392077, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1386254927023557, model__max_delta_step=20, model__max_depth=9, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.5581625488060291, model__subsample=0.6289416747925071, scale=passthrough, score=0.812, total=   8.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8798568306611239, model__colsample_bytree=0.47270753775719826, model__gamma=1, model__learning_rate=0.037150031895065, model__max_delta_step=10, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=157.84093873250987, model__subsample=0.7285773004147215, scale=passthrough 
[13:08:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8798568306611239, model__colsample_bytree=0.47270753775719826, model__gamma=1, model__learning_rate=0.037150031895065, model__max_delta_step=10, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=157.84093873250987, model__subsample=0.7285773004147215, scale=passthrough, score=0.814, total=  19.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.06852714836629802, model__colsample_bytree=0.6721648535255251, model__gamma=4, model__learning_rate=0.9786052823132902, model__max_delta_step=19, model__max_depth=19, model__min_child_weight=6, model__n_estimators=93, model__scale_pos_weight=15.114368867960748, model__subsample=0.99098756513387, scale=passthrough 
[13:12:37] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.06852714836629802, model__colsample_bytree=0.6721648535255251, model__gamma=4, model__learning_rate=0.9786052823132902, model__max_delta_step=19, model__max_depth=19, model__min_child_weight=6, model__n_estimators=93, model__scale_pos_weight=15.114368867960748, model__subsample=0.99098756513387, scale=passthrough, score=0.783, total=   1.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2505428520452186, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.0803489186489822, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=100, model__scale_pos_weight=53.4291088650935, model__subsample=1.0, scale=passthrough 
[13:16:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2505428520452186, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.0803489186489822, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=100, model__scale_pos_weight=53.4291088650935, model__subsample=1.0, scale=passthrough, score=0.822, total=   6.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6019253335494583, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.04140404996605915, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7690437666379234, scale=passthrough 
[13:21:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6019253335494583, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.04140404996605915, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7690437666379234, scale=passthrough, score=0.814, total=  28.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5810672524816962, model__colsample_bytree=0.7387973192421962, model__gamma=1, model__learning_rate=0.3466551095725686, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=3, model__n_estimators=143, model__scale_pos_weight=671.269873737053, model__subsample=0.9210538089708267, scale=passthrough 
[13:26:01] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5810672524816962, model__colsample_bytree=0.7387973192421962, model__gamma=1, model__learning_rate=0.3466551095725686, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=3, model__n_estimators=143, model__scale_pos_weight=671.269873737053, model__subsample=0.9210538089708267, scale=passthrough, score=0.811, total=  16.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7383482959082196, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09394733982427142, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.5309510763054156, scale=passthrough 
[13:31:06] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7383482959082196, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09394733982427142, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.5309510763054156, scale=passthrough, score=0.815, total=   7.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.036013135558974105, model__colsample_bytree=0.6770798813716852, model__gamma=1, model__learning_rate=0.35384207897748293, model__max_delta_step=7, model__max_depth=14, model__min_child_weight=4, model__n_estimators=141, model__scale_pos_weight=13.587798533272867, model__subsample=0.7134838459802921, scale=passthrough 
[12:39:44] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.036013135558974105, model__colsample_bytree=0.6770798813716852, model__gamma=1, model__learning_rate=0.35384207897748293, model__max_delta_step=7, model__max_depth=14, model__min_child_weight=4, model__n_estimators=141, model__scale_pos_weight=13.587798533272867, model__subsample=0.7134838459802921, scale=passthrough, score=0.801, total=   2.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.1420774216790083, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.4509992641426783, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=8, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.8623998033233848, scale=passthrough 
[12:41:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.1420774216790083, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.4509992641426783, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=8, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.8623998033233848, scale=passthrough, score=0.810, total=   1.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5196344243152036, model__colsample_bytree=0.9624293710653027, model__gamma=1, model__learning_rate=0.046588484069784795, model__max_delta_step=15, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=31.748607485649025, model__subsample=1.0, scale=passthrough 
[12:44:39] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5196344243152036, model__colsample_bytree=0.9624293710653027, model__gamma=1, model__learning_rate=0.046588484069784795, model__max_delta_step=15, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=31.748607485649025, model__subsample=1.0, scale=passthrough, score=0.818, total=  13.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.30710558780986585, model__colsample_bytree=0.7451117847409254, model__gamma=4, model__learning_rate=0.03979965805844932, model__max_delta_step=1, model__max_depth=20, model__min_child_weight=3, model__n_estimators=150, model__scale_pos_weight=73.2857211995429, model__subsample=1.0, scale=passthrough 
[12:48:09] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.30710558780986585, model__colsample_bytree=0.7451117847409254, model__gamma=4, model__learning_rate=0.03979965805844932, model__max_delta_step=1, model__max_depth=20, model__min_child_weight=3, model__n_estimators=150, model__scale_pos_weight=73.2857211995429, model__subsample=1.0, scale=passthrough, score=0.819, total=  12.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.415790734612201, model__colsample_bytree=0.6845964052587015, model__gamma=1, model__learning_rate=0.020308990155481214, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=14.718278134971332, model__subsample=0.3, scale=passthrough 
[12:51:10] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.415790734612201, model__colsample_bytree=0.6845964052587015, model__gamma=1, model__learning_rate=0.020308990155481214, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=14.718278134971332, model__subsample=0.3, scale=passthrough, score=0.812, total=   6.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7936756256804407, model__colsample_bytree=0.7257873766908297, model__gamma=5, model__learning_rate=0.030237589119733947, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=47.39578121166871, model__subsample=0.42602881074865684, scale=passthrough 
[12:55:15] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7936756256804407, model__colsample_bytree=0.7257873766908297, model__gamma=5, model__learning_rate=0.030237589119733947, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=47.39578121166871, model__subsample=0.42602881074865684, scale=passthrough, score=0.800, total=   4.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9252061892810777, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07134063846005033, model__max_delta_step=15, model__max_depth=17, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.9024170930502224, scale=passthrough 
[12:58:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9252061892810777, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07134063846005033, model__max_delta_step=15, model__max_depth=17, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.9024170930502224, scale=passthrough, score=0.815, total=  28.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=0.9498280409117508, model__gamma=2, model__learning_rate=1.0, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.7897702919913976, model__subsample=1.0, scale=passthrough 
[13:01:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=0.9498280409117508, model__gamma=2, model__learning_rate=1.0, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.7897702919913976, model__subsample=1.0, scale=passthrough, score=0.799, total=   0.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2477702860939067, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.3461558214213515, model__max_delta_step=5, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=177.45000122817396, model__subsample=1.0, scale=passthrough 
[13:05:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2477702860939067, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.3461558214213515, model__max_delta_step=5, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=177.45000122817396, model__subsample=1.0, scale=passthrough, score=0.807, total=   4.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6954617459256157, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08474569606546652, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=2.280597182116985, model__subsample=0.5936363540144308, scale=passthrough 
[13:08:21] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6954617459256157, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08474569606546652, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=2.280597182116985, model__subsample=0.5936363540144308, scale=passthrough, score=0.827, total=  22.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6748069479751319, model__colsample_bytree=0.9980520411215905, model__gamma=2, model__learning_rate=0.5736481967628337, model__max_delta_step=14, model__max_depth=4, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=16.08828817508725, model__subsample=0.9654648425589478, scale=passthrough 
[13:12:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6748069479751319, model__colsample_bytree=0.9980520411215905, model__gamma=2, model__learning_rate=0.5736481967628337, model__max_delta_step=14, model__max_depth=4, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=16.08828817508725, model__subsample=0.9654648425589478, scale=passthrough, score=0.803, total=   3.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.35612969648125914, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.027575612985359214, model__max_delta_step=0, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=90.96557432140554, model__subsample=1.0, scale=passthrough 
[13:16:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.35612969648125914, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.027575612985359214, model__max_delta_step=0, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=90.96557432140554, model__subsample=1.0, scale=passthrough, score=0.820, total=  11.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6560569571142313, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.099536311198538, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=1, model__n_estimators=94, model__scale_pos_weight=1000.0, model__subsample=0.572266839191951, scale=passthrough 
[13:21:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6560569571142313, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.099536311198538, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=1, model__n_estimators=94, model__scale_pos_weight=1000.0, model__subsample=0.572266839191951, scale=passthrough, score=0.828, total=   9.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5810672524816962, model__colsample_bytree=0.7387973192421962, model__gamma=1, model__learning_rate=0.3466551095725686, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=3, model__n_estimators=143, model__scale_pos_weight=671.269873737053, model__subsample=0.9210538089708267, scale=passthrough 
[13:26:01] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5810672524816962, model__colsample_bytree=0.7387973192421962, model__gamma=1, model__learning_rate=0.3466551095725686, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=3, model__n_estimators=143, model__scale_pos_weight=671.269873737053, model__subsample=0.9210538089708267, scale=passthrough, score=0.817, total=  16.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7383482959082196, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09394733982427142, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.5309510763054156, scale=passthrough 
[13:31:06] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7383482959082196, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09394733982427142, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.5309510763054156, scale=passthrough, score=0.818, total=   7.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5078988934265182, model__colsample_bytree=0.8346246633266341, model__gamma=4, model__learning_rate=0.43750217377340134, model__max_delta_step=2, model__max_depth=13, model__min_child_weight=4, model__n_estimators=53, model__scale_pos_weight=7.209798890237415, model__subsample=0.6639515335369921, scale=passthrough 
[12:39:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5078988934265182, model__colsample_bytree=0.8346246633266341, model__gamma=4, model__learning_rate=0.43750217377340134, model__max_delta_step=2, model__max_depth=13, model__min_child_weight=4, model__n_estimators=53, model__scale_pos_weight=7.209798890237415, model__subsample=0.6639515335369921, scale=passthrough, score=0.808, total=   6.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.04051980750184009, model__max_delta_step=15, model__max_depth=20, model__min_child_weight=5, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:41:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.04051980750184009, model__max_delta_step=15, model__max_depth=20, model__min_child_weight=5, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.804, total=   1.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.30473733141436166, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.26300031954289427, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:44:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.30473733141436166, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.26300031954289427, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.813, total=   3.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.30710558780986585, model__colsample_bytree=0.7451117847409254, model__gamma=4, model__learning_rate=0.03979965805844932, model__max_delta_step=1, model__max_depth=20, model__min_child_weight=3, model__n_estimators=150, model__scale_pos_weight=73.2857211995429, model__subsample=1.0, scale=passthrough 
[12:48:09] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.30710558780986585, model__colsample_bytree=0.7451117847409254, model__gamma=4, model__learning_rate=0.03979965805844932, model__max_delta_step=1, model__max_depth=20, model__min_child_weight=3, model__n_estimators=150, model__scale_pos_weight=73.2857211995429, model__subsample=1.0, scale=passthrough, score=0.818, total=  12.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4561709681306783, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.05744678535505964, model__max_delta_step=8, model__max_depth=14, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.30013062014501, scale=passthrough 
[12:51:20] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4561709681306783, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.05744678535505964, model__max_delta_step=8, model__max_depth=14, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.30013062014501, scale=passthrough, score=0.813, total=   9.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7936756256804407, model__colsample_bytree=0.7257873766908297, model__gamma=5, model__learning_rate=0.030237589119733947, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=47.39578121166871, model__subsample=0.42602881074865684, scale=passthrough 
[12:55:15] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7936756256804407, model__colsample_bytree=0.7257873766908297, model__gamma=5, model__learning_rate=0.030237589119733947, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=47.39578121166871, model__subsample=0.42602881074865684, scale=passthrough, score=0.805, total=   4.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2626717566045728, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.061741286298299246, model__max_delta_step=11, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:59:10] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2626717566045728, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.061741286298299246, model__max_delta_step=11, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.821, total=   4.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5843600897185549, model__colsample_bytree=0.9430163495262514, model__gamma=1, model__learning_rate=0.1691671183377136, model__max_delta_step=5, model__max_depth=4, model__min_child_weight=10, model__n_estimators=51, model__scale_pos_weight=960.7489282692309, model__subsample=0.42952695098688654, scale=passthrough 
[13:01:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5843600897185549, model__colsample_bytree=0.9430163495262514, model__gamma=1, model__learning_rate=0.1691671183377136, model__max_delta_step=5, model__max_depth=4, model__min_child_weight=10, model__n_estimators=51, model__scale_pos_weight=960.7489282692309, model__subsample=0.42952695098688654, scale=passthrough, score=0.818, total=   2.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2589955559392077, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1386254927023557, model__max_delta_step=20, model__max_depth=9, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.5581625488060291, model__subsample=0.6289416747925071, scale=passthrough 
[13:05:12] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2589955559392077, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1386254927023557, model__max_delta_step=20, model__max_depth=9, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.5581625488060291, model__subsample=0.6289416747925071, scale=passthrough, score=0.819, total=   8.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8798568306611239, model__colsample_bytree=0.47270753775719826, model__gamma=1, model__learning_rate=0.037150031895065, model__max_delta_step=10, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=157.84093873250987, model__subsample=0.7285773004147215, scale=passthrough 
[13:08:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8798568306611239, model__colsample_bytree=0.47270753775719826, model__gamma=1, model__learning_rate=0.037150031895065, model__max_delta_step=10, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=157.84093873250987, model__subsample=0.7285773004147215, scale=passthrough, score=0.826, total=  19.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6748069479751319, model__colsample_bytree=0.9980520411215905, model__gamma=2, model__learning_rate=0.5736481967628337, model__max_delta_step=14, model__max_depth=4, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=16.08828817508725, model__subsample=0.9654648425589478, scale=passthrough 
[13:12:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6748069479751319, model__colsample_bytree=0.9980520411215905, model__gamma=2, model__learning_rate=0.5736481967628337, model__max_delta_step=14, model__max_depth=4, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=16.08828817508725, model__subsample=0.9654648425589478, scale=passthrough, score=0.823, total=   3.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2505428520452186, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.0803489186489822, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=100, model__scale_pos_weight=53.4291088650935, model__subsample=1.0, scale=passthrough 
[13:16:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2505428520452186, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.0803489186489822, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=100, model__scale_pos_weight=53.4291088650935, model__subsample=1.0, scale=passthrough, score=0.821, total=   6.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6019253335494583, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.04140404996605915, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7690437666379234, scale=passthrough 
[13:21:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6019253335494583, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.04140404996605915, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7690437666379234, scale=passthrough, score=0.818, total=  28.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5810672524816962, model__colsample_bytree=0.7387973192421962, model__gamma=1, model__learning_rate=0.3466551095725686, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=3, model__n_estimators=143, model__scale_pos_weight=671.269873737053, model__subsample=0.9210538089708267, scale=passthrough 
[13:26:01] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5810672524816962, model__colsample_bytree=0.7387973192421962, model__gamma=1, model__learning_rate=0.3466551095725686, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=3, model__n_estimators=143, model__scale_pos_weight=671.269873737053, model__subsample=0.9210538089708267, scale=passthrough, score=0.820, total=  16.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7383482959082196, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09394733982427142, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.5309510763054156, scale=passthrough 
[13:31:06] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7383482959082196, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09394733982427142, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.5309510763054156, scale=passthrough, score=0.822, total=   7.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5078988934265182, model__colsample_bytree=0.8346246633266341, model__gamma=4, model__learning_rate=0.43750217377340134, model__max_delta_step=2, model__max_depth=13, model__min_child_weight=4, model__n_estimators=53, model__scale_pos_weight=7.209798890237415, model__subsample=0.6639515335369921, scale=passthrough 
[12:39:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5078988934265182, model__colsample_bytree=0.8346246633266341, model__gamma=4, model__learning_rate=0.43750217377340134, model__max_delta_step=2, model__max_depth=13, model__min_child_weight=4, model__n_estimators=53, model__scale_pos_weight=7.209798890237415, model__subsample=0.6639515335369921, scale=passthrough, score=0.805, total=   6.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9985235150787968, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.18558997178831976, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=71.9368373769291, model__subsample=1.0, scale=passthrough 
[12:41:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9985235150787968, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.18558997178831976, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=71.9368373769291, model__subsample=1.0, scale=passthrough, score=0.814, total=  32.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7209883604008371, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.05711622673001165, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[12:45:21] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7209883604008371, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.05711622673001165, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.820, total=  22.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.33817897669411146, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1062929550762915, model__max_delta_step=0, model__max_depth=17, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:48:34] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.33817897669411146, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1062929550762915, model__max_delta_step=0, model__max_depth=17, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.811, total=  17.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5800812255247891, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.22521631668826875, model__max_delta_step=0, model__max_depth=4, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=599.6975396467072, model__subsample=0.3, scale=passthrough 
[12:51:49] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5800812255247891, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.22521631668826875, model__max_delta_step=0, model__max_depth=4, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=599.6975396467072, model__subsample=0.3, scale=passthrough, score=0.794, total=   5.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3729531833425515, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1927833680266232, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6966147668977061, scale=passthrough 
[12:55:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3729531833425515, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1927833680266232, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6966147668977061, scale=passthrough, score=0.812, total=  16.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.32620009304869785, model__colsample_bytree=0.575801209690553, model__gamma=5, model__learning_rate=0.010375661400059702, model__max_delta_step=7, model__max_depth=10, model__min_child_weight=10, model__n_estimators=107, model__scale_pos_weight=29.14660215561998, model__subsample=0.8964223262021889, scale=passthrough 
[12:59:19] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.32620009304869785, model__colsample_bytree=0.575801209690553, model__gamma=5, model__learning_rate=0.010375661400059702, model__max_delta_step=7, model__max_depth=10, model__min_child_weight=10, model__n_estimators=107, model__scale_pos_weight=29.14660215561998, model__subsample=0.8964223262021889, scale=passthrough, score=0.809, total=   5.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.13518078933230862, model__colsample_bytree=0.7554546456232811, model__gamma=4, model__learning_rate=0.2447022723549562, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=9, model__n_estimators=145, model__scale_pos_weight=15.633109434047906, model__subsample=0.8502072361448936, scale=passthrough 
[13:01:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.13518078933230862, model__colsample_bytree=0.7554546456232811, model__gamma=4, model__learning_rate=0.2447022723549562, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=9, model__n_estimators=145, model__scale_pos_weight=15.633109434047906, model__subsample=0.8502072361448936, scale=passthrough, score=0.820, total=   1.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3117389972617159, model__colsample_bytree=0.5195135091613654, model__gamma=2, model__learning_rate=0.04768913109523132, model__max_delta_step=19, model__max_depth=13, model__min_child_weight=9, model__n_estimators=145, model__scale_pos_weight=358.5890063939114, model__subsample=0.9982940573627086, scale=passthrough 
[13:05:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3117389972617159, model__colsample_bytree=0.5195135091613654, model__gamma=2, model__learning_rate=0.04768913109523132, model__max_delta_step=19, model__max_depth=13, model__min_child_weight=9, model__n_estimators=145, model__scale_pos_weight=358.5890063939114, model__subsample=0.9982940573627086, scale=passthrough, score=0.817, total=   6.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9936699207860689, model__colsample_bytree=0.6645441411502944, model__gamma=3, model__learning_rate=0.26303546610593215, model__max_delta_step=7, model__max_depth=19, model__min_child_weight=8, model__n_estimators=149, model__scale_pos_weight=3.5400627108435816, model__subsample=0.36048433514513245, scale=passthrough 
[13:09:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9936699207860689, model__colsample_bytree=0.6645441411502944, model__gamma=3, model__learning_rate=0.26303546610593215, model__max_delta_step=7, model__max_depth=19, model__min_child_weight=8, model__n_estimators=149, model__scale_pos_weight=3.5400627108435816, model__subsample=0.36048433514513245, scale=passthrough, score=0.821, total=   9.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.06852714836629802, model__colsample_bytree=0.6721648535255251, model__gamma=4, model__learning_rate=0.9786052823132902, model__max_delta_step=19, model__max_depth=19, model__min_child_weight=6, model__n_estimators=93, model__scale_pos_weight=15.114368867960748, model__subsample=0.99098756513387, scale=passthrough 
[13:12:37] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.06852714836629802, model__colsample_bytree=0.6721648535255251, model__gamma=4, model__learning_rate=0.9786052823132902, model__max_delta_step=19, model__max_depth=19, model__min_child_weight=6, model__n_estimators=93, model__scale_pos_weight=15.114368867960748, model__subsample=0.99098756513387, scale=passthrough, score=0.788, total=   1.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2505428520452186, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.0803489186489822, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=100, model__scale_pos_weight=53.4291088650935, model__subsample=1.0, scale=passthrough 
[13:16:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2505428520452186, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.0803489186489822, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=100, model__scale_pos_weight=53.4291088650935, model__subsample=1.0, scale=passthrough, score=0.821, total=   6.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6019253335494583, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.04140404996605915, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7690437666379234, scale=passthrough 
[13:21:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6019253335494583, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.04140404996605915, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7690437666379234, scale=passthrough, score=0.822, total=  28.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2966494369105463, model__colsample_bytree=0.5631636618221096, model__gamma=1, model__learning_rate=0.0920789831417371, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=16.164741746637798, model__subsample=0.7366027336456855, scale=passthrough 
[13:26:30] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2966494369105463, model__colsample_bytree=0.5631636618221096, model__gamma=1, model__learning_rate=0.0920789831417371, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=16.164741746637798, model__subsample=0.7366027336456855, scale=passthrough, score=0.816, total=   2.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.837983323976336, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.1501763422891961, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7933790621572603, scale=passthrough 
[13:31:27] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.837983323976336, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.1501763422891961, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7933790621572603, scale=passthrough, score=0.813, total=   9.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.787035117607132, model__colsample_bytree=0.7112453824126441, model__gamma=4, model__learning_rate=0.02079837150135237, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=4, model__n_estimators=78, model__scale_pos_weight=249.52308451288775, model__subsample=0.9976698378005269, scale=passthrough 
[12:39:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.787035117607132, model__colsample_bytree=0.7112453824126441, model__gamma=4, model__learning_rate=0.02079837150135237, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=4, model__n_estimators=78, model__scale_pos_weight=249.52308451288775, model__subsample=0.9976698378005269, scale=passthrough, score=0.808, total=  16.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9985235150787968, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.18558997178831976, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=71.9368373769291, model__subsample=1.0, scale=passthrough 
[12:41:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9985235150787968, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.18558997178831976, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=71.9368373769291, model__subsample=1.0, scale=passthrough, score=0.815, total=  31.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=1.0, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=51, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:45:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=1.0, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=51, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.788, total=  17.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.33817897669411146, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1062929550762915, model__max_delta_step=0, model__max_depth=17, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:48:34] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.33817897669411146, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1062929550762915, model__max_delta_step=0, model__max_depth=17, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.814, total=  16.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.54122389035169, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.42272303291809443, model__max_delta_step=20, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:51:34] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.54122389035169, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.42272303291809443, model__max_delta_step=20, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.817, total=  11.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3729531833425515, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1927833680266232, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6966147668977061, scale=passthrough 
[12:55:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3729531833425515, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1927833680266232, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6966147668977061, scale=passthrough, score=0.808, total=  16.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.32620009304869785, model__colsample_bytree=0.575801209690553, model__gamma=5, model__learning_rate=0.010375661400059702, model__max_delta_step=7, model__max_depth=10, model__min_child_weight=10, model__n_estimators=107, model__scale_pos_weight=29.14660215561998, model__subsample=0.8964223262021889, scale=passthrough 
[12:59:19] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.32620009304869785, model__colsample_bytree=0.575801209690553, model__gamma=5, model__learning_rate=0.010375661400059702, model__max_delta_step=7, model__max_depth=10, model__min_child_weight=10, model__n_estimators=107, model__scale_pos_weight=29.14660215561998, model__subsample=0.8964223262021889, scale=passthrough, score=0.798, total=   5.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7306643321598706, model__colsample_bytree=0.9047106324665182, model__gamma=3, model__learning_rate=0.289680856607798, model__max_delta_step=2, model__max_depth=5, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=4.830750396431991, model__subsample=0.682152373341296, scale=passthrough 
[13:01:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7306643321598706, model__colsample_bytree=0.9047106324665182, model__gamma=3, model__learning_rate=0.289680856607798, model__max_delta_step=2, model__max_depth=5, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=4.830750396431991, model__subsample=0.682152373341296, scale=passthrough, score=0.809, total=   3.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3117389972617159, model__colsample_bytree=0.5195135091613654, model__gamma=2, model__learning_rate=0.04768913109523132, model__max_delta_step=19, model__max_depth=13, model__min_child_weight=9, model__n_estimators=145, model__scale_pos_weight=358.5890063939114, model__subsample=0.9982940573627086, scale=passthrough 
[13:05:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3117389972617159, model__colsample_bytree=0.5195135091613654, model__gamma=2, model__learning_rate=0.04768913109523132, model__max_delta_step=19, model__max_depth=13, model__min_child_weight=9, model__n_estimators=145, model__scale_pos_weight=358.5890063939114, model__subsample=0.9982940573627086, scale=passthrough, score=0.827, total=   6.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.37124359452914657, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.2387793343534091, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=431.54562714290086, model__subsample=0.7257653442730212, scale=passthrough 
[13:09:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.37124359452914657, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.2387793343534091, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=431.54562714290086, model__subsample=0.7257653442730212, scale=passthrough, score=0.816, total=   1.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.11754292344143252, model__colsample_bytree=0.3717176663785936, model__gamma=5, model__learning_rate=0.4194700852049675, model__max_delta_step=16, model__max_depth=3, model__min_child_weight=1, model__n_estimators=133, model__scale_pos_weight=591.7767669297752, model__subsample=0.3659602277225823, scale=passthrough 
[13:12:48] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.11754292344143252, model__colsample_bytree=0.3717176663785936, model__gamma=5, model__learning_rate=0.4194700852049675, model__max_delta_step=16, model__max_depth=3, model__min_child_weight=1, model__n_estimators=133, model__scale_pos_weight=591.7767669297752, model__subsample=0.3659602277225823, scale=passthrough, score=0.790, total=   0.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.28381391345916734, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16756239530200986, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7043083452715965, scale=passthrough 
[13:17:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.28381391345916734, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16756239530200986, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7043083452715965, scale=passthrough, score=0.825, total=   3.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4294194035519802, model__colsample_bytree=0.9985425452472365, model__gamma=3, model__learning_rate=0.04074439657930806, model__max_delta_step=11, model__max_depth=4, model__min_child_weight=2, model__n_estimators=50, model__scale_pos_weight=5.056400141838011, model__subsample=0.3276436882498791, scale=passthrough 
[13:22:08] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4294194035519802, model__colsample_bytree=0.9985425452472365, model__gamma=3, model__learning_rate=0.04074439657930806, model__max_delta_step=11, model__max_depth=4, model__min_child_weight=2, model__n_estimators=50, model__scale_pos_weight=5.056400141838011, model__subsample=0.3276436882498791, scale=passthrough, score=0.804, total=   1.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2966494369105463, model__colsample_bytree=0.5631636618221096, model__gamma=1, model__learning_rate=0.0920789831417371, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=16.164741746637798, model__subsample=0.7366027336456855, scale=passthrough 
[13:26:30] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2966494369105463, model__colsample_bytree=0.5631636618221096, model__gamma=1, model__learning_rate=0.0920789831417371, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=16.164741746637798, model__subsample=0.7366027336456855, scale=passthrough, score=0.815, total=   2.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.837983323976336, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.1501763422891961, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7933790621572603, scale=passthrough 
[13:31:27] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.837983323976336, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.1501763422891961, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7933790621572603, scale=passthrough, score=0.817, total=   9.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.036013135558974105, model__colsample_bytree=0.6770798813716852, model__gamma=1, model__learning_rate=0.35384207897748293, model__max_delta_step=7, model__max_depth=14, model__min_child_weight=4, model__n_estimators=141, model__scale_pos_weight=13.587798533272867, model__subsample=0.7134838459802921, scale=passthrough 
[12:39:45] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.036013135558974105, model__colsample_bytree=0.6770798813716852, model__gamma=1, model__learning_rate=0.35384207897748293, model__max_delta_step=7, model__max_depth=14, model__min_child_weight=4, model__n_estimators=141, model__scale_pos_weight=13.587798533272867, model__subsample=0.7134838459802921, scale=passthrough, score=0.792, total=   2.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.1420774216790083, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.4509992641426783, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=8, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.8623998033233848, scale=passthrough 
[12:41:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.1420774216790083, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.4509992641426783, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=8, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.8623998033233848, scale=passthrough, score=0.812, total=   1.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.30473733141436166, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.26300031954289427, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:44:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.30473733141436166, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.26300031954289427, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.809, total=   3.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.23848993246804506, model__colsample_bytree=0.9097869239684406, model__gamma=3, model__learning_rate=0.07521545489840264, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=14.096088207945458, model__subsample=0.3, scale=passthrough 
[12:48:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.23848993246804506, model__colsample_bytree=0.9097869239684406, model__gamma=3, model__learning_rate=0.07521545489840264, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=14.096088207945458, model__subsample=0.3, scale=passthrough, score=0.808, total=   5.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4561709681306783, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.05744678535505964, model__max_delta_step=8, model__max_depth=14, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.30013062014501, scale=passthrough 
[12:51:20] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4561709681306783, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.05744678535505964, model__max_delta_step=8, model__max_depth=14, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.30013062014501, scale=passthrough, score=0.817, total=  10.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.596005016271846, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.15313504883569234, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6736223814213212, scale=passthrough 
[12:55:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.596005016271846, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.15313504883569234, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6736223814213212, scale=passthrough, score=0.818, total=   7.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2626717566045728, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.061741286298299246, model__max_delta_step=11, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:59:10] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2626717566045728, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.061741286298299246, model__max_delta_step=11, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.825, total=   4.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.13518078933230862, model__colsample_bytree=0.7554546456232811, model__gamma=4, model__learning_rate=0.2447022723549562, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=9, model__n_estimators=145, model__scale_pos_weight=15.633109434047906, model__subsample=0.8502072361448936, scale=passthrough 
[13:01:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.13518078933230862, model__colsample_bytree=0.7554546456232811, model__gamma=4, model__learning_rate=0.2447022723549562, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=9, model__n_estimators=145, model__scale_pos_weight=15.633109434047906, model__subsample=0.8502072361448936, scale=passthrough, score=0.811, total=   1.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2589955559392077, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1386254927023557, model__max_delta_step=20, model__max_depth=9, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.5581625488060291, model__subsample=0.6289416747925071, scale=passthrough 
[13:05:12] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2589955559392077, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1386254927023557, model__max_delta_step=20, model__max_depth=9, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.5581625488060291, model__subsample=0.6289416747925071, scale=passthrough, score=0.827, total=   8.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9936699207860689, model__colsample_bytree=0.6645441411502944, model__gamma=3, model__learning_rate=0.26303546610593215, model__max_delta_step=7, model__max_depth=19, model__min_child_weight=8, model__n_estimators=149, model__scale_pos_weight=3.5400627108435816, model__subsample=0.36048433514513245, scale=passthrough 
[13:09:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9936699207860689, model__colsample_bytree=0.6645441411502944, model__gamma=3, model__learning_rate=0.26303546610593215, model__max_delta_step=7, model__max_depth=19, model__min_child_weight=8, model__n_estimators=149, model__scale_pos_weight=3.5400627108435816, model__subsample=0.36048433514513245, scale=passthrough, score=0.803, total=   9.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.06852714836629802, model__colsample_bytree=0.6721648535255251, model__gamma=4, model__learning_rate=0.9786052823132902, model__max_delta_step=19, model__max_depth=19, model__min_child_weight=6, model__n_estimators=93, model__scale_pos_weight=15.114368867960748, model__subsample=0.99098756513387, scale=passthrough 
[13:12:37] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.06852714836629802, model__colsample_bytree=0.6721648535255251, model__gamma=4, model__learning_rate=0.9786052823132902, model__max_delta_step=19, model__max_depth=19, model__min_child_weight=6, model__n_estimators=93, model__scale_pos_weight=15.114368867960748, model__subsample=0.99098756513387, scale=passthrough, score=0.789, total=   1.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.28381391345916734, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16756239530200986, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7043083452715965, scale=passthrough 
[13:17:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.28381391345916734, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16756239530200986, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7043083452715965, scale=passthrough, score=0.821, total=   3.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4294194035519802, model__colsample_bytree=0.9985425452472365, model__gamma=3, model__learning_rate=0.04074439657930806, model__max_delta_step=11, model__max_depth=4, model__min_child_weight=2, model__n_estimators=50, model__scale_pos_weight=5.056400141838011, model__subsample=0.3276436882498791, scale=passthrough 
[13:22:08] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4294194035519802, model__colsample_bytree=0.9985425452472365, model__gamma=3, model__learning_rate=0.04074439657930806, model__max_delta_step=11, model__max_depth=4, model__min_child_weight=2, model__n_estimators=50, model__scale_pos_weight=5.056400141838011, model__subsample=0.3276436882498791, scale=passthrough, score=0.801, total=   1.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2966494369105463, model__colsample_bytree=0.5631636618221096, model__gamma=1, model__learning_rate=0.0920789831417371, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=16.164741746637798, model__subsample=0.7366027336456855, scale=passthrough 
[13:26:30] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2966494369105463, model__colsample_bytree=0.5631636618221096, model__gamma=1, model__learning_rate=0.0920789831417371, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=16.164741746637798, model__subsample=0.7366027336456855, scale=passthrough, score=0.818, total=   2.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.837983323976336, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.1501763422891961, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7933790621572603, scale=passthrough 
[13:31:27] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.837983323976336, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.1501763422891961, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7933790621572603, scale=passthrough, score=0.826, total=   9.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.787035117607132, model__colsample_bytree=0.7112453824126441, model__gamma=4, model__learning_rate=0.02079837150135237, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=4, model__n_estimators=78, model__scale_pos_weight=249.52308451288775, model__subsample=0.9976698378005269, scale=passthrough 
[12:39:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.787035117607132, model__colsample_bytree=0.7112453824126441, model__gamma=4, model__learning_rate=0.02079837150135237, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=4, model__n_estimators=78, model__scale_pos_weight=249.52308451288775, model__subsample=0.9976698378005269, scale=passthrough, score=0.811, total=  16.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6372693350745634, model__colsample_bytree=0.856279090521453, model__gamma=4, model__learning_rate=0.01, model__max_delta_step=14, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[12:42:10] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6372693350745634, model__colsample_bytree=0.856279090521453, model__gamma=4, model__learning_rate=0.01, model__max_delta_step=14, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.768, total=   4.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7209883604008371, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.05711622673001165, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[12:45:21] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7209883604008371, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.05711622673001165, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.808, total=  23.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5506653020270686, model__colsample_bytree=0.9878808042703486, model__gamma=1, model__learning_rate=0.9418344688387262, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=149, model__scale_pos_weight=3.118852246044101, model__subsample=1.0, scale=passthrough 
[12:48:54] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5506653020270686, model__colsample_bytree=0.9878808042703486, model__gamma=1, model__learning_rate=0.9418344688387262, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=149, model__scale_pos_weight=3.118852246044101, model__subsample=1.0, scale=passthrough, score=0.806, total=   6.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.773545840828518, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.11718196680162268, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[12:51:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.773545840828518, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.11718196680162268, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.806, total=  13.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.17881855116962453, model__colsample_bytree=0.9439760336166867, model__gamma=1, model__learning_rate=0.10711338444861279, model__max_delta_step=0, model__max_depth=16, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=16.736349345470014, model__subsample=0.3, scale=passthrough 
[12:55:57] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.17881855116962453, model__colsample_bytree=0.9439760336166867, model__gamma=1, model__learning_rate=0.10711338444861279, model__max_delta_step=0, model__max_depth=16, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=16.736349345470014, model__subsample=0.3, scale=passthrough, score=0.814, total=   4.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8624028593474139, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.119961338472243, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7712371023169001, scale=passthrough 
[12:59:30] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8624028593474139, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.119961338472243, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7712371023169001, scale=passthrough, score=0.822, total=   9.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7306643321598706, model__colsample_bytree=0.9047106324665182, model__gamma=3, model__learning_rate=0.289680856607798, model__max_delta_step=2, model__max_depth=5, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=4.830750396431991, model__subsample=0.682152373341296, scale=passthrough 
[13:01:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7306643321598706, model__colsample_bytree=0.9047106324665182, model__gamma=3, model__learning_rate=0.289680856607798, model__max_delta_step=2, model__max_depth=5, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=4.830750396431991, model__subsample=0.682152373341296, scale=passthrough, score=0.807, total=   3.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3117389972617159, model__colsample_bytree=0.5195135091613654, model__gamma=2, model__learning_rate=0.04768913109523132, model__max_delta_step=19, model__max_depth=13, model__min_child_weight=9, model__n_estimators=145, model__scale_pos_weight=358.5890063939114, model__subsample=0.9982940573627086, scale=passthrough 
[13:05:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3117389972617159, model__colsample_bytree=0.5195135091613654, model__gamma=2, model__learning_rate=0.04768913109523132, model__max_delta_step=19, model__max_depth=13, model__min_child_weight=9, model__n_estimators=145, model__scale_pos_weight=358.5890063939114, model__subsample=0.9982940573627086, scale=passthrough, score=0.819, total=   6.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9936699207860689, model__colsample_bytree=0.6645441411502944, model__gamma=3, model__learning_rate=0.26303546610593215, model__max_delta_step=7, model__max_depth=19, model__min_child_weight=8, model__n_estimators=149, model__scale_pos_weight=3.5400627108435816, model__subsample=0.36048433514513245, scale=passthrough 
[13:09:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9936699207860689, model__colsample_bytree=0.6645441411502944, model__gamma=3, model__learning_rate=0.26303546610593215, model__max_delta_step=7, model__max_depth=19, model__min_child_weight=8, model__n_estimators=149, model__scale_pos_weight=3.5400627108435816, model__subsample=0.36048433514513245, scale=passthrough, score=0.801, total=   9.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.11754292344143252, model__colsample_bytree=0.3717176663785936, model__gamma=5, model__learning_rate=0.4194700852049675, model__max_delta_step=16, model__max_depth=3, model__min_child_weight=1, model__n_estimators=133, model__scale_pos_weight=591.7767669297752, model__subsample=0.3659602277225823, scale=passthrough 
[13:12:48] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.11754292344143252, model__colsample_bytree=0.3717176663785936, model__gamma=5, model__learning_rate=0.4194700852049675, model__max_delta_step=16, model__max_depth=3, model__min_child_weight=1, model__n_estimators=133, model__scale_pos_weight=591.7767669297752, model__subsample=0.3659602277225823, scale=passthrough, score=0.793, total=   0.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.28381391345916734, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16756239530200986, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7043083452715965, scale=passthrough 
[13:17:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.28381391345916734, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16756239530200986, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7043083452715965, scale=passthrough, score=0.823, total=   3.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4294194035519802, model__colsample_bytree=0.9985425452472365, model__gamma=3, model__learning_rate=0.04074439657930806, model__max_delta_step=11, model__max_depth=4, model__min_child_weight=2, model__n_estimators=50, model__scale_pos_weight=5.056400141838011, model__subsample=0.3276436882498791, scale=passthrough 
[13:22:08] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4294194035519802, model__colsample_bytree=0.9985425452472365, model__gamma=3, model__learning_rate=0.04074439657930806, model__max_delta_step=11, model__max_depth=4, model__min_child_weight=2, model__n_estimators=50, model__scale_pos_weight=5.056400141838011, model__subsample=0.3276436882498791, scale=passthrough, score=0.812, total=   1.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.981045325174474, model__colsample_bytree=0.5264717163452097, model__gamma=3, model__learning_rate=0.01193916349064292, model__max_delta_step=10, model__max_depth=10, model__min_child_weight=9, model__n_estimators=147, model__scale_pos_weight=162.41796391491437, model__subsample=0.3016928308053273, scale=passthrough 
[13:26:46] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.981045325174474, model__colsample_bytree=0.5264717163452097, model__gamma=3, model__learning_rate=0.01193916349064292, model__max_delta_step=10, model__max_depth=10, model__min_child_weight=9, model__n_estimators=147, model__scale_pos_weight=162.41796391491437, model__subsample=0.3016928308053273, scale=passthrough, score=0.778, total=   7.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.503220179218465, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16994682863716545, model__max_delta_step=4, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=0.7902666752934907, scale=passthrough 
[13:31:51] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.503220179218465, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16994682863716545, model__max_delta_step=4, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=0.7902666752934907, scale=passthrough, score=0.821, total=   2.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2378981683448771, model__colsample_bytree=0.4246854599411771, model__gamma=3, model__learning_rate=0.5679480397376981, model__max_delta_step=13, model__max_depth=14, model__min_child_weight=9, model__n_estimators=89, model__scale_pos_weight=1.9808702709217594, model__subsample=0.637798907679531, scale=passthrough 
[12:40:31] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2378981683448771, model__colsample_bytree=0.4246854599411771, model__gamma=3, model__learning_rate=0.5679480397376981, model__max_delta_step=13, model__max_depth=14, model__min_child_weight=9, model__n_estimators=89, model__scale_pos_weight=1.9808702709217594, model__subsample=0.637798907679531, scale=passthrough, score=0.782, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5463605528721855, model__colsample_bytree=0.7118040938283031, model__gamma=5, model__learning_rate=0.16951716523028687, model__max_delta_step=6, model__max_depth=14, model__min_child_weight=3, model__n_estimators=93, model__scale_pos_weight=1000.0, model__subsample=0.7509140215242676, scale=passthrough 
[12:42:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5463605528721855, model__colsample_bytree=0.7118040938283031, model__gamma=5, model__learning_rate=0.16951716523028687, model__max_delta_step=6, model__max_depth=14, model__min_child_weight=3, model__n_estimators=93, model__scale_pos_weight=1000.0, model__subsample=0.7509140215242676, scale=passthrough, score=0.819, total=   9.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6806280748235639, model__colsample_bytree=0.48764509248314014, model__gamma=5, model__learning_rate=0.09523406289357018, model__max_delta_step=0, model__max_depth=6, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:45:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6806280748235639, model__colsample_bytree=0.48764509248314014, model__gamma=5, model__learning_rate=0.09523406289357018, model__max_delta_step=0, model__max_depth=6, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.814, total=   6.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3487729741375725, model__colsample_bytree=0.9093771692550638, model__gamma=4, model__learning_rate=0.03255609651115708, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=1, model__n_estimators=87, model__scale_pos_weight=57.66714231001726, model__subsample=1.0, scale=passthrough 
[12:49:03] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3487729741375725, model__colsample_bytree=0.9093771692550638, model__gamma=4, model__learning_rate=0.03255609651115708, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=1, model__n_estimators=87, model__scale_pos_weight=57.66714231001726, model__subsample=1.0, scale=passthrough, score=0.812, total=   8.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.773545840828518, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.11718196680162268, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[12:51:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.773545840828518, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.11718196680162268, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.815, total=  13.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.17881855116962453, model__colsample_bytree=0.9439760336166867, model__gamma=1, model__learning_rate=0.10711338444861279, model__max_delta_step=0, model__max_depth=16, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=16.736349345470014, model__subsample=0.3, scale=passthrough 
[12:55:57] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.17881855116962453, model__colsample_bytree=0.9439760336166867, model__gamma=1, model__learning_rate=0.10711338444861279, model__max_delta_step=0, model__max_depth=16, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=16.736349345470014, model__subsample=0.3, scale=passthrough, score=0.823, total=   4.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7480226532288533, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.14204556358464834, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6743244476697982, scale=passthrough 
[12:59:44] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7480226532288533, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.14204556358464834, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6743244476697982, scale=passthrough, score=0.824, total=   8.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6278104355427412, model__colsample_bytree=0.9340618268551624, model__gamma=1, model__learning_rate=0.07795317314610904, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.5342704969018652, scale=passthrough 
[13:02:08] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6278104355427412, model__colsample_bytree=0.9340618268551624, model__gamma=1, model__learning_rate=0.07795317314610904, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.5342704969018652, scale=passthrough, score=0.816, total=   6.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1124768899984001, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=2.7910206703123195, model__subsample=1.0, scale=passthrough 
[13:05:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1124768899984001, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=2.7910206703123195, model__subsample=1.0, scale=passthrough, score=0.815, total=  13.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.37124359452914657, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.2387793343534091, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=431.54562714290086, model__subsample=0.7257653442730212, scale=passthrough 
[13:09:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.37124359452914657, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.2387793343534091, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=431.54562714290086, model__subsample=0.7257653442730212, scale=passthrough, score=0.808, total=   1.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.11754292344143252, model__colsample_bytree=0.3717176663785936, model__gamma=5, model__learning_rate=0.4194700852049675, model__max_delta_step=16, model__max_depth=3, model__min_child_weight=1, model__n_estimators=133, model__scale_pos_weight=591.7767669297752, model__subsample=0.3659602277225823, scale=passthrough 
[13:12:48] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.11754292344143252, model__colsample_bytree=0.3717176663785936, model__gamma=5, model__learning_rate=0.4194700852049675, model__max_delta_step=16, model__max_depth=3, model__min_child_weight=1, model__n_estimators=133, model__scale_pos_weight=591.7767669297752, model__subsample=0.3659602277225823, scale=passthrough, score=0.803, total=   0.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5665127357805507, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07557817482194025, model__max_delta_step=20, model__max_depth=9, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=101.1085187309343, model__subsample=0.5929559335829364, scale=passthrough 
[13:17:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5665127357805507, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07557817482194025, model__max_delta_step=20, model__max_depth=9, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=101.1085187309343, model__subsample=0.5929559335829364, scale=passthrough, score=0.819, total=  17.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.16854968896737774, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.08028164532086843, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[13:22:23] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.16854968896737774, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.08028164532086843, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.815, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.981045325174474, model__colsample_bytree=0.5264717163452097, model__gamma=3, model__learning_rate=0.01193916349064292, model__max_delta_step=10, model__max_depth=10, model__min_child_weight=9, model__n_estimators=147, model__scale_pos_weight=162.41796391491437, model__subsample=0.3016928308053273, scale=passthrough 
[13:26:46] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.981045325174474, model__colsample_bytree=0.5264717163452097, model__gamma=3, model__learning_rate=0.01193916349064292, model__max_delta_step=10, model__max_depth=10, model__min_child_weight=9, model__n_estimators=147, model__scale_pos_weight=162.41796391491437, model__subsample=0.3016928308053273, scale=passthrough, score=0.801, total=   7.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.503220179218465, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16994682863716545, model__max_delta_step=4, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=0.7902666752934907, scale=passthrough 
[13:31:51] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.503220179218465, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16994682863716545, model__max_delta_step=4, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=0.7902666752934907, scale=passthrough, score=0.812, total=   2.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.804000760089205, model__colsample_bytree=0.87439356412997, model__gamma=2, model__learning_rate=0.09724451331363028, model__max_delta_step=8, model__max_depth=12, model__min_child_weight=5, model__n_estimators=91, model__scale_pos_weight=8.712236078372266, model__subsample=0.5590460523937827, scale=passthrough 
[12:40:17] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.804000760089205, model__colsample_bytree=0.87439356412997, model__gamma=2, model__learning_rate=0.09724451331363028, model__max_delta_step=8, model__max_depth=12, model__min_child_weight=5, model__n_estimators=91, model__scale_pos_weight=8.712236078372266, model__subsample=0.5590460523937827, scale=passthrough, score=0.821, total=  12.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6372693350745634, model__colsample_bytree=0.856279090521453, model__gamma=4, model__learning_rate=0.01, model__max_delta_step=14, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[12:42:10] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6372693350745634, model__colsample_bytree=0.856279090521453, model__gamma=4, model__learning_rate=0.01, model__max_delta_step=14, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.774, total=   4.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1581960850027507, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=2, model__n_estimators=50, model__scale_pos_weight=9.047961657876439, model__subsample=1.0, scale=passthrough 
[12:45:47] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1581960850027507, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=2, model__n_estimators=50, model__scale_pos_weight=9.047961657876439, model__subsample=1.0, scale=passthrough, score=0.735, total=   0.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5506653020270686, model__colsample_bytree=0.9878808042703486, model__gamma=1, model__learning_rate=0.9418344688387262, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=149, model__scale_pos_weight=3.118852246044101, model__subsample=1.0, scale=passthrough 
[12:48:54] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5506653020270686, model__colsample_bytree=0.9878808042703486, model__gamma=1, model__learning_rate=0.9418344688387262, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=149, model__scale_pos_weight=3.118852246044101, model__subsample=1.0, scale=passthrough, score=0.811, total=   6.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5800812255247891, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.22521631668826875, model__max_delta_step=0, model__max_depth=4, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=599.6975396467072, model__subsample=0.3, scale=passthrough 
[12:51:49] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5800812255247891, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.22521631668826875, model__max_delta_step=0, model__max_depth=4, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=599.6975396467072, model__subsample=0.3, scale=passthrough, score=0.818, total=   5.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.17881855116962453, model__colsample_bytree=0.9439760336166867, model__gamma=1, model__learning_rate=0.10711338444861279, model__max_delta_step=0, model__max_depth=16, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=16.736349345470014, model__subsample=0.3, scale=passthrough 
[12:55:57] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.17881855116962453, model__colsample_bytree=0.9439760336166867, model__gamma=1, model__learning_rate=0.10711338444861279, model__max_delta_step=0, model__max_depth=16, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=16.736349345470014, model__subsample=0.3, scale=passthrough, score=0.805, total=   4.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8624028593474139, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.119961338472243, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7712371023169001, scale=passthrough 
[12:59:30] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8624028593474139, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.119961338472243, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7712371023169001, scale=passthrough, score=0.828, total=   9.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6278104355427412, model__colsample_bytree=0.9340618268551624, model__gamma=1, model__learning_rate=0.07795317314610904, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.5342704969018652, scale=passthrough 
[13:02:08] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6278104355427412, model__colsample_bytree=0.9340618268551624, model__gamma=1, model__learning_rate=0.07795317314610904, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.5342704969018652, scale=passthrough, score=0.821, total=   6.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1124768899984001, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=2.7910206703123195, model__subsample=1.0, scale=passthrough 
[13:05:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1124768899984001, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=2.7910206703123195, model__subsample=1.0, scale=passthrough, score=0.816, total=  13.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.37124359452914657, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.2387793343534091, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=431.54562714290086, model__subsample=0.7257653442730212, scale=passthrough 
[13:09:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.37124359452914657, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.2387793343534091, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=431.54562714290086, model__subsample=0.7257653442730212, scale=passthrough, score=0.819, total=   1.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.06715616801878019, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7340131984203679, scale=passthrough 
[13:12:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.06715616801878019, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7340131984203679, scale=passthrough, score=0.815, total=   8.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5665127357805507, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07557817482194025, model__max_delta_step=20, model__max_depth=9, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=101.1085187309343, model__subsample=0.5929559335829364, scale=passthrough 
[13:17:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5665127357805507, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07557817482194025, model__max_delta_step=20, model__max_depth=9, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=101.1085187309343, model__subsample=0.5929559335829364, scale=passthrough, score=0.819, total=  17.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.16854968896737774, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.08028164532086843, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[13:22:23] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.16854968896737774, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.08028164532086843, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.822, total=   7.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.981045325174474, model__colsample_bytree=0.5264717163452097, model__gamma=3, model__learning_rate=0.01193916349064292, model__max_delta_step=10, model__max_depth=10, model__min_child_weight=9, model__n_estimators=147, model__scale_pos_weight=162.41796391491437, model__subsample=0.3016928308053273, scale=passthrough 
[13:26:46] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.981045325174474, model__colsample_bytree=0.5264717163452097, model__gamma=3, model__learning_rate=0.01193916349064292, model__max_delta_step=10, model__max_depth=10, model__min_child_weight=9, model__n_estimators=147, model__scale_pos_weight=162.41796391491437, model__subsample=0.3016928308053273, scale=passthrough, score=0.806, total=   7.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.503220179218465, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16994682863716545, model__max_delta_step=4, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=0.7902666752934907, scale=passthrough 
[13:31:51] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.503220179218465, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16994682863716545, model__max_delta_step=4, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=0.7902666752934907, scale=passthrough, score=0.821, total=   2.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.39232926160480097, model__gamma=1, model__learning_rate=1.0, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[12:40:44] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.39232926160480097, model__gamma=1, model__learning_rate=1.0, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.751, total=   2.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7765467128965023, model__colsample_bytree=0.47449772718627137, model__gamma=2, model__learning_rate=0.2169162634145997, model__max_delta_step=19, model__max_depth=20, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=9.675167622062212, model__subsample=0.90717348388679, scale=passthrough 
[12:42:48] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7765467128965023, model__colsample_bytree=0.47449772718627137, model__gamma=2, model__learning_rate=0.2169162634145997, model__max_delta_step=19, model__max_depth=20, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=9.675167622062212, model__subsample=0.90717348388679, scale=passthrough, score=0.826, total=  13.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5319250256040385, model__colsample_bytree=0.5421940677812587, model__gamma=4, model__learning_rate=0.041051773959994736, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:46:09] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5319250256040385, model__colsample_bytree=0.5421940677812587, model__gamma=4, model__learning_rate=0.041051773959994736, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.817, total=  12.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6586096224709334, model__colsample_bytree=0.3, model__gamma=4, model__learning_rate=0.06355706096516056, model__max_delta_step=1, model__max_depth=14, model__min_child_weight=10, model__n_estimators=55, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[12:49:25] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6586096224709334, model__colsample_bytree=0.3, model__gamma=4, model__learning_rate=0.06355706096516056, model__max_delta_step=1, model__max_depth=14, model__min_child_weight=10, model__n_estimators=55, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.808, total=   3.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.689713924422194, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.039397143036738566, model__max_delta_step=0, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:52:51] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.689713924422194, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.039397143036738566, model__max_delta_step=0, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.816, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8328798665656025, model__colsample_bytree=0.8641530432628106, model__gamma=5, model__learning_rate=0.18180439867552042, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.7641293579113424, model__subsample=0.7529559001830912, scale=passthrough 
[12:56:15] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8328798665656025, model__colsample_bytree=0.8641530432628106, model__gamma=5, model__learning_rate=0.18180439867552042, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.7641293579113424, model__subsample=0.7529559001830912, scale=passthrough, score=0.823, total=  35.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2212595747279, model__colsample_bytree=0.8456003131367817, model__gamma=4, model__learning_rate=0.18767576643234232, model__max_delta_step=12, model__max_depth=7, model__min_child_weight=9, model__n_estimators=143, model__scale_pos_weight=732.8868593669005, model__subsample=0.48737223244557426, scale=passthrough 
[13:00:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2212595747279, model__colsample_bytree=0.8456003131367817, model__gamma=4, model__learning_rate=0.18767576643234232, model__max_delta_step=12, model__max_depth=7, model__min_child_weight=9, model__n_estimators=143, model__scale_pos_weight=732.8868593669005, model__subsample=0.48737223244557426, scale=passthrough, score=0.810, total=   3.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6509883200932527, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.18036595906132868, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7198184445399873, scale=passthrough 
[13:02:30] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6509883200932527, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.18036595906132868, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7198184445399873, scale=passthrough, score=0.817, total=   7.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8420342990824446, model__colsample_bytree=0.793823268897349, model__gamma=3, model__learning_rate=0.1494590893130938, model__max_delta_step=14, model__max_depth=4, model__min_child_weight=1, model__n_estimators=149, model__scale_pos_weight=182.2988537761414, model__subsample=0.7000085627096705, scale=passthrough 
[13:06:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8420342990824446, model__colsample_bytree=0.793823268897349, model__gamma=3, model__learning_rate=0.1494590893130938, model__max_delta_step=14, model__max_depth=4, model__min_child_weight=1, model__n_estimators=149, model__scale_pos_weight=182.2988537761414, model__subsample=0.7000085627096705, scale=passthrough, score=0.812, total=  10.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3610289879511644, model__colsample_bytree=0.8794040949446551, model__gamma=1, model__learning_rate=0.07114080874500128, model__max_delta_step=7, model__max_depth=3, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[13:10:01] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3610289879511644, model__colsample_bytree=0.8794040949446551, model__gamma=1, model__learning_rate=0.07114080874500128, model__max_delta_step=7, model__max_depth=3, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.812, total=   5.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6163527786738386, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10094658635968386, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1.142841169809037, model__subsample=0.66461683533738, scale=passthrough 
[13:13:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6163527786738386, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10094658635968386, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1.142841169809037, model__subsample=0.66461683533738, scale=passthrough, score=0.817, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7883810115957455, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10038810423698225, model__max_delta_step=20, model__max_depth=5, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.705046821629796, scale=passthrough 
[13:17:56] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7883810115957455, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10038810423698225, model__max_delta_step=20, model__max_depth=5, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.705046821629796, scale=passthrough, score=0.821, total=  13.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3287345894566851, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11907973975594477, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6051624223829977, scale=passthrough 
[13:22:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3287345894566851, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11907973975594477, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6051624223829977, scale=passthrough, score=0.818, total=   3.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7295693406448678, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11495791474302917, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=18.656186168499335, model__subsample=0.6540461186238449, scale=passthrough 
[13:27:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7295693406448678, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11495791474302917, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=18.656186168499335, model__subsample=0.6540461186238449, scale=passthrough, score=0.818, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.27864801763257824, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.0815770429427172, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[13:32:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.27864801763257824, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.0815770429427172, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.817, total=  10.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2378981683448771, model__colsample_bytree=0.4246854599411771, model__gamma=3, model__learning_rate=0.5679480397376981, model__max_delta_step=13, model__max_depth=14, model__min_child_weight=9, model__n_estimators=89, model__scale_pos_weight=1.9808702709217594, model__subsample=0.637798907679531, scale=passthrough 
[12:40:31] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2378981683448771, model__colsample_bytree=0.4246854599411771, model__gamma=3, model__learning_rate=0.5679480397376981, model__max_delta_step=13, model__max_depth=14, model__min_child_weight=9, model__n_estimators=89, model__scale_pos_weight=1.9808702709217594, model__subsample=0.637798907679531, scale=passthrough, score=0.808, total=   2.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5463605528721855, model__colsample_bytree=0.7118040938283031, model__gamma=5, model__learning_rate=0.16951716523028687, model__max_delta_step=6, model__max_depth=14, model__min_child_weight=3, model__n_estimators=93, model__scale_pos_weight=1000.0, model__subsample=0.7509140215242676, scale=passthrough 
[12:42:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5463605528721855, model__colsample_bytree=0.7118040938283031, model__gamma=5, model__learning_rate=0.16951716523028687, model__max_delta_step=6, model__max_depth=14, model__min_child_weight=3, model__n_estimators=93, model__scale_pos_weight=1000.0, model__subsample=0.7509140215242676, scale=passthrough, score=0.816, total=   9.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1581960850027507, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=2, model__n_estimators=50, model__scale_pos_weight=9.047961657876439, model__subsample=1.0, scale=passthrough 
[12:45:47] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1581960850027507, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=2, model__n_estimators=50, model__scale_pos_weight=9.047961657876439, model__subsample=1.0, scale=passthrough, score=0.761, total=   0.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3487729741375725, model__colsample_bytree=0.9093771692550638, model__gamma=4, model__learning_rate=0.03255609651115708, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=1, model__n_estimators=87, model__scale_pos_weight=57.66714231001726, model__subsample=1.0, scale=passthrough 
[12:49:03] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3487729741375725, model__colsample_bytree=0.9093771692550638, model__gamma=4, model__learning_rate=0.03255609651115708, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=1, model__n_estimators=87, model__scale_pos_weight=57.66714231001726, model__subsample=1.0, scale=passthrough, score=0.811, total=   8.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.773545840828518, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.11718196680162268, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[12:51:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.773545840828518, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.11718196680162268, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.808, total=  13.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5323120346429068, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.955995972082883, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:56:06] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5323120346429068, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.955995972082883, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.800, total=   4.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7480226532288533, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.14204556358464834, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6743244476697982, scale=passthrough 
[12:59:44] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7480226532288533, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.14204556358464834, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6743244476697982, scale=passthrough, score=0.827, total=   8.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6278104355427412, model__colsample_bytree=0.9340618268551624, model__gamma=1, model__learning_rate=0.07795317314610904, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.5342704969018652, scale=passthrough 
[13:02:08] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6278104355427412, model__colsample_bytree=0.9340618268551624, model__gamma=1, model__learning_rate=0.07795317314610904, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.5342704969018652, scale=passthrough, score=0.829, total=   6.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4421753592698282, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.3291395022208627, model__max_delta_step=19, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=218.85312393876526, model__subsample=0.6182771993189242, scale=passthrough 
[13:06:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4421753592698282, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.3291395022208627, model__max_delta_step=19, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=218.85312393876526, model__subsample=0.6182771993189242, scale=passthrough, score=0.812, total=   4.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9887257144971328, model__colsample_bytree=0.9110195960318892, model__gamma=2, model__learning_rate=0.8217627525189802, model__max_delta_step=3, model__max_depth=3, model__min_child_weight=10, model__n_estimators=145, model__scale_pos_weight=729.0973283235462, model__subsample=0.9877580955181187, scale=passthrough 
[13:09:41] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9887257144971328, model__colsample_bytree=0.9110195960318892, model__gamma=2, model__learning_rate=0.8217627525189802, model__max_delta_step=3, model__max_depth=3, model__min_child_weight=10, model__n_estimators=145, model__scale_pos_weight=729.0973283235462, model__subsample=0.9877580955181187, scale=passthrough, score=0.813, total=  10.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.06715616801878019, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7340131984203679, scale=passthrough 
[13:12:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.06715616801878019, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7340131984203679, scale=passthrough, score=0.820, total=   8.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5665127357805507, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07557817482194025, model__max_delta_step=20, model__max_depth=9, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=101.1085187309343, model__subsample=0.5929559335829364, scale=passthrough 
[13:17:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5665127357805507, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07557817482194025, model__max_delta_step=20, model__max_depth=9, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=101.1085187309343, model__subsample=0.5929559335829364, scale=passthrough, score=0.826, total=  17.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.16854968896737774, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.08028164532086843, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[13:22:23] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.16854968896737774, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.08028164532086843, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.828, total=   7.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7295693406448678, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11495791474302917, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=18.656186168499335, model__subsample=0.6540461186238449, scale=passthrough 
[13:27:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7295693406448678, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11495791474302917, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=18.656186168499335, model__subsample=0.6540461186238449, scale=passthrough, score=0.828, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.27864801763257824, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.0815770429427172, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[13:32:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.27864801763257824, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.0815770429427172, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.817, total=  10.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.011902017182026462, model__colsample_bytree=0.7873661660413364, model__gamma=3, model__learning_rate=0.015215020717305742, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=4, model__n_estimators=129, model__scale_pos_weight=28.52738776154143, model__subsample=0.7086817848712379, scale=passthrough 
[12:40:37] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.011902017182026462, model__colsample_bytree=0.7873661660413364, model__gamma=3, model__learning_rate=0.015215020717305742, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=4, model__n_estimators=129, model__scale_pos_weight=28.52738776154143, model__subsample=0.7086817848712379, scale=passthrough, score=0.713, total=   2.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44570692226878567, model__colsample_bytree=0.9301667584195348, model__gamma=4, model__learning_rate=1.0, model__max_delta_step=14, model__max_depth=13, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=3.0252585215462067, model__subsample=0.948328801556569, scale=passthrough 
[12:42:29] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44570692226878567, model__colsample_bytree=0.9301667584195348, model__gamma=4, model__learning_rate=1.0, model__max_delta_step=14, model__max_depth=13, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=3.0252585215462067, model__subsample=0.948328801556569, scale=passthrough, score=0.804, total=  16.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6806280748235639, model__colsample_bytree=0.48764509248314014, model__gamma=5, model__learning_rate=0.09523406289357018, model__max_delta_step=0, model__max_depth=6, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:45:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6806280748235639, model__colsample_bytree=0.48764509248314014, model__gamma=5, model__learning_rate=0.09523406289357018, model__max_delta_step=0, model__max_depth=6, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.814, total=   6.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3487729741375725, model__colsample_bytree=0.9093771692550638, model__gamma=4, model__learning_rate=0.03255609651115708, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=1, model__n_estimators=87, model__scale_pos_weight=57.66714231001726, model__subsample=1.0, scale=passthrough 
[12:49:03] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3487729741375725, model__colsample_bytree=0.9093771692550638, model__gamma=4, model__learning_rate=0.03255609651115708, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=1, model__n_estimators=87, model__scale_pos_weight=57.66714231001726, model__subsample=1.0, scale=passthrough, score=0.818, total=   8.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4796817805920893, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.01470772226123463, model__max_delta_step=15, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:52:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4796817805920893, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.01470772226123463, model__max_delta_step=15, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.812, total=  29.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5323120346429068, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.955995972082883, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:56:06] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5323120346429068, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.955995972082883, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.808, total=   4.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7480226532288533, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.14204556358464834, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6743244476697982, scale=passthrough 
[12:59:44] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7480226532288533, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.14204556358464834, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6743244476697982, scale=passthrough, score=0.819, total=   8.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.484080037051211, model__colsample_bytree=0.9181123691412922, model__gamma=4, model__learning_rate=0.01, model__max_delta_step=10, model__max_depth=16, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=1.546040733397408, model__subsample=0.3, scale=passthrough 
[13:02:21] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.484080037051211, model__colsample_bytree=0.9181123691412922, model__gamma=4, model__learning_rate=0.01, model__max_delta_step=10, model__max_depth=16, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=1.546040733397408, model__subsample=0.3, scale=passthrough, score=0.804, total=   3.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4421753592698282, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.3291395022208627, model__max_delta_step=19, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=218.85312393876526, model__subsample=0.6182771993189242, scale=passthrough 
[13:06:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4421753592698282, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.3291395022208627, model__max_delta_step=19, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=218.85312393876526, model__subsample=0.6182771993189242, scale=passthrough, score=0.814, total=   4.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9887257144971328, model__colsample_bytree=0.9110195960318892, model__gamma=2, model__learning_rate=0.8217627525189802, model__max_delta_step=3, model__max_depth=3, model__min_child_weight=10, model__n_estimators=145, model__scale_pos_weight=729.0973283235462, model__subsample=0.9877580955181187, scale=passthrough 
[13:09:41] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9887257144971328, model__colsample_bytree=0.9110195960318892, model__gamma=2, model__learning_rate=0.8217627525189802, model__max_delta_step=3, model__max_depth=3, model__min_child_weight=10, model__n_estimators=145, model__scale_pos_weight=729.0973283235462, model__subsample=0.9877580955181187, scale=passthrough, score=0.821, total=  10.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.06715616801878019, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7340131984203679, scale=passthrough 
[13:12:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.06715616801878019, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7340131984203679, scale=passthrough, score=0.819, total=   8.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7883810115957455, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10038810423698225, model__max_delta_step=20, model__max_depth=5, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.705046821629796, scale=passthrough 
[13:17:56] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7883810115957455, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10038810423698225, model__max_delta_step=20, model__max_depth=5, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.705046821629796, scale=passthrough, score=0.822, total=  13.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3287345894566851, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11907973975594477, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6051624223829977, scale=passthrough 
[13:22:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3287345894566851, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11907973975594477, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6051624223829977, scale=passthrough, score=0.818, total=   3.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7295693406448678, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11495791474302917, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=18.656186168499335, model__subsample=0.6540461186238449, scale=passthrough 
[13:27:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7295693406448678, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11495791474302917, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=18.656186168499335, model__subsample=0.6540461186238449, scale=passthrough, score=0.826, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.27864801763257824, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.0815770429427172, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[13:32:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.27864801763257824, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.0815770429427172, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.822, total=  10.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5912298436097947, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.2372450606441309, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=184.62872204248956, model__subsample=1.0, scale=passthrough 
[12:40:51] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5912298436097947, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.2372450606441309, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=184.62872204248956, model__subsample=1.0, scale=passthrough, score=0.822, total=   3.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9120957067510712, model__colsample_bytree=0.5976528037728883, model__gamma=1, model__learning_rate=0.12761761072761757, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=2.0000521908976103, model__subsample=1.0, scale=passthrough 
[12:43:15] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9120957067510712, model__colsample_bytree=0.5976528037728883, model__gamma=1, model__learning_rate=0.12761761072761757, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=2.0000521908976103, model__subsample=1.0, scale=passthrough, score=0.809, total=  29.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4519864554659911, model__colsample_bytree=0.8366425105706587, model__gamma=5, model__learning_rate=0.18683460622727016, model__max_delta_step=9, model__max_depth=8, model__min_child_weight=1, model__n_estimators=107, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:46:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4519864554659911, model__colsample_bytree=0.8366425105706587, model__gamma=5, model__learning_rate=0.18683460622727016, model__max_delta_step=9, model__max_depth=8, model__min_child_weight=1, model__n_estimators=107, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.808, total=  10.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8567412002271322, model__colsample_bytree=0.8575671103085107, model__gamma=2, model__learning_rate=0.07465261039980901, model__max_delta_step=18, model__max_depth=3, model__min_child_weight=9, model__n_estimators=107, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[12:49:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8567412002271322, model__colsample_bytree=0.8575671103085107, model__gamma=2, model__learning_rate=0.07465261039980901, model__max_delta_step=18, model__max_depth=3, model__min_child_weight=9, model__n_estimators=107, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.811, total=   3.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7327427198317836, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.05318619770853978, model__max_delta_step=20, model__max_depth=5, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6714582277622831, scale=passthrough 
[12:52:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7327427198317836, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.05318619770853978, model__max_delta_step=20, model__max_depth=5, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6714582277622831, scale=passthrough, score=0.811, total=  14.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.29504087950548863, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.2177922599853049, model__max_delta_step=20, model__max_depth=17, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=173.66523151392474, model__subsample=0.3, scale=passthrough 
[12:56:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.29504087950548863, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.2177922599853049, model__max_delta_step=20, model__max_depth=17, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=173.66523151392474, model__subsample=0.3, scale=passthrough, score=0.806, total=   2.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2212595747279, model__colsample_bytree=0.8456003131367817, model__gamma=4, model__learning_rate=0.18767576643234232, model__max_delta_step=12, model__max_depth=7, model__min_child_weight=9, model__n_estimators=143, model__scale_pos_weight=732.8868593669005, model__subsample=0.48737223244557426, scale=passthrough 
[13:00:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2212595747279, model__colsample_bytree=0.8456003131367817, model__gamma=4, model__learning_rate=0.18767576643234232, model__max_delta_step=12, model__max_depth=7, model__min_child_weight=9, model__n_estimators=143, model__scale_pos_weight=732.8868593669005, model__subsample=0.48737223244557426, scale=passthrough, score=0.819, total=   3.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3144666704979742, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.15503232672208117, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=3, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6954064460144382, scale=passthrough 
[13:02:43] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3144666704979742, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.15503232672208117, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=3, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6954064460144382, scale=passthrough, score=0.827, total=   4.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7975556755091645, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.23661077950939263, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=203.09690651748897, model__subsample=1.0, scale=passthrough 
[13:06:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7975556755091645, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.23661077950939263, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=203.09690651748897, model__subsample=1.0, scale=passthrough, score=0.830, total=  10.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2848417324417165, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.1595137567347673, model__max_delta_step=7, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[13:10:13] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2848417324417165, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.1595137567347673, model__max_delta_step=7, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.816, total=   4.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7793269398106947, model__colsample_bytree=0.8460423420685759, model__gamma=4, model__learning_rate=0.4520210689634202, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=1, model__n_estimators=63, model__scale_pos_weight=11.716568798360003, model__subsample=0.8782649268360583, scale=passthrough 
[13:13:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7793269398106947, model__colsample_bytree=0.8460423420685759, model__gamma=4, model__learning_rate=0.4520210689634202, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=1, model__n_estimators=63, model__scale_pos_weight=11.716568798360003, model__subsample=0.8782649268360583, scale=passthrough, score=0.819, total=  15.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.46476812763552044, model__colsample_bytree=0.4279578966612934, model__gamma=4, model__learning_rate=0.01095924342794842, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=2, model__n_estimators=140, model__scale_pos_weight=2.0466633977771815, model__subsample=0.47493466094751796, scale=passthrough 
[13:18:20] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.46476812763552044, model__colsample_bytree=0.4279578966612934, model__gamma=4, model__learning_rate=0.01095924342794842, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=2, model__n_estimators=140, model__scale_pos_weight=2.0466633977771815, model__subsample=0.47493466094751796, scale=passthrough, score=0.809, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.15422998735889965, model__colsample_bytree=0.559080415297065, model__gamma=1, model__learning_rate=0.16521794081310845, model__max_delta_step=7, model__max_depth=16, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=658.1634602836999, model__subsample=1.0, scale=passthrough 
[13:22:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.15422998735889965, model__colsample_bytree=0.559080415297065, model__gamma=1, model__learning_rate=0.16521794081310845, model__max_delta_step=7, model__max_depth=16, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=658.1634602836999, model__subsample=1.0, scale=passthrough, score=0.814, total=   3.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7567370446384274, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11171291371452337, model__max_delta_step=20, model__max_depth=8, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7776434975141822, scale=passthrough 
[13:27:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7567370446384274, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11171291371452337, model__max_delta_step=20, model__max_depth=8, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7776434975141822, scale=passthrough, score=0.826, total=  19.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8619070312505364, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10597559475989468, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8016679277664882, scale=passthrough 
[13:32:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8619070312505364, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10597559475989468, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8016679277664882, scale=passthrough, score=0.820, total=  21.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.804000760089205, model__colsample_bytree=0.87439356412997, model__gamma=2, model__learning_rate=0.09724451331363028, model__max_delta_step=8, model__max_depth=12, model__min_child_weight=5, model__n_estimators=91, model__scale_pos_weight=8.712236078372266, model__subsample=0.5590460523937827, scale=passthrough 
[12:40:17] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.804000760089205, model__colsample_bytree=0.87439356412997, model__gamma=2, model__learning_rate=0.09724451331363028, model__max_delta_step=8, model__max_depth=12, model__min_child_weight=5, model__n_estimators=91, model__scale_pos_weight=8.712236078372266, model__subsample=0.5590460523937827, scale=passthrough, score=0.818, total=  12.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5463605528721855, model__colsample_bytree=0.7118040938283031, model__gamma=5, model__learning_rate=0.16951716523028687, model__max_delta_step=6, model__max_depth=14, model__min_child_weight=3, model__n_estimators=93, model__scale_pos_weight=1000.0, model__subsample=0.7509140215242676, scale=passthrough 
[12:42:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5463605528721855, model__colsample_bytree=0.7118040938283031, model__gamma=5, model__learning_rate=0.16951716523028687, model__max_delta_step=6, model__max_depth=14, model__min_child_weight=3, model__n_estimators=93, model__scale_pos_weight=1000.0, model__subsample=0.7509140215242676, scale=passthrough, score=0.809, total=   9.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1581960850027507, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=2, model__n_estimators=50, model__scale_pos_weight=9.047961657876439, model__subsample=1.0, scale=passthrough 
[12:45:47] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1581960850027507, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=2, model__n_estimators=50, model__scale_pos_weight=9.047961657876439, model__subsample=1.0, scale=passthrough, score=0.751, total=   0.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5506653020270686, model__colsample_bytree=0.9878808042703486, model__gamma=1, model__learning_rate=0.9418344688387262, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=149, model__scale_pos_weight=3.118852246044101, model__subsample=1.0, scale=passthrough 
[12:48:54] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5506653020270686, model__colsample_bytree=0.9878808042703486, model__gamma=1, model__learning_rate=0.9418344688387262, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=149, model__scale_pos_weight=3.118852246044101, model__subsample=1.0, scale=passthrough, score=0.799, total=   6.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5800812255247891, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.22521631668826875, model__max_delta_step=0, model__max_depth=4, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=599.6975396467072, model__subsample=0.3, scale=passthrough 
[12:51:49] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5800812255247891, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.22521631668826875, model__max_delta_step=0, model__max_depth=4, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=599.6975396467072, model__subsample=0.3, scale=passthrough, score=0.809, total=   5.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3729531833425515, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1927833680266232, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6966147668977061, scale=passthrough 
[12:55:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3729531833425515, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1927833680266232, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6966147668977061, scale=passthrough, score=0.824, total=  16.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8624028593474139, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.119961338472243, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7712371023169001, scale=passthrough 
[12:59:30] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8624028593474139, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.119961338472243, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7712371023169001, scale=passthrough, score=0.824, total=   9.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7306643321598706, model__colsample_bytree=0.9047106324665182, model__gamma=3, model__learning_rate=0.289680856607798, model__max_delta_step=2, model__max_depth=5, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=4.830750396431991, model__subsample=0.682152373341296, scale=passthrough 
[13:01:58] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7306643321598706, model__colsample_bytree=0.9047106324665182, model__gamma=3, model__learning_rate=0.289680856607798, model__max_delta_step=2, model__max_depth=5, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=4.830750396431991, model__subsample=0.682152373341296, scale=passthrough, score=0.819, total=   4.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1124768899984001, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=2.7910206703123195, model__subsample=1.0, scale=passthrough 
[13:05:42] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.1124768899984001, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=2.7910206703123195, model__subsample=1.0, scale=passthrough, score=0.821, total=  13.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9887257144971328, model__colsample_bytree=0.9110195960318892, model__gamma=2, model__learning_rate=0.8217627525189802, model__max_delta_step=3, model__max_depth=3, model__min_child_weight=10, model__n_estimators=145, model__scale_pos_weight=729.0973283235462, model__subsample=0.9877580955181187, scale=passthrough 
[13:09:41] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9887257144971328, model__colsample_bytree=0.9110195960318892, model__gamma=2, model__learning_rate=0.8217627525189802, model__max_delta_step=3, model__max_depth=3, model__min_child_weight=10, model__n_estimators=145, model__scale_pos_weight=729.0973283235462, model__subsample=0.9877580955181187, scale=passthrough, score=0.796, total=  10.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6163527786738386, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10094658635968386, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1.142841169809037, model__subsample=0.66461683533738, scale=passthrough 
[13:13:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6163527786738386, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10094658635968386, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1.142841169809037, model__subsample=0.66461683533738, scale=passthrough, score=0.826, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7883810115957455, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10038810423698225, model__max_delta_step=20, model__max_depth=5, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.705046821629796, scale=passthrough 
[13:17:56] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7883810115957455, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10038810423698225, model__max_delta_step=20, model__max_depth=5, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.705046821629796, scale=passthrough, score=0.826, total=  13.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3287345894566851, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11907973975594477, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6051624223829977, scale=passthrough 
[13:22:43] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3287345894566851, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11907973975594477, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6051624223829977, scale=passthrough, score=0.828, total=   3.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7567370446384274, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11171291371452337, model__max_delta_step=20, model__max_depth=8, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7776434975141822, scale=passthrough 
[13:27:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7567370446384274, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11171291371452337, model__max_delta_step=20, model__max_depth=8, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7776434975141822, scale=passthrough, score=0.825, total=  18.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8619070312505364, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10597559475989468, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8016679277664882, scale=passthrough 
[13:32:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8619070312505364, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10597559475989468, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8016679277664882, scale=passthrough, score=0.819, total=  22.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.011902017182026462, model__colsample_bytree=0.7873661660413364, model__gamma=3, model__learning_rate=0.015215020717305742, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=4, model__n_estimators=129, model__scale_pos_weight=28.52738776154143, model__subsample=0.7086817848712379, scale=passthrough 
[12:40:37] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.011902017182026462, model__colsample_bytree=0.7873661660413364, model__gamma=3, model__learning_rate=0.015215020717305742, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=4, model__n_estimators=129, model__scale_pos_weight=28.52738776154143, model__subsample=0.7086817848712379, scale=passthrough, score=0.764, total=   2.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7765467128965023, model__colsample_bytree=0.47449772718627137, model__gamma=2, model__learning_rate=0.2169162634145997, model__max_delta_step=19, model__max_depth=20, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=9.675167622062212, model__subsample=0.90717348388679, scale=passthrough 
[12:42:48] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7765467128965023, model__colsample_bytree=0.47449772718627137, model__gamma=2, model__learning_rate=0.2169162634145997, model__max_delta_step=19, model__max_depth=20, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=9.675167622062212, model__subsample=0.90717348388679, scale=passthrough, score=0.816, total=  13.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6690442908198551, model__colsample_bytree=0.9611093825304611, model__gamma=2, model__learning_rate=0.010735390356849636, model__max_delta_step=9, model__max_depth=11, model__min_child_weight=3, model__n_estimators=68, model__scale_pos_weight=14.770406100341361, model__subsample=0.36808154547666466, scale=passthrough 
[12:45:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6690442908198551, model__colsample_bytree=0.9611093825304611, model__gamma=2, model__learning_rate=0.010735390356849636, model__max_delta_step=9, model__max_depth=11, model__min_child_weight=3, model__n_estimators=68, model__scale_pos_weight=14.770406100341361, model__subsample=0.36808154547666466, scale=passthrough, score=0.811, total=   6.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6675765153644005, model__colsample_bytree=0.5505381326437495, model__gamma=2, model__learning_rate=0.4094607061353391, model__max_delta_step=0, model__max_depth=10, model__min_child_weight=5, model__n_estimators=113, model__scale_pos_weight=37.34055062512279, model__subsample=1.0, scale=passthrough 
[12:49:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6675765153644005, model__colsample_bytree=0.5505381326437495, model__gamma=2, model__learning_rate=0.4094607061353391, model__max_delta_step=0, model__max_depth=10, model__min_child_weight=5, model__n_estimators=113, model__scale_pos_weight=37.34055062512279, model__subsample=1.0, scale=passthrough, score=0.815, total=   8.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4796817805920893, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.01470772226123463, model__max_delta_step=15, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:52:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4796817805920893, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.01470772226123463, model__max_delta_step=15, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.804, total=  30.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8328798665656025, model__colsample_bytree=0.8641530432628106, model__gamma=5, model__learning_rate=0.18180439867552042, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.7641293579113424, model__subsample=0.7529559001830912, scale=passthrough 
[12:56:15] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8328798665656025, model__colsample_bytree=0.8641530432628106, model__gamma=5, model__learning_rate=0.18180439867552042, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.7641293579113424, model__subsample=0.7529559001830912, scale=passthrough, score=0.815, total=  34.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8441827290623279, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08088260623930922, model__max_delta_step=20, model__max_depth=4, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7800718254694903, scale=passthrough 
[12:59:57] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8441827290623279, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08088260623930922, model__max_delta_step=20, model__max_depth=4, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7800718254694903, scale=passthrough, score=0.827, total=  13.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.484080037051211, model__colsample_bytree=0.9181123691412922, model__gamma=4, model__learning_rate=0.01, model__max_delta_step=10, model__max_depth=16, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=1.546040733397408, model__subsample=0.3, scale=passthrough 
[13:02:21] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.484080037051211, model__colsample_bytree=0.9181123691412922, model__gamma=4, model__learning_rate=0.01, model__max_delta_step=10, model__max_depth=16, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=1.546040733397408, model__subsample=0.3, scale=passthrough, score=0.811, total=   3.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4421753592698282, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.3291395022208627, model__max_delta_step=19, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=218.85312393876526, model__subsample=0.6182771993189242, scale=passthrough 
[13:06:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4421753592698282, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.3291395022208627, model__max_delta_step=19, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=218.85312393876526, model__subsample=0.6182771993189242, scale=passthrough, score=0.812, total=   4.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3610289879511644, model__colsample_bytree=0.8794040949446551, model__gamma=1, model__learning_rate=0.07114080874500128, model__max_delta_step=7, model__max_depth=3, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[13:10:01] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3610289879511644, model__colsample_bytree=0.8794040949446551, model__gamma=1, model__learning_rate=0.07114080874500128, model__max_delta_step=7, model__max_depth=3, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.819, total=   5.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7793269398106947, model__colsample_bytree=0.8460423420685759, model__gamma=4, model__learning_rate=0.4520210689634202, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=1, model__n_estimators=63, model__scale_pos_weight=11.716568798360003, model__subsample=0.8782649268360583, scale=passthrough 
[13:13:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7793269398106947, model__colsample_bytree=0.8460423420685759, model__gamma=4, model__learning_rate=0.4520210689634202, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=1, model__n_estimators=63, model__scale_pos_weight=11.716568798360003, model__subsample=0.8782649268360583, scale=passthrough, score=0.809, total=  15.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.46476812763552044, model__colsample_bytree=0.4279578966612934, model__gamma=4, model__learning_rate=0.01095924342794842, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=2, model__n_estimators=140, model__scale_pos_weight=2.0466633977771815, model__subsample=0.47493466094751796, scale=passthrough 
[13:18:20] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.46476812763552044, model__colsample_bytree=0.4279578966612934, model__gamma=4, model__learning_rate=0.01095924342794842, model__max_delta_step=8, model__max_depth=20, model__min_child_weight=2, model__n_estimators=140, model__scale_pos_weight=2.0466633977771815, model__subsample=0.47493466094751796, scale=passthrough, score=0.823, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.15422998735889965, model__colsample_bytree=0.559080415297065, model__gamma=1, model__learning_rate=0.16521794081310845, model__max_delta_step=7, model__max_depth=16, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=658.1634602836999, model__subsample=1.0, scale=passthrough 
[13:22:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.15422998735889965, model__colsample_bytree=0.559080415297065, model__gamma=1, model__learning_rate=0.16521794081310845, model__max_delta_step=7, model__max_depth=16, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=658.1634602836999, model__subsample=1.0, scale=passthrough, score=0.824, total=   3.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7567370446384274, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11171291371452337, model__max_delta_step=20, model__max_depth=8, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7776434975141822, scale=passthrough 
[13:27:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7567370446384274, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11171291371452337, model__max_delta_step=20, model__max_depth=8, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7776434975141822, scale=passthrough, score=0.819, total=  19.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8619070312505364, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10597559475989468, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8016679277664882, scale=passthrough 
[13:32:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8619070312505364, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10597559475989468, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8016679277664882, scale=passthrough, score=0.823, total=  22.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5912298436097947, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.2372450606441309, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=184.62872204248956, model__subsample=1.0, scale=passthrough 
[12:40:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5912298436097947, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.2372450606441309, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=184.62872204248956, model__subsample=1.0, scale=passthrough, score=0.807, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.625380306995069, model__colsample_bytree=0.8514283442895596, model__gamma=5, model__learning_rate=0.41910787084766915, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.40915009963638754, scale=passthrough 
[12:43:03] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.625380306995069, model__colsample_bytree=0.8514283442895596, model__gamma=5, model__learning_rate=0.41910787084766915, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.40915009963638754, scale=passthrough, score=0.795, total=   9.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5319250256040385, model__colsample_bytree=0.5421940677812587, model__gamma=4, model__learning_rate=0.041051773959994736, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:46:09] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5319250256040385, model__colsample_bytree=0.5421940677812587, model__gamma=4, model__learning_rate=0.041051773959994736, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.827, total=  12.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6586096224709334, model__colsample_bytree=0.3, model__gamma=4, model__learning_rate=0.06355706096516056, model__max_delta_step=1, model__max_depth=14, model__min_child_weight=10, model__n_estimators=55, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[12:49:25] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6586096224709334, model__colsample_bytree=0.3, model__gamma=4, model__learning_rate=0.06355706096516056, model__max_delta_step=1, model__max_depth=14, model__min_child_weight=10, model__n_estimators=55, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.822, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7327427198317836, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.05318619770853978, model__max_delta_step=20, model__max_depth=5, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6714582277622831, scale=passthrough 
[12:52:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7327427198317836, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.05318619770853978, model__max_delta_step=20, model__max_depth=5, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6714582277622831, scale=passthrough, score=0.819, total=  14.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.29504087950548863, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.2177922599853049, model__max_delta_step=20, model__max_depth=17, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=173.66523151392474, model__subsample=0.3, scale=passthrough 
[12:56:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.29504087950548863, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.2177922599853049, model__max_delta_step=20, model__max_depth=17, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=173.66523151392474, model__subsample=0.3, scale=passthrough, score=0.818, total=   2.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9186093142414973, model__colsample_bytree=0.3426101106885372, model__gamma=2, model__learning_rate=0.9814305978851464, model__max_delta_step=11, model__max_depth=15, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=3.3351492261289715, model__subsample=0.986860683696918, scale=passthrough 
[13:00:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9186093142414973, model__colsample_bytree=0.3426101106885372, model__gamma=2, model__learning_rate=0.9814305978851464, model__max_delta_step=11, model__max_depth=15, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=3.3351492261289715, model__subsample=0.986860683696918, scale=passthrough, score=0.795, total=   8.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3144666704979742, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.15503232672208117, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=3, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6954064460144382, scale=passthrough 
[13:02:43] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3144666704979742, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.15503232672208117, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=3, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6954064460144382, scale=passthrough, score=0.825, total=   4.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.25162162218389456, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=4, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=18.30486052676598, model__subsample=1.0, scale=passthrough 
[13:06:48] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.25162162218389456, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=4, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=18.30486052676598, model__subsample=1.0, scale=passthrough, score=0.808, total=  10.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9932967556686029, model__colsample_bytree=0.7591777852931287, model__gamma=2, model__learning_rate=0.04119481156715826, model__max_delta_step=11, model__max_depth=4, model__min_child_weight=8, model__n_estimators=62, model__scale_pos_weight=925.6932253258915, model__subsample=0.7396145920669119, scale=passthrough 
[13:10:25] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9932967556686029, model__colsample_bytree=0.7591777852931287, model__gamma=2, model__learning_rate=0.04119481156715826, model__max_delta_step=11, model__max_depth=4, model__min_child_weight=8, model__n_estimators=62, model__scale_pos_weight=925.6932253258915, model__subsample=0.7396145920669119, scale=passthrough, score=0.800, total=   5.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5283288332660206, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.14894535378591978, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8188083661080623, scale=passthrough 
[13:13:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5283288332660206, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.14894535378591978, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8188083661080623, scale=passthrough, score=0.815, total=   5.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2153599397239865, model__colsample_bytree=0.922078348309785, model__gamma=5, model__learning_rate=0.021479986135452957, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=5, model__n_estimators=56, model__scale_pos_weight=38.59487821201587, model__subsample=0.9605964562185123, scale=passthrough 
[13:18:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2153599397239865, model__colsample_bytree=0.922078348309785, model__gamma=5, model__learning_rate=0.021479986135452957, model__max_delta_step=13, model__max_depth=20, model__min_child_weight=5, model__n_estimators=56, model__scale_pos_weight=38.59487821201587, model__subsample=0.9605964562185123, scale=passthrough, score=0.813, total=   3.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8491308316053338, model__colsample_bytree=0.9259115147228867, model__gamma=4, model__learning_rate=0.219537601255428, model__max_delta_step=15, model__max_depth=12, model__min_child_weight=8, model__n_estimators=53, model__scale_pos_weight=98.16359301666786, model__subsample=0.9909209199087825, scale=passthrough 
[13:23:15] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8491308316053338, model__colsample_bytree=0.9259115147228867, model__gamma=4, model__learning_rate=0.219537601255428, model__max_delta_step=15, model__max_depth=12, model__min_child_weight=8, model__n_estimators=53, model__scale_pos_weight=98.16359301666786, model__subsample=0.9909209199087825, scale=passthrough, score=0.817, total=  10.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.20308158569106502, model__colsample_bytree=0.6401627286084413, model__gamma=4, model__learning_rate=0.9958188276694409, model__max_delta_step=3, model__max_depth=4, model__min_child_weight=10, model__n_estimators=57, model__scale_pos_weight=461.29058521458205, model__subsample=0.9876357058598466, scale=passthrough 
[13:28:22] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.20308158569106502, model__colsample_bytree=0.6401627286084413, model__gamma=4, model__learning_rate=0.9958188276694409, model__max_delta_step=3, model__max_depth=4, model__min_child_weight=10, model__n_estimators=57, model__scale_pos_weight=461.29058521458205, model__subsample=0.9876357058598466, scale=passthrough, score=0.798, total=   1.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8216926856123244, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16864254346485413, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=34.07608767092671, model__subsample=1.0, scale=passthrough 
[13:33:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8216926856123244, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16864254346485413, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=34.07608767092671, model__subsample=1.0, scale=passthrough, score=0.812, total=   9.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5912298436097947, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.2372450606441309, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=184.62872204248956, model__subsample=1.0, scale=passthrough 
[12:40:50] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5912298436097947, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.2372450606441309, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=184.62872204248956, model__subsample=1.0, scale=passthrough, score=0.813, total=   3.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.625380306995069, model__colsample_bytree=0.8514283442895596, model__gamma=5, model__learning_rate=0.41910787084766915, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.40915009963638754, scale=passthrough 
[12:43:03] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.625380306995069, model__colsample_bytree=0.8514283442895596, model__gamma=5, model__learning_rate=0.41910787084766915, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.40915009963638754, scale=passthrough, score=0.810, total=   9.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4519864554659911, model__colsample_bytree=0.8366425105706587, model__gamma=5, model__learning_rate=0.18683460622727016, model__max_delta_step=9, model__max_depth=8, model__min_child_weight=1, model__n_estimators=107, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:46:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4519864554659911, model__colsample_bytree=0.8366425105706587, model__gamma=5, model__learning_rate=0.18683460622727016, model__max_delta_step=9, model__max_depth=8, model__min_child_weight=1, model__n_estimators=107, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.814, total=  10.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.19204835502229126, model__colsample_bytree=0.9762399643818847, model__gamma=3, model__learning_rate=0.248985809110902, model__max_delta_step=1, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[12:49:39] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.19204835502229126, model__colsample_bytree=0.9762399643818847, model__gamma=3, model__learning_rate=0.248985809110902, model__max_delta_step=1, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.814, total=  12.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.33427716540771224, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.02433661877263249, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=14.638697274418845, model__subsample=0.3, scale=passthrough 
[12:53:17] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.33427716540771224, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.02433661877263249, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=14.638697274418845, model__subsample=0.3, scale=passthrough, score=0.811, total=   2.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5018576187286898, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.028564295402751114, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=101, model__scale_pos_weight=1.0, model__subsample=0.6459261463922767, scale=passthrough 
[12:57:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5018576187286898, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.028564295402751114, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=101, model__scale_pos_weight=1.0, model__subsample=0.6459261463922767, scale=passthrough, score=0.823, total=  13.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9186093142414973, model__colsample_bytree=0.3426101106885372, model__gamma=2, model__learning_rate=0.9814305978851464, model__max_delta_step=11, model__max_depth=15, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=3.3351492261289715, model__subsample=0.986860683696918, scale=passthrough 
[13:00:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9186093142414973, model__colsample_bytree=0.3426101106885372, model__gamma=2, model__learning_rate=0.9814305978851464, model__max_delta_step=11, model__max_depth=15, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=3.3351492261289715, model__subsample=0.986860683696918, scale=passthrough, score=0.799, total=   9.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.35786876313122484, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1400059167253532, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.804837633099327, scale=passthrough 
[13:02:53] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.35786876313122484, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1400059167253532, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.804837633099327, scale=passthrough, score=0.826, total=   4.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.25162162218389456, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=4, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=18.30486052676598, model__subsample=1.0, scale=passthrough 
[13:06:48] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.25162162218389456, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=4, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=18.30486052676598, model__subsample=1.0, scale=passthrough, score=0.809, total=  10.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8239118000910547, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.13590694805472336, model__max_delta_step=5, model__max_depth=10, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7636751799087067, scale=passthrough 
[13:10:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8239118000910547, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.13590694805472336, model__max_delta_step=5, model__max_depth=10, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7636751799087067, scale=passthrough, score=0.823, total=  19.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9365057126379146, model__colsample_bytree=0.9868871308476761, model__gamma=3, model__learning_rate=0.04020976089944642, model__max_delta_step=1, model__max_depth=13, model__min_child_weight=1, model__n_estimators=146, model__scale_pos_weight=11.775609005448057, model__subsample=0.3268292221957598, scale=passthrough 
[13:14:09] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9365057126379146, model__colsample_bytree=0.9868871308476761, model__gamma=3, model__learning_rate=0.04020976089944642, model__max_delta_step=1, model__max_depth=13, model__min_child_weight=1, model__n_estimators=146, model__scale_pos_weight=11.775609005448057, model__subsample=0.3268292221957598, scale=passthrough, score=0.807, total=  19.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.907369960529755, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.03960228586907178, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6179628538616335, scale=passthrough 
[13:18:54] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.907369960529755, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.03960228586907178, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6179628538616335, scale=passthrough, score=0.818, total=  33.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9568008986065447, model__colsample_bytree=0.5203044858428413, model__gamma=5, model__learning_rate=0.8820045266265615, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=3, model__n_estimators=55, model__scale_pos_weight=3.2719254666846522, model__subsample=0.3038874352935374, scale=passthrough 
[13:23:37] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9568008986065447, model__colsample_bytree=0.5203044858428413, model__gamma=5, model__learning_rate=0.8820045266265615, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=3, model__n_estimators=55, model__scale_pos_weight=3.2719254666846522, model__subsample=0.3038874352935374, scale=passthrough, score=0.759, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.20308158569106502, model__colsample_bytree=0.6401627286084413, model__gamma=4, model__learning_rate=0.9958188276694409, model__max_delta_step=3, model__max_depth=4, model__min_child_weight=10, model__n_estimators=57, model__scale_pos_weight=461.29058521458205, model__subsample=0.9876357058598466, scale=passthrough 
[13:28:22] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.20308158569106502, model__colsample_bytree=0.6401627286084413, model__gamma=4, model__learning_rate=0.9958188276694409, model__max_delta_step=3, model__max_depth=4, model__min_child_weight=10, model__n_estimators=57, model__scale_pos_weight=461.29058521458205, model__subsample=0.9876357058598466, scale=passthrough, score=0.812, total=   1.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8216926856123244, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16864254346485413, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=34.07608767092671, model__subsample=1.0, scale=passthrough 
[13:33:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8216926856123244, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16864254346485413, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=34.07608767092671, model__subsample=1.0, scale=passthrough, score=0.817, total=   9.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.39232926160480097, model__gamma=1, model__learning_rate=1.0, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[12:40:44] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.39232926160480097, model__gamma=1, model__learning_rate=1.0, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.747, total=   2.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.625380306995069, model__colsample_bytree=0.8514283442895596, model__gamma=5, model__learning_rate=0.41910787084766915, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.40915009963638754, scale=passthrough 
[12:43:03] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.625380306995069, model__colsample_bytree=0.8514283442895596, model__gamma=5, model__learning_rate=0.41910787084766915, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.40915009963638754, scale=passthrough, score=0.794, total=   8.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5319250256040385, model__colsample_bytree=0.5421940677812587, model__gamma=4, model__learning_rate=0.041051773959994736, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:46:09] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5319250256040385, model__colsample_bytree=0.5421940677812587, model__gamma=4, model__learning_rate=0.041051773959994736, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.814, total=  12.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8567412002271322, model__colsample_bytree=0.8575671103085107, model__gamma=2, model__learning_rate=0.07465261039980901, model__max_delta_step=18, model__max_depth=3, model__min_child_weight=9, model__n_estimators=107, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[12:49:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8567412002271322, model__colsample_bytree=0.8575671103085107, model__gamma=2, model__learning_rate=0.07465261039980901, model__max_delta_step=18, model__max_depth=3, model__min_child_weight=9, model__n_estimators=107, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.797, total=   3.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7327427198317836, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.05318619770853978, model__max_delta_step=20, model__max_depth=5, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6714582277622831, scale=passthrough 
[12:52:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7327427198317836, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.05318619770853978, model__max_delta_step=20, model__max_depth=5, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6714582277622831, scale=passthrough, score=0.829, total=  14.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5018576187286898, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.028564295402751114, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=101, model__scale_pos_weight=1.0, model__subsample=0.6459261463922767, scale=passthrough 
[12:57:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5018576187286898, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.028564295402751114, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=101, model__scale_pos_weight=1.0, model__subsample=0.6459261463922767, scale=passthrough, score=0.814, total=  13.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9186093142414973, model__colsample_bytree=0.3426101106885372, model__gamma=2, model__learning_rate=0.9814305978851464, model__max_delta_step=11, model__max_depth=15, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=3.3351492261289715, model__subsample=0.986860683696918, scale=passthrough 
[13:00:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9186093142414973, model__colsample_bytree=0.3426101106885372, model__gamma=2, model__learning_rate=0.9814305978851464, model__max_delta_step=11, model__max_depth=15, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=3.3351492261289715, model__subsample=0.986860683696918, scale=passthrough, score=0.798, total=   8.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3144666704979742, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.15503232672208117, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=3, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6954064460144382, scale=passthrough 
[13:02:43] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3144666704979742, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.15503232672208117, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=3, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6954064460144382, scale=passthrough, score=0.825, total=   4.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7975556755091645, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.23661077950939263, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=203.09690651748897, model__subsample=1.0, scale=passthrough 
[13:06:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7975556755091645, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.23661077950939263, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=203.09690651748897, model__subsample=1.0, scale=passthrough, score=0.809, total=  10.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9932967556686029, model__colsample_bytree=0.7591777852931287, model__gamma=2, model__learning_rate=0.04119481156715826, model__max_delta_step=11, model__max_depth=4, model__min_child_weight=8, model__n_estimators=62, model__scale_pos_weight=925.6932253258915, model__subsample=0.7396145920669119, scale=passthrough 
[13:10:25] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9932967556686029, model__colsample_bytree=0.7591777852931287, model__gamma=2, model__learning_rate=0.04119481156715826, model__max_delta_step=11, model__max_depth=4, model__min_child_weight=8, model__n_estimators=62, model__scale_pos_weight=925.6932253258915, model__subsample=0.7396145920669119, scale=passthrough, score=0.808, total=   5.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5283288332660206, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.14894535378591978, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8188083661080623, scale=passthrough 
[13:13:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5283288332660206, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.14894535378591978, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8188083661080623, scale=passthrough, score=0.826, total=   5.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.907369960529755, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.03960228586907178, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6179628538616335, scale=passthrough 
[13:18:54] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.907369960529755, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.03960228586907178, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6179628538616335, scale=passthrough, score=0.823, total=  33.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9568008986065447, model__colsample_bytree=0.5203044858428413, model__gamma=5, model__learning_rate=0.8820045266265615, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=3, model__n_estimators=55, model__scale_pos_weight=3.2719254666846522, model__subsample=0.3038874352935374, scale=passthrough 
[13:23:37] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9568008986065447, model__colsample_bytree=0.5203044858428413, model__gamma=5, model__learning_rate=0.8820045266265615, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=3, model__n_estimators=55, model__scale_pos_weight=3.2719254666846522, model__subsample=0.3038874352935374, scale=passthrough, score=0.751, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.20308158569106502, model__colsample_bytree=0.6401627286084413, model__gamma=4, model__learning_rate=0.9958188276694409, model__max_delta_step=3, model__max_depth=4, model__min_child_weight=10, model__n_estimators=57, model__scale_pos_weight=461.29058521458205, model__subsample=0.9876357058598466, scale=passthrough 
[13:28:22] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.20308158569106502, model__colsample_bytree=0.6401627286084413, model__gamma=4, model__learning_rate=0.9958188276694409, model__max_delta_step=3, model__max_depth=4, model__min_child_weight=10, model__n_estimators=57, model__scale_pos_weight=461.29058521458205, model__subsample=0.9876357058598466, scale=passthrough, score=0.791, total=   1.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8216926856123244, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16864254346485413, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=34.07608767092671, model__subsample=1.0, scale=passthrough 
[13:33:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8216926856123244, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.16864254346485413, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=34.07608767092671, model__subsample=1.0, scale=passthrough, score=0.828, total=   9.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8956598812561088, model__colsample_bytree=0.6432413582312556, model__gamma=2, model__learning_rate=0.47950224134277997, model__max_delta_step=9, model__max_depth=11, model__min_child_weight=8, model__n_estimators=129, model__scale_pos_weight=16.340094294903054, model__subsample=0.7395710203466399, scale=passthrough 
[12:38:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8956598812561088, model__colsample_bytree=0.6432413582312556, model__gamma=2, model__learning_rate=0.47950224134277997, model__max_delta_step=9, model__max_depth=11, model__min_child_weight=8, model__n_estimators=129, model__scale_pos_weight=16.340094294903054, model__subsample=0.7395710203466399, scale=passthrough, score=0.808, total=  13.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.8835222719721867, model__gamma=3, model__learning_rate=0.01, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=7, model__n_estimators=80, model__scale_pos_weight=24.931036467252635, model__subsample=0.3, scale=passthrough 
[12:41:04] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.8835222719721867, model__gamma=3, model__learning_rate=0.01, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=7, model__n_estimators=80, model__scale_pos_weight=24.931036467252635, model__subsample=0.3, scale=passthrough, score=0.802, total=   7.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.01, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:43:47] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.01, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.791, total=  10.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4201453433278661, model__colsample_bytree=0.6602346245231958, model__gamma=5, model__learning_rate=0.01, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=4.536038333596355, model__subsample=1.0, scale=passthrough 
[12:47:05] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4201453433278661, model__colsample_bytree=0.6602346245231958, model__gamma=5, model__learning_rate=0.01, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=4.536038333596355, model__subsample=1.0, scale=passthrough, score=0.797, total=   6.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8106827059215695, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.027779855529191815, model__max_delta_step=1, model__max_depth=10, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.636469752338156, scale=passthrough 
[12:49:56] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8106827059215695, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.027779855529191815, model__max_delta_step=1, model__max_depth=10, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.636469752338156, scale=passthrough, score=0.814, total=  27.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6476297636717281, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.032733906308545044, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.5768325263639889, scale=passthrough 
[12:53:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6476297636717281, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.032733906308545044, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.5768325263639889, scale=passthrough, score=0.826, total=   9.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3850395588759831, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.26109741414365173, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=1.0926202043666218, model__subsample=1.0, scale=passthrough 
[12:57:21] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3850395588759831, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.26109741414365173, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=1.0926202043666218, model__subsample=1.0, scale=passthrough, score=0.823, total=   1.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3728573344531136, model__colsample_bytree=0.996298705345964, model__gamma=2, model__learning_rate=0.8927049177339886, model__max_delta_step=1, model__max_depth=3, model__min_child_weight=1, model__n_estimators=53, model__scale_pos_weight=3.893877211807879, model__subsample=0.9822400866927687, scale=passthrough 
[13:00:46] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3728573344531136, model__colsample_bytree=0.996298705345964, model__gamma=2, model__learning_rate=0.8927049177339886, model__max_delta_step=1, model__max_depth=3, model__min_child_weight=1, model__n_estimators=53, model__scale_pos_weight=3.893877211807879, model__subsample=0.9822400866927687, scale=passthrough, score=0.799, total=   2.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.605848784786007, model__colsample_bytree=0.3030158208675209, model__gamma=1, model__learning_rate=0.016666545458275794, model__max_delta_step=14, model__max_depth=3, model__min_child_weight=3, model__n_estimators=59, model__scale_pos_weight=57.48214623733764, model__subsample=0.8271495199964074, scale=passthrough 
[13:03:04] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.605848784786007, model__colsample_bytree=0.3030158208675209, model__gamma=1, model__learning_rate=0.016666545458275794, model__max_delta_step=14, model__max_depth=3, model__min_child_weight=3, model__n_estimators=59, model__scale_pos_weight=57.48214623733764, model__subsample=0.8271495199964074, scale=passthrough, score=0.774, total=   1.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5509412498824555, model__colsample_bytree=0.9876610047109231, model__gamma=4, model__learning_rate=0.9817695135819916, model__max_delta_step=12, model__max_depth=4, model__min_child_weight=10, model__n_estimators=60, model__scale_pos_weight=228.264514753827, model__subsample=0.31836289784150784, scale=passthrough 
[13:07:06] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5509412498824555, model__colsample_bytree=0.9876610047109231, model__gamma=4, model__learning_rate=0.9817695135819916, model__max_delta_step=12, model__max_depth=4, model__min_child_weight=10, model__n_estimators=60, model__scale_pos_weight=228.264514753827, model__subsample=0.31836289784150784, scale=passthrough, score=0.766, total=   1.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8239118000910547, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.13590694805472336, model__max_delta_step=5, model__max_depth=10, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7636751799087067, scale=passthrough 
[13:10:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8239118000910547, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.13590694805472336, model__max_delta_step=5, model__max_depth=10, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7636751799087067, scale=passthrough, score=0.821, total=  19.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8011959448551085, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.05610219809054872, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8173084402012074, scale=passthrough 
[13:14:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8011959448551085, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.05610219809054872, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8173084402012074, scale=passthrough, score=0.831, total=  23.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9315262437086874, model__colsample_bytree=0.5209034930826074, model__gamma=3, model__learning_rate=0.06678354184062682, model__max_delta_step=16, model__max_depth=20, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=4.944792697764897, model__subsample=0.35858782860200866, scale=passthrough 
[13:19:40] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9315262437086874, model__colsample_bytree=0.5209034930826074, model__gamma=3, model__learning_rate=0.06678354184062682, model__max_delta_step=16, model__max_depth=20, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=4.944792697764897, model__subsample=0.35858782860200866, scale=passthrough, score=0.806, total=   7.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9951983831500005, model__colsample_bytree=0.3610949756900127, model__gamma=1, model__learning_rate=0.01098541902881326, model__max_delta_step=18, model__max_depth=17, model__min_child_weight=10, model__n_estimators=59, model__scale_pos_weight=420.9935578783081, model__subsample=0.9577403793948231, scale=passthrough 
[13:23:52] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9951983831500005, model__colsample_bytree=0.3610949756900127, model__gamma=1, model__learning_rate=0.01098541902881326, model__max_delta_step=18, model__max_depth=17, model__min_child_weight=10, model__n_estimators=59, model__scale_pos_weight=420.9935578783081, model__subsample=0.9577403793948231, scale=passthrough, score=0.809, total=   5.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8668701895013304, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.12492801938016393, model__max_delta_step=0, model__max_depth=8, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.871625599700572, scale=passthrough 
[13:28:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8668701895013304, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.12492801938016393, model__max_delta_step=0, model__max_depth=8, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.871625599700572, scale=passthrough, score=0.826, total=  17.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6844854538966096, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.13716347464584985, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7816123683388981, scale=passthrough 
[13:33:29] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6844854538966096, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.13716347464584985, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7816123683388981, scale=passthrough, score=0.814, total=   6.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6582926807483003, model__colsample_bytree=0.3, model__gamma=5, model__learning_rate=0.2482871564923991, model__max_delta_step=14, model__max_depth=20, model__min_child_weight=10, model__n_estimators=61, model__scale_pos_weight=882.6450983940014, model__subsample=1.0, scale=passthrough 
[12:40:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6582926807483003, model__colsample_bytree=0.3, model__gamma=5, model__learning_rate=0.2482871564923991, model__max_delta_step=14, model__max_depth=20, model__min_child_weight=10, model__n_estimators=61, model__scale_pos_weight=882.6450983940014, model__subsample=1.0, scale=passthrough, score=0.811, total=   4.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.01, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:43:47] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.01, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.791, total=  10.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.06348571978562509, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=1, model__n_estimators=134, model__scale_pos_weight=56.24623518863065, model__subsample=1.0, scale=passthrough 
[12:46:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.06348571978562509, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=1, model__n_estimators=134, model__scale_pos_weight=56.24623518863065, model__subsample=1.0, scale=passthrough, score=0.817, total=  24.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.19204835502229126, model__colsample_bytree=0.9762399643818847, model__gamma=3, model__learning_rate=0.248985809110902, model__max_delta_step=1, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[12:49:39] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.19204835502229126, model__colsample_bytree=0.9762399643818847, model__gamma=3, model__learning_rate=0.248985809110902, model__max_delta_step=1, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.807, total=  12.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.33427716540771224, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.02433661877263249, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=14.638697274418845, model__subsample=0.3, scale=passthrough 
[12:53:17] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.33427716540771224, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.02433661877263249, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=14.638697274418845, model__subsample=0.3, scale=passthrough, score=0.800, total=   2.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3850395588759831, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.26109741414365173, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=1.0926202043666218, model__subsample=1.0, scale=passthrough 
[12:57:21] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3850395588759831, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.26109741414365173, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=1.0926202043666218, model__subsample=1.0, scale=passthrough, score=0.820, total=   1.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9330712449712505, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.11159539600064079, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.729062663586322, scale=passthrough 
[13:00:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9330712449712505, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.11159539600064079, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.729062663586322, scale=passthrough, score=0.817, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.35786876313122484, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1400059167253532, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.804837633099327, scale=passthrough 
[13:02:53] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.35786876313122484, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1400059167253532, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.804837633099327, scale=passthrough, score=0.814, total=   4.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.25162162218389456, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=4, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=18.30486052676598, model__subsample=1.0, scale=passthrough 
[13:06:48] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.25162162218389456, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=4, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=18.30486052676598, model__subsample=1.0, scale=passthrough, score=0.816, total=  10.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9932967556686029, model__colsample_bytree=0.7591777852931287, model__gamma=2, model__learning_rate=0.04119481156715826, model__max_delta_step=11, model__max_depth=4, model__min_child_weight=8, model__n_estimators=62, model__scale_pos_weight=925.6932253258915, model__subsample=0.7396145920669119, scale=passthrough 
[13:10:25] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9932967556686029, model__colsample_bytree=0.7591777852931287, model__gamma=2, model__learning_rate=0.04119481156715826, model__max_delta_step=11, model__max_depth=4, model__min_child_weight=8, model__n_estimators=62, model__scale_pos_weight=925.6932253258915, model__subsample=0.7396145920669119, scale=passthrough, score=0.811, total=   5.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9365057126379146, model__colsample_bytree=0.9868871308476761, model__gamma=3, model__learning_rate=0.04020976089944642, model__max_delta_step=1, model__max_depth=13, model__min_child_weight=1, model__n_estimators=146, model__scale_pos_weight=11.775609005448057, model__subsample=0.3268292221957598, scale=passthrough 
[13:14:09] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9365057126379146, model__colsample_bytree=0.9868871308476761, model__gamma=3, model__learning_rate=0.04020976089944642, model__max_delta_step=1, model__max_depth=13, model__min_child_weight=1, model__n_estimators=146, model__scale_pos_weight=11.775609005448057, model__subsample=0.3268292221957598, scale=passthrough, score=0.819, total=  19.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.907369960529755, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.03960228586907178, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6179628538616335, scale=passthrough 
[13:18:54] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.907369960529755, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.03960228586907178, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6179628538616335, scale=passthrough, score=0.810, total=  33.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9568008986065447, model__colsample_bytree=0.5203044858428413, model__gamma=5, model__learning_rate=0.8820045266265615, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=3, model__n_estimators=55, model__scale_pos_weight=3.2719254666846522, model__subsample=0.3038874352935374, scale=passthrough 
[13:23:37] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9568008986065447, model__colsample_bytree=0.5203044858428413, model__gamma=5, model__learning_rate=0.8820045266265615, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=3, model__n_estimators=55, model__scale_pos_weight=3.2719254666846522, model__subsample=0.3038874352935374, scale=passthrough, score=0.762, total=   3.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8668701895013304, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.12492801938016393, model__max_delta_step=0, model__max_depth=8, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.871625599700572, scale=passthrough 
[13:28:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8668701895013304, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.12492801938016393, model__max_delta_step=0, model__max_depth=8, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.871625599700572, scale=passthrough, score=0.829, total=  17.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6844854538966096, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.13716347464584985, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7816123683388981, scale=passthrough 
[13:33:29] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6844854538966096, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.13716347464584985, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7816123683388981, scale=passthrough, score=0.819, total=   6.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8956598812561088, model__colsample_bytree=0.6432413582312556, model__gamma=2, model__learning_rate=0.47950224134277997, model__max_delta_step=9, model__max_depth=11, model__min_child_weight=8, model__n_estimators=129, model__scale_pos_weight=16.340094294903054, model__subsample=0.7395710203466399, scale=passthrough 
[12:38:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8956598812561088, model__colsample_bytree=0.6432413582312556, model__gamma=2, model__learning_rate=0.47950224134277997, model__max_delta_step=9, model__max_depth=11, model__min_child_weight=8, model__n_estimators=129, model__scale_pos_weight=16.340094294903054, model__subsample=0.7395710203466399, scale=passthrough, score=0.804, total=  13.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=0.3, model__gamma=5, model__learning_rate=0.09212493376669943, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=278.87157613599607, model__subsample=0.46981062344447505, scale=passthrough 
[12:41:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=0.3, model__gamma=5, model__learning_rate=0.09212493376669943, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=278.87157613599607, model__subsample=0.46981062344447505, scale=passthrough, score=0.751, total=   1.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6731793514102031, model__colsample_bytree=0.6363610788977796, model__gamma=3, model__learning_rate=0.06654762391643661, model__max_delta_step=6, model__max_depth=19, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=4.459684760380094, model__subsample=0.699457292016114, scale=passthrough 
[12:44:01] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6731793514102031, model__colsample_bytree=0.6363610788977796, model__gamma=3, model__learning_rate=0.06654762391643661, model__max_delta_step=6, model__max_depth=19, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=4.459684760380094, model__subsample=0.699457292016114, scale=passthrough, score=0.818, total=  13.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4201453433278661, model__colsample_bytree=0.6602346245231958, model__gamma=5, model__learning_rate=0.01, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=4.536038333596355, model__subsample=1.0, scale=passthrough 
[12:47:05] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4201453433278661, model__colsample_bytree=0.6602346245231958, model__gamma=5, model__learning_rate=0.01, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=4.536038333596355, model__subsample=1.0, scale=passthrough, score=0.816, total=   6.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8106827059215695, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.027779855529191815, model__max_delta_step=1, model__max_depth=10, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.636469752338156, scale=passthrough 
[12:49:56] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8106827059215695, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.027779855529191815, model__max_delta_step=1, model__max_depth=10, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.636469752338156, scale=passthrough, score=0.819, total=  27.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6116986539206163, model__colsample_bytree=0.8566999167764007, model__gamma=1, model__learning_rate=0.04296027090185901, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:53:37] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6116986539206163, model__colsample_bytree=0.8566999167764007, model__gamma=1, model__learning_rate=0.04296027090185901, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.814, total=  20.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=20, model__max_depth=16, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=419.3974496621373, model__subsample=0.3, scale=passthrough 
[12:57:27] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=20, model__max_depth=16, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=419.3974496621373, model__subsample=0.3, scale=passthrough, score=0.816, total=  21.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3728573344531136, model__colsample_bytree=0.996298705345964, model__gamma=2, model__learning_rate=0.8927049177339886, model__max_delta_step=1, model__max_depth=3, model__min_child_weight=1, model__n_estimators=53, model__scale_pos_weight=3.893877211807879, model__subsample=0.9822400866927687, scale=passthrough 
[13:00:46] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3728573344531136, model__colsample_bytree=0.996298705345964, model__gamma=2, model__learning_rate=0.8927049177339886, model__max_delta_step=1, model__max_depth=3, model__min_child_weight=1, model__n_estimators=53, model__scale_pos_weight=3.893877211807879, model__subsample=0.9822400866927687, scale=passthrough, score=0.814, total=   2.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[13:03:11] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.800, total=  49.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.47049265824961084, model__colsample_bytree=0.336411957584814, model__gamma=2, model__learning_rate=0.0628578451181805, model__max_delta_step=16, model__max_depth=18, model__min_child_weight=9, model__n_estimators=53, model__scale_pos_weight=768.7838984341289, model__subsample=0.9992098127509952, scale=passthrough 
[13:07:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.47049265824961084, model__colsample_bytree=0.336411957584814, model__gamma=2, model__learning_rate=0.0628578451181805, model__max_delta_step=16, model__max_depth=18, model__min_child_weight=9, model__n_estimators=53, model__scale_pos_weight=768.7838984341289, model__subsample=0.9992098127509952, scale=passthrough, score=0.817, total=   2.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44888233845569864, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09627500238061928, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6523953423489568, scale=passthrough 
[13:11:05] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44888233845569864, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09627500238061928, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6523953423489568, scale=passthrough, score=0.820, total=   4.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8011959448551085, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.05610219809054872, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8173084402012074, scale=passthrough 
[13:14:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8011959448551085, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.05610219809054872, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8173084402012074, scale=passthrough, score=0.812, total=  24.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9315262437086874, model__colsample_bytree=0.5209034930826074, model__gamma=3, model__learning_rate=0.06678354184062682, model__max_delta_step=16, model__max_depth=20, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=4.944792697764897, model__subsample=0.35858782860200866, scale=passthrough 
[13:19:40] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9315262437086874, model__colsample_bytree=0.5209034930826074, model__gamma=3, model__learning_rate=0.06678354184062682, model__max_delta_step=16, model__max_depth=20, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=4.944792697764897, model__subsample=0.35858782860200866, scale=passthrough, score=0.821, total=   7.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9951983831500005, model__colsample_bytree=0.3610949756900127, model__gamma=1, model__learning_rate=0.01098541902881326, model__max_delta_step=18, model__max_depth=17, model__min_child_weight=10, model__n_estimators=59, model__scale_pos_weight=420.9935578783081, model__subsample=0.9577403793948231, scale=passthrough 
[13:23:52] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9951983831500005, model__colsample_bytree=0.3610949756900127, model__gamma=1, model__learning_rate=0.01098541902881326, model__max_delta_step=18, model__max_depth=17, model__min_child_weight=10, model__n_estimators=59, model__scale_pos_weight=420.9935578783081, model__subsample=0.9577403793948231, scale=passthrough, score=0.816, total=   5.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8668701895013304, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.12492801938016393, model__max_delta_step=0, model__max_depth=8, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.871625599700572, scale=passthrough 
[13:28:36] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8668701895013304, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.12492801938016393, model__max_delta_step=0, model__max_depth=8, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.871625599700572, scale=passthrough, score=0.825, total=  17.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6844854538966096, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.13716347464584985, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7816123683388981, scale=passthrough 
[13:33:29] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6844854538966096, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.13716347464584985, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7816123683388981, scale=passthrough, score=0.825, total=   6.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8956598812561088, model__colsample_bytree=0.6432413582312556, model__gamma=2, model__learning_rate=0.47950224134277997, model__max_delta_step=9, model__max_depth=11, model__min_child_weight=8, model__n_estimators=129, model__scale_pos_weight=16.340094294903054, model__subsample=0.7395710203466399, scale=passthrough 
[12:38:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8956598812561088, model__colsample_bytree=0.6432413582312556, model__gamma=2, model__learning_rate=0.47950224134277997, model__max_delta_step=9, model__max_depth=11, model__min_child_weight=8, model__n_estimators=129, model__scale_pos_weight=16.340094294903054, model__subsample=0.7395710203466399, scale=passthrough, score=0.801, total=  12.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.8835222719721867, model__gamma=3, model__learning_rate=0.01, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=7, model__n_estimators=80, model__scale_pos_weight=24.931036467252635, model__subsample=0.3, scale=passthrough 
[12:41:04] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.8835222719721867, model__gamma=3, model__learning_rate=0.01, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=7, model__n_estimators=80, model__scale_pos_weight=24.931036467252635, model__subsample=0.3, scale=passthrough, score=0.799, total=   6.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.01, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:43:47] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=5, model__learning_rate=0.01, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.788, total=  10.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.06348571978562509, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=1, model__n_estimators=134, model__scale_pos_weight=56.24623518863065, model__subsample=1.0, scale=passthrough 
[12:46:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.06348571978562509, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=1, model__n_estimators=134, model__scale_pos_weight=56.24623518863065, model__subsample=1.0, scale=passthrough, score=0.807, total=  24.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.19204835502229126, model__colsample_bytree=0.9762399643818847, model__gamma=3, model__learning_rate=0.248985809110902, model__max_delta_step=1, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[12:49:39] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.19204835502229126, model__colsample_bytree=0.9762399643818847, model__gamma=3, model__learning_rate=0.248985809110902, model__max_delta_step=1, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.826, total=  12.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6476297636717281, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.032733906308545044, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.5768325263639889, scale=passthrough 
[12:53:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6476297636717281, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.032733906308545044, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.5768325263639889, scale=passthrough, score=0.811, total=   9.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3850395588759831, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.26109741414365173, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=1.0926202043666218, model__subsample=1.0, scale=passthrough 
[12:57:21] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3850395588759831, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.26109741414365173, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=7, model__n_estimators=50, model__scale_pos_weight=1.0926202043666218, model__subsample=1.0, scale=passthrough, score=0.817, total=   1.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9330712449712505, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.11159539600064079, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.729062663586322, scale=passthrough 
[13:00:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9330712449712505, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.11159539600064079, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.729062663586322, scale=passthrough, score=0.826, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.605848784786007, model__colsample_bytree=0.3030158208675209, model__gamma=1, model__learning_rate=0.016666545458275794, model__max_delta_step=14, model__max_depth=3, model__min_child_weight=3, model__n_estimators=59, model__scale_pos_weight=57.48214623733764, model__subsample=0.8271495199964074, scale=passthrough 
[13:03:04] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.605848784786007, model__colsample_bytree=0.3030158208675209, model__gamma=1, model__learning_rate=0.016666545458275794, model__max_delta_step=14, model__max_depth=3, model__min_child_weight=3, model__n_estimators=59, model__scale_pos_weight=57.48214623733764, model__subsample=0.8271495199964074, scale=passthrough, score=0.766, total=   1.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5509412498824555, model__colsample_bytree=0.9876610047109231, model__gamma=4, model__learning_rate=0.9817695135819916, model__max_delta_step=12, model__max_depth=4, model__min_child_weight=10, model__n_estimators=60, model__scale_pos_weight=228.264514753827, model__subsample=0.31836289784150784, scale=passthrough 
[13:07:06] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5509412498824555, model__colsample_bytree=0.9876610047109231, model__gamma=4, model__learning_rate=0.9817695135819916, model__max_delta_step=12, model__max_depth=4, model__min_child_weight=10, model__n_estimators=60, model__scale_pos_weight=228.264514753827, model__subsample=0.31836289784150784, scale=passthrough, score=0.758, total=   1.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44888233845569864, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09627500238061928, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6523953423489568, scale=passthrough 
[13:11:05] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44888233845569864, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09627500238061928, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6523953423489568, scale=passthrough, score=0.822, total=   4.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8011959448551085, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.05610219809054872, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8173084402012074, scale=passthrough 
[13:14:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8011959448551085, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.05610219809054872, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8173084402012074, scale=passthrough, score=0.823, total=  24.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9315262437086874, model__colsample_bytree=0.5209034930826074, model__gamma=3, model__learning_rate=0.06678354184062682, model__max_delta_step=16, model__max_depth=20, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=4.944792697764897, model__subsample=0.35858782860200866, scale=passthrough 
[13:19:40] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9315262437086874, model__colsample_bytree=0.5209034930826074, model__gamma=3, model__learning_rate=0.06678354184062682, model__max_delta_step=16, model__max_depth=20, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=4.944792697764897, model__subsample=0.35858782860200866, scale=passthrough, score=0.820, total=   7.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6541951007767545, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10696240430203029, model__max_delta_step=20, model__max_depth=12, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8501377179735958, scale=passthrough 
[13:24:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6541951007767545, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10696240430203029, model__max_delta_step=20, model__max_depth=12, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8501377179735958, scale=passthrough, score=0.822, total=  18.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9916904238916124, model__colsample_bytree=0.9688464311980622, model__gamma=3, model__learning_rate=0.20688302542803436, model__max_delta_step=19, model__max_depth=8, model__min_child_weight=10, model__n_estimators=149, model__scale_pos_weight=47.440087594703016, model__subsample=0.6276583216721197, scale=passthrough 
[13:29:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9916904238916124, model__colsample_bytree=0.9688464311980622, model__gamma=3, model__learning_rate=0.20688302542803436, model__max_delta_step=19, model__max_depth=8, model__min_child_weight=10, model__n_estimators=149, model__scale_pos_weight=47.440087594703016, model__subsample=0.6276583216721197, scale=passthrough, score=0.819, total=  18.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5813068156435819, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1178995687832883, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6204906001531987, scale=passthrough 
[13:33:49] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5813068156435819, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1178995687832883, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6204906001531987, scale=passthrough, score=0.818, total=  10.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8496240201470282, model__colsample_bytree=0.9830777326171856, model__gamma=4, model__learning_rate=0.06874849914790944, model__max_delta_step=4, model__max_depth=12, model__min_child_weight=8, model__n_estimators=133, model__scale_pos_weight=8.080969479597385, model__subsample=0.537030103927309, scale=passthrough 
[12:39:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8496240201470282, model__colsample_bytree=0.9830777326171856, model__gamma=4, model__learning_rate=0.06874849914790944, model__max_delta_step=4, model__max_depth=12, model__min_child_weight=8, model__n_estimators=133, model__scale_pos_weight=8.080969479597385, model__subsample=0.537030103927309, scale=passthrough, score=0.823, total=  18.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5288586629520308, model__colsample_bytree=0.3, model__gamma=3, model__learning_rate=0.16432636056877883, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=5, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:41:23] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5288586629520308, model__colsample_bytree=0.3, model__gamma=3, model__learning_rate=0.16432636056877883, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=5, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.808, total=   3.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.17501511587798843, model__colsample_bytree=0.688339167996399, model__gamma=4, model__learning_rate=0.14555030812967049, model__max_delta_step=19, model__max_depth=15, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1.5505401377102335, model__subsample=1.0, scale=passthrough 
[12:44:29] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.17501511587798843, model__colsample_bytree=0.688339167996399, model__gamma=4, model__learning_rate=0.14555030812967049, model__max_delta_step=19, model__max_depth=15, model__min_child_weight=2, model__n_estimators=150, model__scale_pos_weight=1.5505401377102335, model__subsample=1.0, scale=passthrough, score=0.822, total=   7.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5986048699610145, model__colsample_bytree=0.7206152207911285, model__gamma=1, model__learning_rate=0.030273563622536564, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=9, model__n_estimators=50, model__scale_pos_weight=953.4397812625493, model__subsample=1.0, scale=passthrough 
[12:47:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5986048699610145, model__colsample_bytree=0.7206152207911285, model__gamma=1, model__learning_rate=0.030273563622536564, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=9, model__n_estimators=50, model__scale_pos_weight=953.4397812625493, model__subsample=1.0, scale=passthrough, score=0.817, total=   4.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6883518065722666, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.04130579513609374, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.5103962518485224, scale=passthrough 
[12:50:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6883518065722666, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.04130579513609374, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.5103962518485224, scale=passthrough, score=0.827, total=  25.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9098253164362686, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.2593988949894903, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=4.418766958765141, model__subsample=1.0, scale=passthrough 
[12:54:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9098253164362686, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.2593988949894903, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=4.418766958765141, model__subsample=1.0, scale=passthrough, score=0.815, total=   4.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.028930220462137776, model__max_delta_step=13, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:58:12] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.028930220462137776, model__max_delta_step=13, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.809, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.26523868268741607, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[13:01:04] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.26523868268741607, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.781, total=   2.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2926672548978454, model__colsample_bytree=0.5867886522755954, model__gamma=3, model__learning_rate=0.086894693605999, model__max_delta_step=1, model__max_depth=3, model__min_child_weight=1, model__n_estimators=119, model__scale_pos_weight=4.783825724876682, model__subsample=0.3041125013442748, scale=passthrough 
[13:04:09] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2926672548978454, model__colsample_bytree=0.5867886522755954, model__gamma=3, model__learning_rate=0.086894693605999, model__max_delta_step=1, model__max_depth=3, model__min_child_weight=1, model__n_estimators=119, model__scale_pos_weight=4.783825724876682, model__subsample=0.3041125013442748, scale=passthrough, score=0.819, total=   1.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2311826252494585, model__colsample_bytree=0.5676651755593167, model__gamma=3, model__learning_rate=0.010748621084095817, model__max_delta_step=2, model__max_depth=19, model__min_child_weight=9, model__n_estimators=146, model__scale_pos_weight=1.2649493021420082, model__subsample=0.3659818044313171, scale=passthrough 
[13:07:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2311826252494585, model__colsample_bytree=0.5676651755593167, model__gamma=3, model__learning_rate=0.010748621084095817, model__max_delta_step=2, model__max_depth=19, model__min_child_weight=9, model__n_estimators=146, model__scale_pos_weight=1.2649493021420082, model__subsample=0.3659818044313171, scale=passthrough, score=0.788, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.68577891423815, model__colsample_bytree=0.5886129420682689, model__gamma=3, model__learning_rate=0.010700985541269331, model__max_delta_step=9, model__max_depth=19, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=1.6415738019047055, model__subsample=0.8637639144432199, scale=passthrough 
[13:11:18] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.68577891423815, model__colsample_bytree=0.5886129420682689, model__gamma=3, model__learning_rate=0.010700985541269331, model__max_delta_step=9, model__max_depth=19, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=1.6415738019047055, model__subsample=0.8637639144432199, scale=passthrough, score=0.813, total=  15.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.20188376728451304, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08019434098964026, model__max_delta_step=3, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.3112689020839243, model__subsample=1.0, scale=passthrough 
[13:15:11] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.20188376728451304, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08019434098964026, model__max_delta_step=3, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.3112689020839243, model__subsample=1.0, scale=passthrough, score=0.825, total=   3.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.046730668908318174, model__colsample_bytree=0.6602693794904608, model__gamma=2, model__learning_rate=0.11136392187445981, model__max_delta_step=3, model__max_depth=19, model__min_child_weight=9, model__n_estimators=138, model__scale_pos_weight=742.0520711455373, model__subsample=0.975120004288275, scale=passthrough 
[13:19:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.046730668908318174, model__colsample_bytree=0.6602693794904608, model__gamma=2, model__learning_rate=0.11136392187445981, model__max_delta_step=3, model__max_depth=19, model__min_child_weight=9, model__n_estimators=138, model__scale_pos_weight=742.0520711455373, model__subsample=0.975120004288275, scale=passthrough, score=0.816, total=   2.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6541951007767545, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10696240430203029, model__max_delta_step=20, model__max_depth=12, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8501377179735958, scale=passthrough 
[13:24:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6541951007767545, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10696240430203029, model__max_delta_step=20, model__max_depth=12, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8501377179735958, scale=passthrough, score=0.821, total=  18.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9916904238916124, model__colsample_bytree=0.9688464311980622, model__gamma=3, model__learning_rate=0.20688302542803436, model__max_delta_step=19, model__max_depth=8, model__min_child_weight=10, model__n_estimators=149, model__scale_pos_weight=47.440087594703016, model__subsample=0.6276583216721197, scale=passthrough 
[13:29:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9916904238916124, model__colsample_bytree=0.9688464311980622, model__gamma=3, model__learning_rate=0.20688302542803436, model__max_delta_step=19, model__max_depth=8, model__min_child_weight=10, model__n_estimators=149, model__scale_pos_weight=47.440087594703016, model__subsample=0.6276583216721197, scale=passthrough, score=0.815, total=  19.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5813068156435819, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1178995687832883, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6204906001531987, scale=passthrough 
[13:33:49] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5813068156435819, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1178995687832883, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6204906001531987, scale=passthrough, score=0.822, total=  10.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5813068156435819, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1178995687832883, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6204906001531987, scale=passthrough 
[13:33:52] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5813068156435819, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1178995687832883, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.6204906001531987, scale=passthrough, score=0.824, total=  11.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6582926807483003, model__colsample_bytree=0.3, model__gamma=5, model__learning_rate=0.2482871564923991, model__max_delta_step=14, model__max_depth=20, model__min_child_weight=10, model__n_estimators=61, model__scale_pos_weight=882.6450983940014, model__subsample=1.0, scale=passthrough 
[12:40:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6582926807483003, model__colsample_bytree=0.3, model__gamma=5, model__learning_rate=0.2482871564923991, model__max_delta_step=14, model__max_depth=20, model__min_child_weight=10, model__n_estimators=61, model__scale_pos_weight=882.6450983940014, model__subsample=1.0, scale=passthrough, score=0.812, total=   4.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9120957067510712, model__colsample_bytree=0.5976528037728883, model__gamma=1, model__learning_rate=0.12761761072761757, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=2.0000521908976103, model__subsample=1.0, scale=passthrough 
[12:43:15] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9120957067510712, model__colsample_bytree=0.5976528037728883, model__gamma=1, model__learning_rate=0.12761761072761757, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=2.0000521908976103, model__subsample=1.0, scale=passthrough, score=0.822, total=  29.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.06348571978562509, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=1, model__n_estimators=134, model__scale_pos_weight=56.24623518863065, model__subsample=1.0, scale=passthrough 
[12:46:38] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.06348571978562509, model__max_delta_step=20, model__max_depth=6, model__min_child_weight=1, model__n_estimators=134, model__scale_pos_weight=56.24623518863065, model__subsample=1.0, scale=passthrough, score=0.817, total=  24.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8106827059215695, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.027779855529191815, model__max_delta_step=1, model__max_depth=10, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.636469752338156, scale=passthrough 
[12:49:56] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8106827059215695, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.027779855529191815, model__max_delta_step=1, model__max_depth=10, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.636469752338156, scale=passthrough, score=0.821, total=  27.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6476297636717281, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.032733906308545044, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.5768325263639889, scale=passthrough 
[12:53:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6476297636717281, model__colsample_bytree=1.0, model__gamma=2, model__learning_rate=0.032733906308545044, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=1000.0, model__subsample=0.5768325263639889, scale=passthrough, score=0.811, total=   9.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=20, model__max_depth=16, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=419.3974496621373, model__subsample=0.3, scale=passthrough 
[12:57:27] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=20, model__max_depth=16, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=419.3974496621373, model__subsample=0.3, scale=passthrough, score=0.819, total=  21.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3728573344531136, model__colsample_bytree=0.996298705345964, model__gamma=2, model__learning_rate=0.8927049177339886, model__max_delta_step=1, model__max_depth=3, model__min_child_weight=1, model__n_estimators=53, model__scale_pos_weight=3.893877211807879, model__subsample=0.9822400866927687, scale=passthrough 
[13:00:46] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3728573344531136, model__colsample_bytree=0.996298705345964, model__gamma=2, model__learning_rate=0.8927049177339886, model__max_delta_step=1, model__max_depth=3, model__min_child_weight=1, model__n_estimators=53, model__scale_pos_weight=3.893877211807879, model__subsample=0.9822400866927687, scale=passthrough, score=0.812, total=   2.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.605848784786007, model__colsample_bytree=0.3030158208675209, model__gamma=1, model__learning_rate=0.016666545458275794, model__max_delta_step=14, model__max_depth=3, model__min_child_weight=3, model__n_estimators=59, model__scale_pos_weight=57.48214623733764, model__subsample=0.8271495199964074, scale=passthrough 
[13:03:04] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.605848784786007, model__colsample_bytree=0.3030158208675209, model__gamma=1, model__learning_rate=0.016666545458275794, model__max_delta_step=14, model__max_depth=3, model__min_child_weight=3, model__n_estimators=59, model__scale_pos_weight=57.48214623733764, model__subsample=0.8271495199964074, scale=passthrough, score=0.783, total=   1.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.47049265824961084, model__colsample_bytree=0.336411957584814, model__gamma=2, model__learning_rate=0.0628578451181805, model__max_delta_step=16, model__max_depth=18, model__min_child_weight=9, model__n_estimators=53, model__scale_pos_weight=768.7838984341289, model__subsample=0.9992098127509952, scale=passthrough 
[13:07:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.47049265824961084, model__colsample_bytree=0.336411957584814, model__gamma=2, model__learning_rate=0.0628578451181805, model__max_delta_step=16, model__max_depth=18, model__min_child_weight=9, model__n_estimators=53, model__scale_pos_weight=768.7838984341289, model__subsample=0.9992098127509952, scale=passthrough, score=0.805, total=   2.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44888233845569864, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09627500238061928, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6523953423489568, scale=passthrough 
[13:11:05] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44888233845569864, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.09627500238061928, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=8, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.6523953423489568, scale=passthrough, score=0.827, total=   4.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.20188376728451304, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08019434098964026, model__max_delta_step=3, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.3112689020839243, model__subsample=1.0, scale=passthrough 
[13:15:11] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.20188376728451304, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08019434098964026, model__max_delta_step=3, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.3112689020839243, model__subsample=1.0, scale=passthrough, score=0.820, total=   2.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.046730668908318174, model__colsample_bytree=0.6602693794904608, model__gamma=2, model__learning_rate=0.11136392187445981, model__max_delta_step=3, model__max_depth=19, model__min_child_weight=9, model__n_estimators=138, model__scale_pos_weight=742.0520711455373, model__subsample=0.975120004288275, scale=passthrough 
[13:19:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.046730668908318174, model__colsample_bytree=0.6602693794904608, model__gamma=2, model__learning_rate=0.11136392187445981, model__max_delta_step=3, model__max_depth=19, model__min_child_weight=9, model__n_estimators=138, model__scale_pos_weight=742.0520711455373, model__subsample=0.975120004288275, scale=passthrough, score=0.817, total=   2.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6541951007767545, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10696240430203029, model__max_delta_step=20, model__max_depth=12, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8501377179735958, scale=passthrough 
[13:24:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6541951007767545, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10696240430203029, model__max_delta_step=20, model__max_depth=12, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.8501377179735958, scale=passthrough, score=0.821, total=  18.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9916904238916124, model__colsample_bytree=0.9688464311980622, model__gamma=3, model__learning_rate=0.20688302542803436, model__max_delta_step=19, model__max_depth=8, model__min_child_weight=10, model__n_estimators=149, model__scale_pos_weight=47.440087594703016, model__subsample=0.6276583216721197, scale=passthrough 
[13:29:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9916904238916124, model__colsample_bytree=0.9688464311980622, model__gamma=3, model__learning_rate=0.20688302542803436, model__max_delta_step=19, model__max_depth=8, model__min_child_weight=10, model__n_estimators=149, model__scale_pos_weight=47.440087594703016, model__subsample=0.6276583216721197, scale=passthrough, score=0.828, total=  19.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7529066100167874, model__colsample_bytree=0.8659802214495997, model__gamma=4, model__learning_rate=0.12838713094015772, model__max_delta_step=0, model__max_depth=15, model__min_child_weight=1, model__n_estimators=65, model__scale_pos_weight=8.262419368059616, model__subsample=0.9672368693922622, scale=passthrough 
[13:34:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7529066100167874, model__colsample_bytree=0.8659802214495997, model__gamma=4, model__learning_rate=0.12838713094015772, model__max_delta_step=0, model__max_depth=15, model__min_child_weight=1, model__n_estimators=65, model__scale_pos_weight=8.262419368059616, model__subsample=0.9672368693922622, scale=passthrough, score=0.815, total=  12.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.21116703221890631, model__colsample_bytree=0.819317800389112, model__gamma=3, model__learning_rate=0.20579929372020303, model__max_delta_step=12, model__max_depth=14, model__min_child_weight=5, model__n_estimators=65, model__scale_pos_weight=597.6163936494521, model__subsample=0.7932909428145046, scale=passthrough 
[12:39:10] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.21116703221890631, model__colsample_bytree=0.819317800389112, model__gamma=3, model__learning_rate=0.20579929372020303, model__max_delta_step=12, model__max_depth=14, model__min_child_weight=5, model__n_estimators=65, model__scale_pos_weight=597.6163936494521, model__subsample=0.7932909428145046, scale=passthrough, score=0.818, total=   3.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=0.3, model__gamma=5, model__learning_rate=0.09212493376669943, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=278.87157613599607, model__subsample=0.46981062344447505, scale=passthrough 
[12:41:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=0.3, model__gamma=5, model__learning_rate=0.09212493376669943, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=278.87157613599607, model__subsample=0.46981062344447505, scale=passthrough, score=0.773, total=   1.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8067700059239111, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.0386039068194868, model__max_delta_step=0, model__max_depth=15, model__min_child_weight=3, model__n_estimators=50, model__scale_pos_weight=1.0841388341722655, model__subsample=0.693493293070414, scale=passthrough 
[12:44:17] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8067700059239111, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.0386039068194868, model__max_delta_step=0, model__max_depth=15, model__min_child_weight=3, model__n_estimators=50, model__scale_pos_weight=1.0841388341722655, model__subsample=0.693493293070414, scale=passthrough, score=0.821, total=   8.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1534871991399859, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=1, model__n_estimators=117, model__scale_pos_weight=6.455106843288009, model__subsample=1.0, scale=passthrough 
[12:47:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1534871991399859, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=1, model__n_estimators=117, model__scale_pos_weight=6.455106843288009, model__subsample=1.0, scale=passthrough, score=0.809, total=  37.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.03288580264204534, model__colsample_bytree=0.5478144161532192, model__gamma=4, model__learning_rate=1.0, model__max_delta_step=14, model__max_depth=20, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:50:27] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.03288580264204534, model__colsample_bytree=0.5478144161532192, model__gamma=4, model__learning_rate=1.0, model__max_delta_step=14, model__max_depth=20, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.740, total=   1.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6116986539206163, model__colsample_bytree=0.8566999167764007, model__gamma=1, model__learning_rate=0.04296027090185901, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:53:37] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6116986539206163, model__colsample_bytree=0.8566999167764007, model__gamma=1, model__learning_rate=0.04296027090185901, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.814, total=  20.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=20, model__max_depth=16, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=419.3974496621373, model__subsample=0.3, scale=passthrough 
[12:57:27] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=20, model__max_depth=16, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=419.3974496621373, model__subsample=0.3, scale=passthrough, score=0.819, total=  21.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8647304389121462, model__colsample_bytree=0.5531570314461818, model__gamma=3, model__learning_rate=0.01029200788866549, model__max_delta_step=18, model__max_depth=11, model__min_child_weight=1, model__n_estimators=71, model__scale_pos_weight=137.07094436479818, model__subsample=0.34245761309552675, scale=passthrough 
[13:00:54] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8647304389121462, model__colsample_bytree=0.5531570314461818, model__gamma=3, model__learning_rate=0.01029200788866549, model__max_delta_step=18, model__max_depth=11, model__min_child_weight=1, model__n_estimators=71, model__scale_pos_weight=137.07094436479818, model__subsample=0.34245761309552675, scale=passthrough, score=0.805, total=   5.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[13:03:11] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.791, total=  51.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.47049265824961084, model__colsample_bytree=0.336411957584814, model__gamma=2, model__learning_rate=0.0628578451181805, model__max_delta_step=16, model__max_depth=18, model__min_child_weight=9, model__n_estimators=53, model__scale_pos_weight=768.7838984341289, model__subsample=0.9992098127509952, scale=passthrough 
[13:07:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.47049265824961084, model__colsample_bytree=0.336411957584814, model__gamma=2, model__learning_rate=0.0628578451181805, model__max_delta_step=16, model__max_depth=18, model__min_child_weight=9, model__n_estimators=53, model__scale_pos_weight=768.7838984341289, model__subsample=0.9992098127509952, scale=passthrough, score=0.815, total=   2.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.68577891423815, model__colsample_bytree=0.5886129420682689, model__gamma=3, model__learning_rate=0.010700985541269331, model__max_delta_step=9, model__max_depth=19, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=1.6415738019047055, model__subsample=0.8637639144432199, scale=passthrough 
[13:11:18] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.68577891423815, model__colsample_bytree=0.5886129420682689, model__gamma=3, model__learning_rate=0.010700985541269331, model__max_delta_step=9, model__max_depth=19, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=1.6415738019047055, model__subsample=0.8637639144432199, scale=passthrough, score=0.808, total=  14.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.20188376728451304, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08019434098964026, model__max_delta_step=3, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.3112689020839243, model__subsample=1.0, scale=passthrough 
[13:15:11] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.20188376728451304, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.08019434098964026, model__max_delta_step=3, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=1.3112689020839243, model__subsample=1.0, scale=passthrough, score=0.821, total=   2.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.046730668908318174, model__colsample_bytree=0.6602693794904608, model__gamma=2, model__learning_rate=0.11136392187445981, model__max_delta_step=3, model__max_depth=19, model__min_child_weight=9, model__n_estimators=138, model__scale_pos_weight=742.0520711455373, model__subsample=0.975120004288275, scale=passthrough 
[13:19:59] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.046730668908318174, model__colsample_bytree=0.6602693794904608, model__gamma=2, model__learning_rate=0.11136392187445981, model__max_delta_step=3, model__max_depth=19, model__min_child_weight=9, model__n_estimators=138, model__scale_pos_weight=742.0520711455373, model__subsample=0.975120004288275, scale=passthrough, score=0.809, total=   2.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7664751801070965, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11878922251722432, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7229682045214889, scale=passthrough 
[13:24:45] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7664751801070965, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11878922251722432, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7229682045214889, scale=passthrough, score=0.822, total=   7.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9162715601351066, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.12409866378814392, model__max_delta_step=0, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8073766448422177, scale=passthrough 
[13:29:40] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9162715601351066, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.12409866378814392, model__max_delta_step=0, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8073766448422177, scale=passthrough, score=0.821, total=  16.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7529066100167874, model__colsample_bytree=0.8659802214495997, model__gamma=4, model__learning_rate=0.12838713094015772, model__max_delta_step=0, model__max_depth=15, model__min_child_weight=1, model__n_estimators=65, model__scale_pos_weight=8.262419368059616, model__subsample=0.9672368693922622, scale=passthrough 
[13:34:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7529066100167874, model__colsample_bytree=0.8659802214495997, model__gamma=4, model__learning_rate=0.12838713094015772, model__max_delta_step=0, model__max_depth=15, model__min_child_weight=1, model__n_estimators=65, model__scale_pos_weight=8.262419368059616, model__subsample=0.9672368693922622, scale=passthrough, score=0.814, total=  13.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.8835222719721867, model__gamma=3, model__learning_rate=0.01, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=7, model__n_estimators=80, model__scale_pos_weight=24.931036467252635, model__subsample=0.3, scale=passthrough 
[12:41:07] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=0.8835222719721867, model__gamma=3, model__learning_rate=0.01, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=7, model__n_estimators=80, model__scale_pos_weight=24.931036467252635, model__subsample=0.3, scale=passthrough, score=0.793, total=   7.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6731793514102031, model__colsample_bytree=0.6363610788977796, model__gamma=3, model__learning_rate=0.06654762391643661, model__max_delta_step=6, model__max_depth=19, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=4.459684760380094, model__subsample=0.699457292016114, scale=passthrough 
[12:44:01] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6731793514102031, model__colsample_bytree=0.6363610788977796, model__gamma=3, model__learning_rate=0.06654762391643661, model__max_delta_step=6, model__max_depth=19, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=4.459684760380094, model__subsample=0.699457292016114, scale=passthrough, score=0.817, total=  13.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4201453433278661, model__colsample_bytree=0.6602346245231958, model__gamma=5, model__learning_rate=0.01, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=4.536038333596355, model__subsample=1.0, scale=passthrough 
[12:47:05] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.4201453433278661, model__colsample_bytree=0.6602346245231958, model__gamma=5, model__learning_rate=0.01, model__max_delta_step=18, model__max_depth=20, model__min_child_weight=1, model__n_estimators=50, model__scale_pos_weight=4.536038333596355, model__subsample=1.0, scale=passthrough, score=0.804, total=   6.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.03288580264204534, model__colsample_bytree=0.5478144161532192, model__gamma=4, model__learning_rate=1.0, model__max_delta_step=14, model__max_depth=20, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:50:27] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.03288580264204534, model__colsample_bytree=0.5478144161532192, model__gamma=4, model__learning_rate=1.0, model__max_delta_step=14, model__max_depth=20, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.725, total=   1.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6116986539206163, model__colsample_bytree=0.8566999167764007, model__gamma=1, model__learning_rate=0.04296027090185901, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[12:53:37] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6116986539206163, model__colsample_bytree=0.8566999167764007, model__gamma=1, model__learning_rate=0.04296027090185901, model__max_delta_step=0, model__max_depth=12, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.822, total=  20.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7643252963704794, scale=passthrough 
[12:57:54] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7643252963704794, scale=passthrough, score=0.794, total=  12.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8647304389121462, model__colsample_bytree=0.5531570314461818, model__gamma=3, model__learning_rate=0.01029200788866549, model__max_delta_step=18, model__max_depth=11, model__min_child_weight=1, model__n_estimators=71, model__scale_pos_weight=137.07094436479818, model__subsample=0.34245761309552675, scale=passthrough 
[13:00:54] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8647304389121462, model__colsample_bytree=0.5531570314461818, model__gamma=3, model__learning_rate=0.01029200788866549, model__max_delta_step=18, model__max_depth=11, model__min_child_weight=1, model__n_estimators=71, model__scale_pos_weight=137.07094436479818, model__subsample=0.34245761309552675, scale=passthrough, score=0.807, total=   5.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough 
[13:03:11] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=1.0, scale=passthrough, score=0.796, total=  52.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2311826252494585, model__colsample_bytree=0.5676651755593167, model__gamma=3, model__learning_rate=0.010748621084095817, model__max_delta_step=2, model__max_depth=19, model__min_child_weight=9, model__n_estimators=146, model__scale_pos_weight=1.2649493021420082, model__subsample=0.3659818044313171, scale=passthrough 
[13:07:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2311826252494585, model__colsample_bytree=0.5676651755593167, model__gamma=3, model__learning_rate=0.010748621084095817, model__max_delta_step=2, model__max_depth=19, model__min_child_weight=9, model__n_estimators=146, model__scale_pos_weight=1.2649493021420082, model__subsample=0.3659818044313171, scale=passthrough, score=0.777, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.68577891423815, model__colsample_bytree=0.5886129420682689, model__gamma=3, model__learning_rate=0.010700985541269331, model__max_delta_step=9, model__max_depth=19, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=1.6415738019047055, model__subsample=0.8637639144432199, scale=passthrough 
[13:11:18] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.68577891423815, model__colsample_bytree=0.5886129420682689, model__gamma=3, model__learning_rate=0.010700985541269331, model__max_delta_step=9, model__max_depth=19, model__min_child_weight=10, model__n_estimators=148, model__scale_pos_weight=1.6415738019047055, model__subsample=0.8637639144432199, scale=passthrough, score=0.812, total=  15.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6171724782762312, model__colsample_bytree=0.9575457944704855, model__gamma=1, model__learning_rate=0.31139832384577526, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=1, model__n_estimators=59, model__scale_pos_weight=802.3181375618043, model__subsample=0.6211383727747098, scale=passthrough 
[13:15:22] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6171724782762312, model__colsample_bytree=0.9575457944704855, model__gamma=1, model__learning_rate=0.31139832384577526, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=1, model__n_estimators=59, model__scale_pos_weight=802.3181375618043, model__subsample=0.6211383727747098, scale=passthrough, score=0.814, total=   8.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44093624934152575, model__colsample_bytree=0.6989660277906319, model__gamma=1, model__learning_rate=0.13577638361933037, model__max_delta_step=13, model__max_depth=11, model__min_child_weight=1, model__n_estimators=54, model__scale_pos_weight=67.11062815232934, model__subsample=0.338745900913235, scale=passthrough 
[13:20:13] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44093624934152575, model__colsample_bytree=0.6989660277906319, model__gamma=1, model__learning_rate=0.13577638361933037, model__max_delta_step=13, model__max_depth=11, model__min_child_weight=1, model__n_estimators=54, model__scale_pos_weight=67.11062815232934, model__subsample=0.338745900913235, scale=passthrough, score=0.812, total=   2.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7664751801070965, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11878922251722432, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7229682045214889, scale=passthrough 
[13:24:45] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7664751801070965, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11878922251722432, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7229682045214889, scale=passthrough, score=0.832, total=   7.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9162715601351066, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.12409866378814392, model__max_delta_step=0, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8073766448422177, scale=passthrough 
[13:29:40] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9162715601351066, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.12409866378814392, model__max_delta_step=0, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8073766448422177, scale=passthrough, score=0.821, total=  16.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7529066100167874, model__colsample_bytree=0.8659802214495997, model__gamma=4, model__learning_rate=0.12838713094015772, model__max_delta_step=0, model__max_depth=15, model__min_child_weight=1, model__n_estimators=65, model__scale_pos_weight=8.262419368059616, model__subsample=0.9672368693922622, scale=passthrough 
[13:34:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7529066100167874, model__colsample_bytree=0.8659802214495997, model__gamma=4, model__learning_rate=0.12838713094015772, model__max_delta_step=0, model__max_depth=15, model__min_child_weight=1, model__n_estimators=65, model__scale_pos_weight=8.262419368059616, model__subsample=0.9672368693922622, scale=passthrough, score=0.816, total=  13.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6565466212924355, model__colsample_bytree=0.735357685288236, model__gamma=2, model__learning_rate=0.04957929129543922, model__max_delta_step=15, model__max_depth=8, model__min_child_weight=4, model__n_estimators=78, model__scale_pos_weight=23.24113601995236, model__subsample=0.3610574395015852, scale=passthrough 
[12:39:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6565466212924355, model__colsample_bytree=0.735357685288236, model__gamma=2, model__learning_rate=0.04957929129543922, model__max_delta_step=15, model__max_depth=8, model__min_child_weight=4, model__n_estimators=78, model__scale_pos_weight=23.24113601995236, model__subsample=0.3610574395015852, scale=passthrough, score=0.815, total=   5.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3877751846015693, model__colsample_bytree=0.3756560342002999, model__gamma=1, model__learning_rate=0.09924153138966316, model__max_delta_step=16, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=4.88715669317987, model__subsample=0.4833253110046396, scale=passthrough 
[12:41:19] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3877751846015693, model__colsample_bytree=0.3756560342002999, model__gamma=1, model__learning_rate=0.09924153138966316, model__max_delta_step=16, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=4.88715669317987, model__subsample=0.4833253110046396, scale=passthrough, score=0.815, total=   1.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8067700059239111, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.0386039068194868, model__max_delta_step=0, model__max_depth=15, model__min_child_weight=3, model__n_estimators=50, model__scale_pos_weight=1.0841388341722655, model__subsample=0.693493293070414, scale=passthrough 
[12:44:17] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8067700059239111, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.0386039068194868, model__max_delta_step=0, model__max_depth=15, model__min_child_weight=3, model__n_estimators=50, model__scale_pos_weight=1.0841388341722655, model__subsample=0.693493293070414, scale=passthrough, score=0.807, total=   9.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1534871991399859, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=1, model__n_estimators=117, model__scale_pos_weight=6.455106843288009, model__subsample=1.0, scale=passthrough 
[12:47:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1534871991399859, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=1, model__n_estimators=117, model__scale_pos_weight=6.455106843288009, model__subsample=1.0, scale=passthrough, score=0.815, total=  37.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6883518065722666, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.04130579513609374, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.5103962518485224, scale=passthrough 
[12:50:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6883518065722666, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.04130579513609374, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.5103962518485224, scale=passthrough, score=0.821, total=  24.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.07004251820541824, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7625147925681803, scale=passthrough 
[12:54:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.07004251820541824, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7625147925681803, scale=passthrough, score=0.807, total=  47.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7643252963704794, scale=passthrough 
[12:57:54] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7643252963704794, scale=passthrough, score=0.799, total=  12.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.26523868268741607, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[13:01:04] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.26523868268741607, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.781, total=   2.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2926672548978454, model__colsample_bytree=0.5867886522755954, model__gamma=3, model__learning_rate=0.086894693605999, model__max_delta_step=1, model__max_depth=3, model__min_child_weight=1, model__n_estimators=119, model__scale_pos_weight=4.783825724876682, model__subsample=0.3041125013442748, scale=passthrough 
[13:04:09] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2926672548978454, model__colsample_bytree=0.5867886522755954, model__gamma=3, model__learning_rate=0.086894693605999, model__max_delta_step=1, model__max_depth=3, model__min_child_weight=1, model__n_estimators=119, model__scale_pos_weight=4.783825724876682, model__subsample=0.3041125013442748, scale=passthrough, score=0.809, total=   1.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.99256112795603, model__colsample_bytree=0.3402333276520046, model__gamma=4, model__learning_rate=0.11307837202164223, model__max_delta_step=19, model__max_depth=4, model__min_child_weight=1, model__n_estimators=145, model__scale_pos_weight=13.987266647869875, model__subsample=0.39763524876794626, scale=passthrough 
[13:07:34] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.99256112795603, model__colsample_bytree=0.3402333276520046, model__gamma=4, model__learning_rate=0.11307837202164223, model__max_delta_step=19, model__max_depth=4, model__min_child_weight=1, model__n_estimators=145, model__scale_pos_weight=13.987266647869875, model__subsample=0.39763524876794626, scale=passthrough, score=0.802, total=   4.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3385057496683822, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07293494024397029, model__max_delta_step=20, model__max_depth=7, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.1054915522600333, model__subsample=0.765240062441286, scale=passthrough 
[13:11:41] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3385057496683822, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07293494024397029, model__max_delta_step=20, model__max_depth=7, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.1054915522600333, model__subsample=0.765240062441286, scale=passthrough, score=0.820, total=   8.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8734254422828995, model__colsample_bytree=0.9509562517823495, model__gamma=2, model__learning_rate=0.010287031832540747, model__max_delta_step=3, model__max_depth=18, model__min_child_weight=2, model__n_estimators=137, model__scale_pos_weight=3.717320547813186, model__subsample=0.5853514305903059, scale=passthrough 
[13:15:40] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8734254422828995, model__colsample_bytree=0.9509562517823495, model__gamma=2, model__learning_rate=0.010287031832540747, model__max_delta_step=3, model__max_depth=18, model__min_child_weight=2, model__n_estimators=137, model__scale_pos_weight=3.717320547813186, model__subsample=0.5853514305903059, scale=passthrough, score=0.816, total=  29.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6788578084180311, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10510529783124824, model__max_delta_step=0, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.712108015281221, scale=passthrough 
[13:20:28] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6788578084180311, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.10510529783124824, model__max_delta_step=0, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.712108015281221, scale=passthrough, score=0.826, total=  12.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9001342684252364, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.054251822511365205, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7348745960658764, scale=passthrough 
[13:25:05] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9001342684252364, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.054251822511365205, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7348745960658764, scale=passthrough, score=0.820, total=   8.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6683160421947889, model__colsample_bytree=0.8777316471202263, model__gamma=2, model__learning_rate=0.03873852470666852, model__max_delta_step=6, model__max_depth=4, model__min_child_weight=1, model__n_estimators=137, model__scale_pos_weight=3.7995034600209316, model__subsample=0.31696593658678845, scale=passthrough 
[13:30:11] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6683160421947889, model__colsample_bytree=0.8777316471202263, model__gamma=2, model__learning_rate=0.03873852470666852, model__max_delta_step=6, model__max_depth=4, model__min_child_weight=1, model__n_estimators=137, model__scale_pos_weight=3.7995034600209316, model__subsample=0.31696593658678845, scale=passthrough, score=0.814, total=   5.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8465371232284055, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11171784991334584, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[13:34:43] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8465371232284055, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11171784991334584, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.815, total=  24.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.21116703221890631, model__colsample_bytree=0.819317800389112, model__gamma=3, model__learning_rate=0.20579929372020303, model__max_delta_step=12, model__max_depth=14, model__min_child_weight=5, model__n_estimators=65, model__scale_pos_weight=597.6163936494521, model__subsample=0.7932909428145046, scale=passthrough 
[12:39:10] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.21116703221890631, model__colsample_bytree=0.819317800389112, model__gamma=3, model__learning_rate=0.20579929372020303, model__max_delta_step=12, model__max_depth=14, model__min_child_weight=5, model__n_estimators=65, model__scale_pos_weight=597.6163936494521, model__subsample=0.7932909428145046, scale=passthrough, score=0.821, total=   4.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3877751846015693, model__colsample_bytree=0.3756560342002999, model__gamma=1, model__learning_rate=0.09924153138966316, model__max_delta_step=16, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=4.88715669317987, model__subsample=0.4833253110046396, scale=passthrough 
[12:41:19] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3877751846015693, model__colsample_bytree=0.3756560342002999, model__gamma=1, model__learning_rate=0.09924153138966316, model__max_delta_step=16, model__max_depth=20, model__min_child_weight=10, model__n_estimators=50, model__scale_pos_weight=4.88715669317987, model__subsample=0.4833253110046396, scale=passthrough, score=0.798, total=   1.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8067700059239111, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.0386039068194868, model__max_delta_step=0, model__max_depth=15, model__min_child_weight=3, model__n_estimators=50, model__scale_pos_weight=1.0841388341722655, model__subsample=0.693493293070414, scale=passthrough 
[12:44:17] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8067700059239111, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.0386039068194868, model__max_delta_step=0, model__max_depth=15, model__min_child_weight=3, model__n_estimators=50, model__scale_pos_weight=1.0841388341722655, model__subsample=0.693493293070414, scale=passthrough, score=0.817, total=   9.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5986048699610145, model__colsample_bytree=0.7206152207911285, model__gamma=1, model__learning_rate=0.030273563622536564, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=9, model__n_estimators=50, model__scale_pos_weight=953.4397812625493, model__subsample=1.0, scale=passthrough 
[12:47:55] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.5986048699610145, model__colsample_bytree=0.7206152207911285, model__gamma=1, model__learning_rate=0.030273563622536564, model__max_delta_step=0, model__max_depth=20, model__min_child_weight=9, model__n_estimators=50, model__scale_pos_weight=953.4397812625493, model__subsample=1.0, scale=passthrough, score=0.811, total=   4.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6883518065722666, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.04130579513609374, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.5103962518485224, scale=passthrough 
[12:50:32] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6883518065722666, model__colsample_bytree=1.0, model__gamma=3, model__learning_rate=0.04130579513609374, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.5103962518485224, scale=passthrough, score=0.811, total=  24.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.07004251820541824, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7625147925681803, scale=passthrough 
[12:54:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.07004251820541824, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7625147925681803, scale=passthrough, score=0.822, total=  47.9s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.028930220462137776, model__max_delta_step=13, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:58:12] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.028930220462137776, model__max_delta_step=13, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.807, total=   7.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.26523868268741607, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough 
[13:01:04] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.26523868268741607, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=15, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.3, scale=passthrough, score=0.796, total=   2.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7723746868256385, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=9.000308447877524, model__subsample=0.3, scale=passthrough 
[13:04:18] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7723746868256385, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=6, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=9.000308447877524, model__subsample=0.3, scale=passthrough, score=0.822, total=  17.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.99256112795603, model__colsample_bytree=0.3402333276520046, model__gamma=4, model__learning_rate=0.11307837202164223, model__max_delta_step=19, model__max_depth=4, model__min_child_weight=1, model__n_estimators=145, model__scale_pos_weight=13.987266647869875, model__subsample=0.39763524876794626, scale=passthrough 
[13:07:34] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.99256112795603, model__colsample_bytree=0.3402333276520046, model__gamma=4, model__learning_rate=0.11307837202164223, model__max_delta_step=19, model__max_depth=4, model__min_child_weight=1, model__n_estimators=145, model__scale_pos_weight=13.987266647869875, model__subsample=0.39763524876794626, scale=passthrough, score=0.811, total=   4.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3385057496683822, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07293494024397029, model__max_delta_step=20, model__max_depth=7, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.1054915522600333, model__subsample=0.765240062441286, scale=passthrough 
[13:11:41] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3385057496683822, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07293494024397029, model__max_delta_step=20, model__max_depth=7, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.1054915522600333, model__subsample=0.765240062441286, scale=passthrough, score=0.818, total=   8.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6171724782762312, model__colsample_bytree=0.9575457944704855, model__gamma=1, model__learning_rate=0.31139832384577526, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=1, model__n_estimators=59, model__scale_pos_weight=802.3181375618043, model__subsample=0.6211383727747098, scale=passthrough 
[13:15:22] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6171724782762312, model__colsample_bytree=0.9575457944704855, model__gamma=1, model__learning_rate=0.31139832384577526, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=1, model__n_estimators=59, model__scale_pos_weight=802.3181375618043, model__subsample=0.6211383727747098, scale=passthrough, score=0.809, total=   8.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44093624934152575, model__colsample_bytree=0.6989660277906319, model__gamma=1, model__learning_rate=0.13577638361933037, model__max_delta_step=13, model__max_depth=11, model__min_child_weight=1, model__n_estimators=54, model__scale_pos_weight=67.11062815232934, model__subsample=0.338745900913235, scale=passthrough 
[13:20:13] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44093624934152575, model__colsample_bytree=0.6989660277906319, model__gamma=1, model__learning_rate=0.13577638361933037, model__max_delta_step=13, model__max_depth=11, model__min_child_weight=1, model__n_estimators=54, model__scale_pos_weight=67.11062815232934, model__subsample=0.338745900913235, scale=passthrough, score=0.815, total=   2.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9001342684252364, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.054251822511365205, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7348745960658764, scale=passthrough 
[13:25:05] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9001342684252364, model__colsample_bytree=0.3, model__gamma=1, model__learning_rate=0.054251822511365205, model__max_delta_step=17, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7348745960658764, scale=passthrough, score=0.817, total=   8.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6683160421947889, model__colsample_bytree=0.8777316471202263, model__gamma=2, model__learning_rate=0.03873852470666852, model__max_delta_step=6, model__max_depth=4, model__min_child_weight=1, model__n_estimators=137, model__scale_pos_weight=3.7995034600209316, model__subsample=0.31696593658678845, scale=passthrough 
[13:30:11] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6683160421947889, model__colsample_bytree=0.8777316471202263, model__gamma=2, model__learning_rate=0.03873852470666852, model__max_delta_step=6, model__max_depth=4, model__min_child_weight=1, model__n_estimators=137, model__scale_pos_weight=3.7995034600209316, model__subsample=0.31696593658678845, scale=passthrough, score=0.817, total=   5.6s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8465371232284055, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11171784991334584, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[13:34:44] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8465371232284055, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11171784991334584, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.823, total=  25.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.21116703221890631, model__colsample_bytree=0.819317800389112, model__gamma=3, model__learning_rate=0.20579929372020303, model__max_delta_step=12, model__max_depth=14, model__min_child_weight=5, model__n_estimators=65, model__scale_pos_weight=597.6163936494521, model__subsample=0.7932909428145046, scale=passthrough 
[12:39:10] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.21116703221890631, model__colsample_bytree=0.819317800389112, model__gamma=3, model__learning_rate=0.20579929372020303, model__max_delta_step=12, model__max_depth=14, model__min_child_weight=5, model__n_estimators=65, model__scale_pos_weight=597.6163936494521, model__subsample=0.7932909428145046, scale=passthrough, score=0.810, total=   4.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=0.3, model__gamma=5, model__learning_rate=0.09212493376669943, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=278.87157613599607, model__subsample=0.46981062344447505, scale=passthrough 
[12:41:16] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.01, model__colsample_bytree=0.3, model__gamma=5, model__learning_rate=0.09212493376669943, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=278.87157613599607, model__subsample=0.46981062344447505, scale=passthrough, score=0.788, total=   1.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6731793514102031, model__colsample_bytree=0.6363610788977796, model__gamma=3, model__learning_rate=0.06654762391643661, model__max_delta_step=6, model__max_depth=19, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=4.459684760380094, model__subsample=0.699457292016114, scale=passthrough 
[12:44:01] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6731793514102031, model__colsample_bytree=0.6363610788977796, model__gamma=3, model__learning_rate=0.06654762391643661, model__max_delta_step=6, model__max_depth=19, model__min_child_weight=7, model__n_estimators=150, model__scale_pos_weight=4.459684760380094, model__subsample=0.699457292016114, scale=passthrough, score=0.825, total=  13.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1534871991399859, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=1, model__n_estimators=117, model__scale_pos_weight=6.455106843288009, model__subsample=1.0, scale=passthrough 
[12:47:14] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.1534871991399859, model__max_delta_step=20, model__max_depth=14, model__min_child_weight=1, model__n_estimators=117, model__scale_pos_weight=6.455106843288009, model__subsample=1.0, scale=passthrough, score=0.812, total=  37.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.03288580264204534, model__colsample_bytree=0.5478144161532192, model__gamma=4, model__learning_rate=1.0, model__max_delta_step=14, model__max_depth=20, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough 
[12:50:27] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.03288580264204534, model__colsample_bytree=0.5478144161532192, model__gamma=4, model__learning_rate=1.0, model__max_delta_step=14, model__max_depth=20, model__min_child_weight=4, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.3, scale=passthrough, score=0.737, total=   1.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.07004251820541824, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7625147925681803, scale=passthrough 
[12:54:02] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=4, model__learning_rate=0.07004251820541824, model__max_delta_step=20, model__max_depth=20, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7625147925681803, scale=passthrough, score=0.821, total=  47.0s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7643252963704794, scale=passthrough 
[12:57:54] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=1.0, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.01, model__max_delta_step=20, model__max_depth=3, model__min_child_weight=1, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.7643252963704794, scale=passthrough, score=0.790, total=  12.2s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8647304389121462, model__colsample_bytree=0.5531570314461818, model__gamma=3, model__learning_rate=0.01029200788866549, model__max_delta_step=18, model__max_depth=11, model__min_child_weight=1, model__n_estimators=71, model__scale_pos_weight=137.07094436479818, model__subsample=0.34245761309552675, scale=passthrough 
[13:00:54] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8647304389121462, model__colsample_bytree=0.5531570314461818, model__gamma=3, model__learning_rate=0.01029200788866549, model__max_delta_step=18, model__max_depth=11, model__min_child_weight=1, model__n_estimators=71, model__scale_pos_weight=137.07094436479818, model__subsample=0.34245761309552675, scale=passthrough, score=0.811, total=   5.4s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2926672548978454, model__colsample_bytree=0.5867886522755954, model__gamma=3, model__learning_rate=0.086894693605999, model__max_delta_step=1, model__max_depth=3, model__min_child_weight=1, model__n_estimators=119, model__scale_pos_weight=4.783825724876682, model__subsample=0.3041125013442748, scale=passthrough 
[13:04:09] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2926672548978454, model__colsample_bytree=0.5867886522755954, model__gamma=3, model__learning_rate=0.086894693605999, model__max_delta_step=1, model__max_depth=3, model__min_child_weight=1, model__n_estimators=119, model__scale_pos_weight=4.783825724876682, model__subsample=0.3041125013442748, scale=passthrough, score=0.798, total=   1.5s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2311826252494585, model__colsample_bytree=0.5676651755593167, model__gamma=3, model__learning_rate=0.010748621084095817, model__max_delta_step=2, model__max_depth=19, model__min_child_weight=9, model__n_estimators=146, model__scale_pos_weight=1.2649493021420082, model__subsample=0.3659818044313171, scale=passthrough 
[13:07:24] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.2311826252494585, model__colsample_bytree=0.5676651755593167, model__gamma=3, model__learning_rate=0.010748621084095817, model__max_delta_step=2, model__max_depth=19, model__min_child_weight=9, model__n_estimators=146, model__scale_pos_weight=1.2649493021420082, model__subsample=0.3659818044313171, scale=passthrough, score=0.805, total=   3.1s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3385057496683822, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07293494024397029, model__max_delta_step=20, model__max_depth=7, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.1054915522600333, model__subsample=0.765240062441286, scale=passthrough 
[13:11:41] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.3385057496683822, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.07293494024397029, model__max_delta_step=20, model__max_depth=7, model__min_child_weight=6, model__n_estimators=150, model__scale_pos_weight=1.1054915522600333, model__subsample=0.765240062441286, scale=passthrough, score=0.821, total=   8.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6171724782762312, model__colsample_bytree=0.9575457944704855, model__gamma=1, model__learning_rate=0.31139832384577526, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=1, model__n_estimators=59, model__scale_pos_weight=802.3181375618043, model__subsample=0.6211383727747098, scale=passthrough 
[13:15:22] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.6171724782762312, model__colsample_bytree=0.9575457944704855, model__gamma=1, model__learning_rate=0.31139832384577526, model__max_delta_step=7, model__max_depth=20, model__min_child_weight=1, model__n_estimators=59, model__scale_pos_weight=802.3181375618043, model__subsample=0.6211383727747098, scale=passthrough, score=0.815, total=   8.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44093624934152575, model__colsample_bytree=0.6989660277906319, model__gamma=1, model__learning_rate=0.13577638361933037, model__max_delta_step=13, model__max_depth=11, model__min_child_weight=1, model__n_estimators=54, model__scale_pos_weight=67.11062815232934, model__subsample=0.338745900913235, scale=passthrough 
[13:20:13] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.44093624934152575, model__colsample_bytree=0.6989660277906319, model__gamma=1, model__learning_rate=0.13577638361933037, model__max_delta_step=13, model__max_depth=11, model__min_child_weight=1, model__n_estimators=54, model__scale_pos_weight=67.11062815232934, model__subsample=0.338745900913235, scale=passthrough, score=0.811, total=   2.7s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7664751801070965, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11878922251722432, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7229682045214889, scale=passthrough 
[13:24:45] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.7664751801070965, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11878922251722432, model__max_delta_step=0, model__max_depth=3, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1000.0, model__subsample=0.7229682045214889, scale=passthrough, score=0.818, total=   7.3s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9162715601351066, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.12409866378814392, model__max_delta_step=0, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8073766448422177, scale=passthrough 
[13:29:40] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.9162715601351066, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.12409866378814392, model__max_delta_step=0, model__max_depth=7, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=0.8073766448422177, scale=passthrough, score=0.819, total=  16.8s
[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8465371232284055, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11171784991334584, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough 
[13:34:43] WARNING: ../src/learner.cc:516: 
Parameters: { feature_names, scale_pos_weight } might not be used.

  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.


[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None,
              feature_names=Index(['mean_rpeaks', 'min_rpeaks', 'max_rpeaks', 'std_rpeaks',
       'median_rpeaks', 'abs_engrpeaks', 'lin_trendrpeaks',
       'approx_entrrpeaks', 'custom_duration', 'custom_duration_std',
       ...
       'extra1', 'extra2', 'extra3', 'extra4', 'extra5', 'corr_ma...
              gamma=None, gpu_id=None, importance_type='gain',
              interaction_constraints=None, learning_rate=None,
              max_delta_step=None, max_depth=None, min_child_weight=None,
              missing=nan, monotone_constraints=None, n_estimators=100,
              n_jobs=None, num_parallel_tree=None, random_state=None,
              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,
              subsample=None, tree_method=None, validate_parameters=None,
              verbosity=None), model__colsample_bylevel=0.8465371232284055, model__colsample_bytree=1.0, model__gamma=1, model__learning_rate=0.11171784991334584, model__max_delta_step=20, model__max_depth=11, model__min_child_weight=10, model__n_estimators=150, model__scale_pos_weight=1.0, model__subsample=1.0, scale=passthrough, score=0.819, total=  25.3s
